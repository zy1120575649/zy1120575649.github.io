<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>腾讯精选练习题50题-最长公共前缀</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
    <content><![CDATA[<ul>
<li><p>给你一个包含 <code>n</code> 个整数的数组 <code>nums</code>，判断 <code>nums</code> 中是否存在三个元素 <em>a，b，c ，*使得 *a + b + c =</em> 0 ？请你找出所有和为 <code>0</code> 且不重复的三元组。</p>
<p><strong>注意：</strong>答案中不可以包含重复的三元组。</p>
</li>
</ul>
<pre><code>**示例 1：**

```
输入：nums = [-1,0,1,2,-1,-4]
输出：[[-1,-1,2],[-1,0,1]]
```

**示例 2：**

```
输入：nums = []
输出：[]
```

**示例 3：**

```
输入：nums = [0]
输出：[]
```</code></pre><pre><code class="java">import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

/*
 * @lc app=leetcode.cn id=15 lang=java
 *
 * [15] 三数之和
 */

// @lc code=start
class Solution {
    public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) {
        List&lt;List&lt;Integer&gt;&gt; res= new ArrayList&lt;&gt;();
        Arrays.sort(nums);
        int n = nums.length;
        for(int i =0;i&lt;n;i++){
           if(i!=0&amp;&amp;nums[i]==nums[i-1]) continue;
           int l=i+1;
           int r =n-1;
           int sum;
           while(l&lt;r){
            sum = nums[i]+nums[l]+nums[r];
            if(sum==0){
                res.add(List.of(nums[i],nums[l],nums[r]));
                 //去除重复处理
                 do {l ++;} while(l &lt; r &amp;&amp; nums[l] == nums[l - 1]);
                 do {r --;} while(l &lt; r &amp;&amp; nums[r] == nums[r + 1]);
            }else if(sum&gt;0){
                r--;
               // continue;
            }else{
                l++;
                //continue;
            }
           }
        }
        return res;
    }
}
// @lc code=end

</code></pre>
<p>算法分析<br>排序 + 双指针</p>
<p>1、枚举每个数，表示该数nums[i]已被确定，在排序后的情况下，通过双指针l，r分别从左边l = i + 1和右边n - 1往中间靠拢，找到nums[i] + nums[l] + nums[r] == 0的所有符合条件的搭配<br>2、在找符合条件搭配的过程中，假设sum = nums[i] + nums[l] + nums[r]<br>若sum &gt; 0，则r往左走，使sum变小<br>若sum &lt; 0，则l往右走，使sum变大<br>若sum == 0，则表示找到了与nums[i]搭配的组合nums[l]和nums[r]，存到ans中<br>3、判重处理<br>确定好nums[i]时，l 需要从i + 1开始<br>当nums[i] == nums[i - 1]，表示当前确定好的数与上一个一样，需要直接continue<br>当找符合条件搭配时，即sum == 0,需要对相同的nums[l]和nums[r]进行判重出来<br>时间复杂度 O(n2)O(n2)</p>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-回文数</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E5%9B%9E%E6%96%87%E6%95%B0/</url>
    <content><![CDATA[<ul>
<li><p>判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。</p>
<p><strong>示例 1:</strong></p>
<pre><code class="markdown">输入: 121
输出: true</code></pre>
<p><strong>示例 2:</strong></p>
<pre><code>输入: -121
输出: false
解释: 从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。</code></pre><p><strong>示例 3:</strong></p>
<pre><code>输入: 10
输出: false
解释: 从右向左读, 为 01 。因此它不是一个回文数。</code></pre><p><strong>进阶:</strong></p>
<p>你能不将整数转为字符串来解决这个问题吗？</p>
</li>
</ul>
<pre><code class="java">

/*
 * @lc app=leetcode.cn id=9 lang=java
 *
 * [9] 回文数
 * 不将整数转为字符串来处理（用的第7题整数反转的思想）
 */

// @lc code=start
class Solution {
    public boolean isPalindrome(int x) {
        // //整数反转后和原数比较(全部反转后可能会溢出)
        // if(x&lt;0) return false;
        // int res=0;
        // int y =x;
        // while(x!=0){
        //     res = res*10+x%10;
        //     x/=10;
        // }
        // return res==y;

        //取后半段进行反转 如果和前半段相同-》是回文数
        if(x&lt;0) return false;
        if(x!=0&amp;&amp;x%10==0) return false;
        int reverseNumber=0;
        while(x&gt;reverseNumber){
            reverseNumber = reverseNumber*10+x%10;
            x/=10;
        }
        return x==reverseNumber||x==reverseNumber/10;//奇数和偶数两种情况 12321 123 12，1221 12 21
       //时间复杂度：O(logn)，对于每次迭代，我们会将输入除以 10，因此时间复杂度为 O(logn)。
    }
}
// @lc code=end

</code></pre>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-最长公共前缀</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/</url>
    <content><![CDATA[<ul>
<li><p>编写一个函数来查找字符串数组中的最长公共前缀。</p>
<p>如果不存在公共前缀，返回空字符串 <code>&quot;&quot;</code>。</p>
</li>
</ul>
<pre><code>**示例 1：**

```
输入：strs = [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]
输出：&quot;fl&quot;
```

**示例 2：**

```
输入：strs = [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]
输出：&quot;&quot;
解释：输入不存在公共前缀。
```



**提示：**

- `0 &lt;= strs.length &lt;= 200`
- `0 &lt;= strs[i].length &lt;= 200`
- `strs[i]` 仅由小写英文字母组成</code></pre><pre><code class="java">/*
 * @lc app=leetcode.cn id=14 lang=java
 *
 * [14] 最长公共前缀(第一次自己调试成功的代码)
 */

// @lc code=start
class Solution {
    public String longestCommonPrefix(String[] strs) {
        String res=&quot;&quot;;
        int index = 0;
        boolean flag= false;
        int n = strs.length;
        if(strs.length==0){
            return res;
        }
        if(strs.length==1){
            return strs[0];
        }
        //获取字符串数组中长度最小的字符串的长度
        int len=strs[0].length();
        for (int i = 0; i &lt; strs.length; i++) {
            len = Math.min(len, strs[i].length());
        }

        while(index&lt;len){
            for (int i = 0; i &lt; n; i++) {
                char s = strs[0].charAt(index);
                if(s==strs[i].charAt(index)){
                    flag=true;
                }else{
                    flag=false;
                    break;
                }
            }
            if(flag==true){
                index++;
            }else{
                res = strs[0].substring(0, index);
                break;
            }
            res= strs[0].substring(0, index);
        }


        return res;
    }
}
// @lc code=end

</code></pre>
<p>算法<br>(暴力枚举) O(nm)<br>暴力枚举方法很简单：先找到所有字符串的最短长度 m，然后从长度 1 到 m 依次枚举判断是否所有字符串的前缀是否都相等。<br>注意输入可能为空数组。<br>时间复杂度<br>最坏情况下，对于 nn 个字符串，都需要遍历到最短长度，故总时间复杂度为 O(nm)。<br>空间复杂度<br>需要额外 O(m)O(m) 的空间存储答案。</p>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-盛最多水的容器</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<ul>
<li><p>给你 <code>n</code> 个非负整数 <code>a1，a2，...，an</code>，每个数代表坐标中的一个点 <code>(i, ai)</code> 。在坐标内画 <code>n</code> 条垂直线，垂直线 <code>i</code> 的两个端点分别为 <code>(i, ai)</code> 和 <code>(i, 0)</code> 。找出其中的两条线，使得它们与 <code>x</code> 轴共同构成的容器可以容纳最多的水。</p>
<p><strong>说明：</strong>你不能倾斜容器。</p>
</li>
</ul>
<p>  <strong>示例 1：</strong></p>
<p><img src="/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8/question_11.jpg" alt="img"></p>
<pre><code>  输入：[1,8,6,2,5,4,8,3,7]
  输出：49 
  解释：图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。</code></pre><p><strong>示例 2：</strong></p>
<pre><code>  输入：height = [1,1]
  输出：1</code></pre><p>  <strong>示例 3：</strong></p>
<pre><code>输入：height = [4,3,2,1,4]
  输出：16</code></pre><p>  <strong>示例 4：</strong></p>
<pre><code>  输入：height = [1,2,1]
  输出：2</code></pre><p>  <strong>提示：</strong></p>
<ul>
<li><code>n = height.length</code></li>
<li><code>2 &lt;= n &lt;= 3 * 104</code></li>
<li><code>0 &lt;= height[i] &lt;= 3 * 104</code></li>
</ul>
<pre><code class="java">/*
 * @lc app=leetcode.cn id=11 lang=java
 *
 * [11] 盛最多水的容器
 */

// @lc code=start
class Solution {
    public int maxArea(int[] height) {
        // int n = height.length;
        // int res =0;
        // for (int i = 1; i &lt;= n-1; i++) {//暴力破解可能会超时
        //     for (int j = 2; j &lt;=n; j++) {
        //         if((j-i)*Math.min(height[i-1], height[j-1])&gt;res){
        //             res = (j-i)*Math.min(height[i-1], height[j-1]);
        //         }
        //     }
        // }
        int n = height.length;
        int res = 0;
        int l = 0;int r = n-1;
        while(l&lt;r){
            res = Math.max(res, Math.min(height[l], height[r])*(r-l));
            if(height[l]&lt;height[r]){
                l++;
            }else{
                r--;
            }

        }
        return res;

    }
}
// @lc code=end



</code></pre>
<p><strong>双指针法</strong>(关键在如何证明)</p>
<p>在暴力解法中，每固定一条直线，就要遍历剩下的所有直线，造成了大量元素的多次重复访问。那么我们有没有办法只扫描一次数组，就可以找到最大的面积呢？让我们来看看双指针算法是怎么做的。<br>1 .最开始的时候，如果我们用指针i和j指向最两端的直线，此时两条直线之间的距离就是最大的，即我们所求矩形面积的宽度(width)为最大。<br>          2.但是位于最两端的直线不一定是最高的，所以它们组成矩形的面积也就不一定是最大的。因此我们依然需要继续遍历整个数组，这时我们将指向数组两端的指针慢慢往里面收敛，直到找到面积最大值。<br>            3.对于此时i和j指向的直线，他们之间的宽度已经是最宽了。于是在收敛的过程中，如果遇到的高度比两端的柱子更低的话，由于之间的宽度更短，所以面积必定更小，我们就可以直接跳过，不予考虑。我们只需要考虑收敛时出现的那些高度更高的柱子。<br>        4.该方法在双指针向中间收敛的过程中，对数组中的每个元素只访问了一次，因此时间复杂度为O(n)</p>
<p><a href="https://leetcode-cn.com/problems/container-with-most-water/solution/zhi-guan-de-shuang-zhi-zhen-fa-jie-shi-by-na-kong/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/container-with-most-water/solution/zhi-guan-de-shuang-zhi-zhen-fa-jie-shi-by-na-kong/</a></p>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-两数相加</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0/</url>
    <content><![CDATA[<pre><code class="java">/*
 * @lc app=leetcode.cn id=2 lang=java
 *
 * [2] 两数相加
 */

// @lc code=start
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
//2-&gt;4-&gt;3 9-&gt;1 结果就是1-&gt;6-&gt;3
class Solution {
    public ListNode addTwoNumbers(ListNode l1, ListNode l2) {
    ListNode l3 = new ListNode(0);//虚拟头节点
    ListNode cur= l3;//当前节点指向l3
    int jin= 0;//进位为0
    while(l1!=null||l2!=null){
        int sum =0;//定义该位上的和
        if(l1!=null){
            sum=sum+l1.val;
            l1=l1.next;
        }//防止999999+999这种位数不同的情况 所以要判断
        if(l2!=null){
            sum+=l2.val;
            l2=l2.next;
        }
        sum += jin;
        cur.next= new ListNode(sum%10);
        cur= cur.next;
        jin = sum/10;
    }
    if(jin!=0){
        cur.next = new ListNode(1);
    }
    return l3.next;

        }

    }
/*这种方法就不需要最后判断最后一位有没有进位了
class Solution {
    public ListNode addTwoNumbers(ListNode l1, ListNode l2) {
        ListNode l3 = new ListNode(0);//虚拟头节点
        ListNode cur = l3;
        int t = 0;//进位
        while(l1!=null||l2!=null||t!=0){
            if(l1!=null) {t+=l1.val;l1=l1.next;}
            if(l2!=null) {t+=l2.val;l2=l2.next;}
            cur.next = new ListNode(t%10);
            cur= cur.next;
           // l1=l1.next;
           // l2=l2.next;
            t/=10;

        }
        return l3.next;
    }
}
*/
// @lc code=end


</code></pre>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-寻找两个正序数组的中位数</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0/</url>
    <content><![CDATA[<p>给定两个大小为 m 和 n 的正序（从小到大）数组 <code>nums1</code> 和 <code>nums2</code>。请你找出并返回这两个正序数组的中位数。</p>
<p><strong>进阶：</strong>你能设计一个时间复杂度为 <code>O(log (m+n))</code> 的算法解决此问题吗</p>
<pre><code class="java">
/*
 * @lc app=leetcode.cn id=4 lang=java
 *
 * [4] 寻找两个正序数组的中位数
 */

// @lc code=start
class Solution {
    public double findMedianSortedArrays(int[] nums1, int[] nums2) {
     int total = nums1.length+nums2.length;
     if(total%2==0){
        int left= f(nums1,0,nums2,0,total/2);
        int right=f(nums1,0,nums2,0,total/2+1);
        return (left+right)/2.0;
     }else{
            return f(nums1,0,nums2,0,total/2+1);
     }
    }
    //寻找第k小元素
    static int f(int[] nums1,int i,int[] nums2,int j,int k){
        //默认第一个数组是最小的
        if(nums1.length-i &gt; nums2.length-j){
            return f(nums2,j,nums1,i,k);
        }
        //当第一个数组已经用完
        if(nums1.length==i){
            return nums2[j+k-1];
        }
        // 当取第一个元素
        if(k==1){
            return Math.min(nums1[i],nums2[j]);
        }

        int si= Math.min(nums1.length, i+k/2);
        int sj= j+k-k/2;
        if(nums1[si-1]&gt;nums2[sj-1]){
            return f(nums1,i,nums2,sj,k-(sj-j));
        }else{
            return f(nums1,si,nums2,j,k-(si-i));
        }
    }

}


</code></pre>
<p><strong>算法分析</strong></p>
<p>给定两个有序的数组，找中位数<code>(n + m) / 2</code>，等价于找第<code>k</code>小的元素，<code>k = (n + m) / 2</code></p>
<p>1、当一共有偶数个数时，找到第<code>total / 2</code>小<code>left</code>和第<code>total / 2 + 1</code>小<code>right</code>，结果是<code>(left + right / 2.0)</code><br>          2、当一共有奇数个数时，找到第<code>total / 2 + 1</code>小，即为结果</p>
<p>==如何找第<code>k</code>小==</p>
<p><img src="/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0/7416_10c98354aa-2020-06-09_170256.jpg" alt="2020-06-09_170256.jpg"></p>
<p>  1、默认第一个数组比第二个数组的有效长度小<br>            2、第一个数组的有效长度从<code>i</code>开始，第二个数组的有效长度从<code>j</code>开始，其中<code>[i,si - 1]</code>是第.                      一个数组的前<code>k / 2个</code>元素，<code>[j, sj - 1]</code>是第二个数组的前<code>k - k / 2</code>个元素<br>            3、当<code>nums1[si - 1] &gt; nums2[sj - 1]</code>时，则表示第<code>k</code>小一定在<code>[i,n]</code>与<code>[sj,m]</code>中<br>            4、当<code>nums1[si - 1] &lt;= nums2[sj - 1</code>]时，则表示第<code>k</code>小一定在<code>[si,n]</code>与<code>[j,m]</code>中</p>
<p>时间复杂度 <code>O(n+m)</code></p>
<p>参考链接：（三种解法）</p>
<p><a href="https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xiang-xi-tong-su-de-si-lu-fen-xi-duo-jie-fa-by-w-2/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xiang-xi-tong-su-de-si-lu-fen-xi-duo-jie-fa-by-w-2/</a></p>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-字符串转换整数 (atoi)</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%8D%A2%E6%95%B4%E6%95%B0%20(atoi)/</url>
    <content><![CDATA[<p>请你来实现一个 <code>atoi</code> 函数，使其能将字符串转换成整数。</p>
<p>首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。接下来的转化规则如下：</p>
<ul>
<li>如果第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字字符组合起来，形成一个有符号整数。</li>
<li>假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成一个整数。</li>
<li>该字符串在有效的整数部分之后也可能会存在多余的字符，那么这些字符可以被忽略，它们对函数不应该造成影响。</li>
</ul>
<p>假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换，即无法进行有效转换。</p>
<p>在任何情况下，若函数不能进行有效的转换时，请返回 0 。</p>
<p><strong>注意：</strong></p>
<ul>
<li>本题中的空白字符只包括空格字符 <code>&#39; &#39;</code> 。</li>
<li>假设我们的环境只能存储 32 位大小的有符号整数，那么其数值范围为 <code>[−231, 231 − 1]</code>。如果数值超过这个范围，请返回 <code>231 − 1</code> 或 <code>−231</code> 。</li>
</ul>
<p><strong>示例 1:</strong></p>
<pre><code>输入: &quot;42&quot;
输出: 42</code></pre><p><strong>示例 2:</strong></p>
<pre><code>输入: &quot;   -42&quot;
输出: -42
解释: 第一个非空白字符为 &#39;-&#39;, 它是一个负号。
     我们尽可能将负号与后面所有连续出现的数字组合起来，最后得到 -42 。</code></pre><p><strong>示例 3:</strong></p>
<pre><code>输入: &quot;4193 with words&quot;
输出: 4193
解释: 转换截止于数字 &#39;3&#39; ，因为它的下一个字符不为数字。</code></pre><p><strong>示例 4:</strong></p>
<pre><code>输入: &quot;words and 987&quot;
输出: 0
解释: 第一个非空字符是 &#39;w&#39;, 但它不是数字或正、负号。
     因此无法执行有效的转换。</code></pre><p><strong>示例 5:</strong></p>
<pre><code>输入: &quot;-91283472332&quot;
输出: -2147483648
解释: 数字 &quot;-91283472332&quot; 超过 32 位有符号整数范围。 
     因此返回 INT_MIN (−231) 。</code></pre><p><strong>提示：</strong></p>
<ul>
<li><code>0 &lt;= s.length &lt;= 200</code></li>
<li><code>s</code> 由英文字母（大写和小写）、数字、<code>&#39; &#39;</code>、<code>&#39;+&#39;</code>、<code>&#39;-&#39;</code> 和 <code>&#39;.&#39;</code> 组成</li>
</ul>
<pre><code class="java">

/*
 * @lc app=leetcode.cn id=8 lang=java
 *
 * [8] 字符串转换整数 (atoi)
 */

// @lc code=start
class Solution {

    public int myAtoi(String s) {
       int n = s.length();
       int k=0;
       while(k&lt;n&amp;&amp;s.charAt(k)==&#39; &#39;){
        k++;
       }
       if(k==n){
           return 0;
       }

       int op = 1;//假设是正号
       if(s.charAt(k)==&#39;-&#39;){
           op=-1;
           k++;
       }else if(s.charAt(k)==&#39;+&#39;){k++;}
/*
算法1
用long记录

1、找到第一个非空的字符位置k，若k == n表示全都是空字符，直接返回0
2、op记录截取后的整数的正负性，1表示正号，-1表示负号
3、使用long类型的res来存储截取后的整数（一定是正整数，因为括号还没包括），在某一刻若res &gt; INT_MAX，则break，表示已经超出
4、截取到res后，附上op的符号，若res &gt; INT_MAX或者res &lt; INT_MIN则分别返回INF_MAX或者INT_MIN
时间复杂度 O(n)
*/
    //    long res = 0;
    //    while(k&lt;n&amp;&amp;s.charAt(k)&gt;=&#39;0&#39; &amp;&amp; s.charAt(k)&lt;=&#39;9&#39;){
    //         res = res * 10 + s.charAt(k)-&#39;0&#39;;
    //         k++;

    //         if(res&gt;Integer.MAX_VALUE) break;
    //    }
    //    res= res*op;
    //    if(res&gt;Integer.MAX_VALUE) res=Integer.MAX_VALUE;
    //    if(res&lt;Integer.MIN_VALUE) res= Integer.MIN_VALUE;
    //    return (int)res;
/*
算法2
用int记录

1、找到第一个非空的字符位置k，若k == n表示全都是空字符，直接返回0
2、op记录截取后的整数的正负性，1表示正号，-1表示负号
3、使用int类型的res来存储截取后的整数（一定是正整数，因为括号还没包括），
在某一刻若op是正数，(res * 10 + x) * op &gt; INT_MAX，即res * op &gt; (INT_MAX - x ) / 10，则返回INF_MAX，表示已经超出（其中x是正数）
在某一刻若op是负数，(res * 10 + x) * op &lt; INT_MIN，即res * op &gt; (INT_MIN - x * (-1)) / 10，则返回INF_MIN，表示已经超出（其中x是负数）
4、截取到res后，附上op的符号，若res &gt; INT_MAX或者res &lt; INT_MIN则分别返回INF_MAX或者INT_MIN
5、最后返回res
时间复杂度 O(n)
*/
        int res=0;
        while(k&lt;n&amp;&amp;s.charAt(k)&gt;=&#39;0&#39;&amp;&amp;s.charAt(k)&lt;=&#39;9&#39;){
            int x = s.charAt(k)-&#39;0&#39;;
            // if(op&gt;0&amp;&amp;res*op&gt;(Integer.MAX_VALUE-x)/10){
            //     res =  Integer.MAX_VALUE;
            //     break;
            // }
            // if(op&lt;0&amp;&amp;res*op&lt;(Integer.MIN_VALUE-x*(-1))/10){
            //     res = Integer.MIN_VALUE;
            //     break;
            // }
            ////为了防止overflow，需要检测一下数字是否大于计算机可以表达的最大值和最小值
            //num = num * 10 + digt &gt; Integer.MAX_VALUE
            //如果是负数就要检测是否num * 10 + digit &lt; Integer.MIN_VALUE
            if(res&gt;(Integer.MAX_VALUE-x)/10){
                return op==1?Integer.MAX_VALUE:Integer.MIN_VALUE;
            }

            res = res*10+s.charAt(k) - &#39;0&#39;;
            k++;
            // int x = arr[k] - &#39;0&#39;;
            // if (minus &gt; 0 &amp;&amp; res &gt; (Integer.MAX_VALUE - x) / 10) return Integer.MAX_VALUE;
            // if (minus &lt; 0 &amp;&amp; -res &lt; (Integer.MIN_VALUE + x) / 10) return Integer.MIN_VALUE;
            // if (-res * 10 - x == Integer.MIN_VALUE) return Integer.MIN_VALUE;
            // res = res * 10 + x;
            // k++;

        }
        return res*op;
    }
}
// @lc code=end

</code></pre>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-整数反转</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E6%95%B4%E6%95%B0%E5%8F%8D%E8%BD%AC/</url>
    <content><![CDATA[<p>给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。</p>
<p><strong>注意：</strong></p>
<ul>
<li>假设我们的环境只能存储得下 32 位的有符号整数，则其数值范围为 [−231, 231 − 1]。请根据这个假设，如果反转后整数溢出那么就返回 0。</li>
</ul>
<p><strong>示例 1：</strong></p>
<pre><code>输入：x = 123
输出：321</code></pre><p><strong>示例 2：</strong></p>
<pre><code>输入：x = -123
输出：-321</code></pre><p><strong>示例 3：</strong></p>
<pre><code>输入：x = 120
输出：21</code></pre><p><strong>示例 4：</strong></p>
<pre><code>输入：x = 0
输出：0</code></pre><pre><code class="java">
/*
 * @lc app=leetcode.cn id=7 lang=java
 *
 * [7] 整数反转
 */

// @lc code=start
class Solution {
    public int reverse(int x) {
        int res=0;
        while(x!=0){
            //判断溢出
            if(res&gt;0&amp;&amp;res&gt;(Integer.MAX_VALUE-x%10)/10){
                    return 0;            
            }
            if(res&lt;0&amp;&amp;res&lt;(Integer.MIN_VALUE-x%10)/10){
                    return 0 ;                
            }
            res = res*10 + x%10;
            x/=10;
        }

      //  System.out.println(43%10); 4
       // System.out.println(-43%10); -4正负数一样 不需要单独考虑
        return res;

    }
}
// @lc code=end


</code></pre>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-最长回文子串</title>
    <url>/2021/01/11/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[<p>给你一个字符串 <code>s</code>，找到 <code>s</code> 中最长的回文子串。</p>
<p><strong>示例 1：</strong></p>
<pre><code>输入：s = &quot;babad&quot;
输出：&quot;bab&quot;
解释：&quot;aba&quot; 同样是符合题意的答案。</code></pre><p><strong>示例 2：</strong></p>
<pre><code>输入：s = &quot;cbbd&quot;
输出：&quot;bb&quot;</code></pre><p><strong>示例 3：</strong></p>
<pre><code>输入：s = &quot;a&quot;
输出：&quot;a&quot;</code></pre><p><strong>示例 4：</strong></p>
<pre><code>输入：s = &quot;ac&quot;
输出：&quot;a&quot;</code></pre><p><strong>提示：</strong></p>
<ul>
<li><code>1 &lt;= s.length &lt;= 1000</code></li>
<li><code>s</code> 仅由数字和英文字母（大写和/或小写）组成</li>
</ul>
<pre><code class="java">
/*
 * @lc app=leetcode.cn id=5 lang=java
 *
 * [5] 最长回文子串
 */

// @lc code=start
class Solution {
    public String longestPalindrome(String s) {
     //动态规划做法
        //特判
        int len =s.length();
        if(len&lt;2){
            return s;
        }
        int maxLen = 1;
        int begin = 0;

        boolean[][] dp = new boolean[len][len];
        char[] charArray = s.toCharArray();

        for (int i = 0; i &lt; len; i++) {
            dp[i][i]=true;
        }
        for (int j = 1; j &lt; len; j++) {
            for (int i = 0; i &lt;j; i++) {
                if(charArray[i]!=charArray[j]){
                    dp[i][j]=false;
                }else{
                    if(j-i&lt;3){
                        dp[i][j]=true;
                    }else{
                        dp[i][j]=dp[i+1][j-1];
                    }
                }

                if(dp[i][j] &amp;&amp; j-i+1&gt;maxLen){
                    maxLen=j-i+1;
                    begin = i;
                }
            }
        }
        return s.substring(begin, begin+maxLen);

    }
}

</code></pre>
<pre><code class="java">/*
 * @lc app=leetcode.cn id=5 lang=java
 *
 * [5] 最长回文子串
 */

// @lc code=start
class Solution {
    public String longestPalindrome(String s) {

        // //特判
        // int len =s.length();
        // if(len&lt;2){
        //     return s;
        // }
        // int maxLen = 1;
        // int begin = 0;

        // boolean[][] dp = new boolean[len][len];
        // char[] charArray = s.toCharArray();

        // for (int i = 0; i &lt; len; i++) {
        //     dp[i][i]=true;
        // }
        // for (int j = 1; j &lt; len; j++) {
        //     for (int i = 0; i &lt;j; i++) {
        //         if(charArray[i]!=charArray[j]){
        //             dp[i][j]=false;
        //         }else{
        //             if(j-i&lt;3){
        //                 dp[i][j]=true;
        //             }else{
        //                 dp[i][j]=dp[i+1][j-1];
        //             }
        //         }

        //         if(dp[i][j] &amp;&amp; j-i+1&gt;maxLen){
        //             maxLen=j-i+1;
        //             begin = i;
        //         }
        //     }
        // }
        // return s.substring(begin, begin+maxLen);
//从中心扩散的方法
        String res= &quot;&quot;;
        for (int i = 0; i &lt; s.length(); i++) {

          //奇数
            int l = i-1;
            int r = i+1;
            while(l&gt;=0&amp;&amp;r&lt;s.length()&amp;&amp;s.charAt(l)==s.charAt(r)){
                l--;
                r++;
            }
            if(r-l-1&gt;res.length()){
                res=s.substring(l+1, r);
            }

                        //偶数
             l =i;
             r= i+1;
            while(l&gt;=0&amp;&amp;r&lt;s.length()&amp;&amp;s.charAt(l)==s.charAt(r)){
                l--;
                r++;
            }
            if(r-l-1&gt;res.length()){
                res=s.substring(l+1, r);
            }
        }
        return res;

    }
}
// @lc code=end

</code></pre>
<p>参考链接：</p>
<p><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/solution/zhong-xin-kuo-san-dong-tai-gui-hua-by-liweiwei1419/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-palindromic-substring/solution/zhong-xin-kuo-san-dong-tai-gui-hua-by-liweiwei1419/</a></p>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯精选练习题50题-两数相加</title>
    <url>/2021/01/11/FIT5216-Workshop-GraghLabel-PowerGen/%E8%85%BE%E8%AE%AF%E7%B2%BE%E9%80%89%E7%BB%83%E4%B9%A0%E9%A2%9850%E9%A2%98-%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0/</url>
    <content><![CDATA[<pre><code class="java">/*
 * @lc app=leetcode.cn id=2 lang=java
 *
 * [2] 两数相加
 */

// @lc code=start
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
//2-&gt;4-&gt;3 9-&gt;1 结果就是1-&gt;6-&gt;3
class Solution {
    public ListNode addTwoNumbers(ListNode l1, ListNode l2) {
    ListNode l3 = new ListNode(0);//虚拟头节点
    ListNode cur= l3;//当前节点指向l3
    int jin= 0;//进位为0
    while(l1!=null||l2!=null){
        int sum =0;//定义该位上的和
        if(l1!=null){
            sum=sum+l1.val;
            l1=l1.next;
        }//防止999999+999这种位数不同的情况 所以要判断
        if(l2!=null){
            sum+=l2.val;
            l2=l2.next;
        }
        sum += jin;
        cur.next= new ListNode(sum%10);
        cur= cur.next;
        jin = sum/10;
    }
    if(jin!=0){
        cur.next = new ListNode(1);
    }
    return l3.next;

        }

    }
/*这种方法就不需要最后判断最后一位有没有进位了
class Solution {
    public ListNode addTwoNumbers(ListNode l1, ListNode l2) {
        ListNode l3 = new ListNode(0);//虚拟头节点
        ListNode cur = l3;
        int t = 0;//进位
        while(l1!=null||l2!=null||t!=0){
            if(l1!=null) {t+=l1.val;l1=l1.next;}
            if(l2!=null) {t+=l2.val;l2=l2.next;}
            cur.next = new ListNode(t%10);
            cur= cur.next;
           // l1=l1.next;
           // l2=l2.next;
            t/=10;

        }
        return l3.next;
    }
}
*/
// @lc code=end


</code></pre>
]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>腾讯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>(C\C++) auto</title>
    <url>/2020/12/26/C-C-auto/</url>
    <content><![CDATA[<h2 id="auto-before-C-0x"><a href="#auto-before-C-0x" class="headerlink" title="auto before C++0x"></a>auto before C++0x</h2><blockquote>
<p>在C++0x之前，<code>auto</code>关键字的意义与static相对，是指自动存储的，写不写的含义都是一样的，这就导致了<code>auto</code>关键字非常的鸡肋；</p>
<p><strong>PS</strong>: auto关键字原来的含义（表示local变量）是多余而无用的——标准委员会的成员们在数百万行代码中仅仅只找到几百个用到auto关键字的地方，并且大多数出现在测试代码中，有的甚至就是一个bug。</p>
</blockquote>
<h2 id="auto的使用方法"><a href="#auto的使用方法" class="headerlink" title="auto的使用方法"></a>auto的使用方法</h2><blockquote>
<p>C++11 赋予 auto 关键字新的含义，使用它来做自动类型推导。也就是说，使用了 auto 关键字以后，编译器会在编译期间自动推导出变量的类型，这样我们就不用手动指明变量的数据类型了。</p>
<p><strong>NOTE</strong>:<code>auto</code>类型是在<font color="red"><strong><em>编译期间</em></strong></font>由编译器推导的</p>
</blockquote>
<pre><code class="cpp">auto name = value;</code></pre>
<p>例如：</p>
<pre><code class="cpp">auto n = 10;
auto f = 12.8;
auto p = &amp;n;
auto url = &quot;http://c.biancheng.net/cplus/&quot;;</code></pre>
<p>下面我们来解释一下：</p>
<ul>
<li>第 1 行中，10 是一个整数，默认是 int 类型，所以推导出变量 n 的类型是 int。</li>
<li>第 2 行中，12.8 是一个小数，默认是 double 类型，所以推导出变量 f 的类型是 double。</li>
<li>第 3 行中，&amp;n 的结果是一个 int* 类型的指针，所以推导出变量 f 的类型是 int*。</li>
<li>第 4 行中，由双引号<code>&quot;&quot;</code>包围起来的字符串是 const char* 类型，所以推导出变量 url 的类型是 const char*，也即一个常量指针。</li>
</ul>
<p>接下来，我们再来看一下 auto 和 const 的结合：</p>
<pre><code class="cpp">int  x = 0;
const  auto n = x;  //n 为 const int ，auto 被推导为 int
auto f = n;      //f 为 const int，auto 被推导为 int（const 属性被抛弃）
const auto &amp;r1 = x;  //r1 为 const int&amp; 类型，auto 被推导为 int
auto &amp;r2 = r1;  //r1 为 const int&amp; 类型，auto 被推导为 const int 类型</code></pre>
<p>最后我们来简单总结一下 auto 与 const 结合的用法：</p>
<ul>
<li>当类型不为引用时，auto 的推导结果将不保留表达式的 const 属性；</li>
<li>当类型为引用时，auto 的推导结果将保留表达式的 const 属性。</li>
</ul>
<h2 id="auto-的限制"><a href="#auto-的限制" class="headerlink" title="auto 的限制"></a>auto 的限制</h2><p>前面介绍推导规则的时候我们说过，使用 auto 的时候必须对变量进行初始化，这是 auto 的限制之一。那么，除此以外，auto 还有哪些其它的限制呢？</p>
<ol>
<li><p>auto 不能在函数的参数中使用。</p>
<p>这个应该很容易理解，我们在定义函数的时候只是对参数进行了声明，指明了参数的类型，但并没有给它赋值，只有在实际调用函数的时候才会给参数赋值；而 auto 要求必须对变量进行初始化，所以这是矛盾的。</p>
</li>
<li><p>auto 不能作用于类的非静态成员变量（也就是没有 static 关键字修饰的成员变量）中。</p>
</li>
<li><p>auto 关键字不能定义数组，比如下面的例子就是错误的：</p>
<pre><code class="cpp">char url[] = &quot;http://c.biancheng.net/&quot;;
auto  str[] = url;  //arr 为数组，所以不能使用 auto
auto temp = url;  // auto被转化为int*
for(auto item: temp)  // error, because temp is not a array any more.
{
    // ...
}</code></pre>
</li>
</ol>
]]></content>
      <categories>
        <category>C\C++</category>
      </categories>
      <tags>
        <tag>C\C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas教程-Task6</title>
    <url>/2020/04/26/Pandas%E6%95%99%E7%A8%8B-Task6/</url>
    <content><![CDATA[<pre><code class="python">import pandas as pd
import numpy as np
df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/table_missing.csv&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>NaN</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>NaN</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>NaN</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>NaN</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103.0</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>NaN</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81.0</td>
      <td>80.4</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105.0</td>
      <td>NaN</td>
      <td>street_4</td>
      <td>159</td>
      <td>64.0</td>
      <td>84.8</td>
      <td>A-</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="一、缺失观测及其类型"><a href="#一、缺失观测及其类型" class="headerlink" title="一、缺失观测及其类型"></a>一、缺失观测及其类型</h2><pre><code class="python">#1. 了解缺失信息
#（a）isna和notna方法
#对Series使用会返回布尔列表
df[&#39;Physics&#39;].isna().head()</code></pre>
<pre><code>0    False
1    False
2    False
3     True
4    False
Name: Physics, dtype: bool</code></pre><pre><code class="python">df[&#39;Physics&#39;].notna().head()</code></pre>
<pre><code>0     True
1     True
2     True
3    False
4     True
Name: Physics, dtype: bool</code></pre><pre><code class="python">df.isna().head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.isna().sum()</code></pre>
<pre><code>School      0
Class       4
ID          6
Gender      7
Address     0
Height      0
Weight     13
Math        5
Physics     4
dtype: int64</code></pre><pre><code class="python">df.info()</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 35 entries, 0 to 34
Data columns (total 9 columns):
School     35 non-null object
Class      31 non-null object
ID         29 non-null float64
Gender     28 non-null object
Address    35 non-null object
Height     35 non-null int64
Weight     22 non-null float64
Math       30 non-null float64
Physics    31 non-null object
dtypes: float64(3), int64(1), object(5)
memory usage: 2.6+ KB</code></pre><pre><code class="python">df[df[&#39;Physics&#39;].isna()]</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81.0</td>
      <td>80.4</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>S_1</td>
      <td>C_2</td>
      <td>1204.0</td>
      <td>F</td>
      <td>street_5</td>
      <td>162</td>
      <td>63.0</td>
      <td>33.8</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>13</th>
      <td>S_1</td>
      <td>C_3</td>
      <td>1304.0</td>
      <td>NaN</td>
      <td>street_2</td>
      <td>195</td>
      <td>70.0</td>
      <td>85.2</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>22</th>
      <td>S_2</td>
      <td>C_2</td>
      <td>2203.0</td>
      <td>M</td>
      <td>street_4</td>
      <td>155</td>
      <td>91.0</td>
      <td>73.8</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[df.notna().all(1)]</code></pre>
<h2 id="二、缺失数据的运算与分组"><a href="#二、缺失数据的运算与分组" class="headerlink" title="二、缺失数据的运算与分组"></a>二、缺失数据的运算与分组</h2><pre><code class="python">#1. 加号与乘号规则
#使用加法时，缺失值为0
s = pd.Series([2,3,np.nan,4])
s.sum()</code></pre>
<pre><code>9.0</code></pre><pre><code class="python">s.prod()</code></pre>
<pre><code>24.0</code></pre><pre><code class="python">s.cumsum()</code></pre>
<pre><code>0    2.0
1    5.0
2    NaN
3    9.0
dtype: float64</code></pre><pre><code class="python">s.cumprod()</code></pre>
<pre><code>0     2.0
1     6.0
2     NaN
3    24.0
dtype: float64</code></pre><pre><code class="python">s.pct_change()</code></pre>
<pre><code>0         NaN
1    0.500000
2    0.000000
3    0.333333
dtype: float64</code></pre><h2 id="三、填充与剔除"><a href="#三、填充与剔除" class="headerlink" title="三、填充与剔除"></a>三、填充与剔除</h2><pre><code class="python">#1. fillna方法
#（a）值填充与前后向填充（分别与ffill方法和bfill方法等价）
df[&#39;Physics&#39;].fillna(&#39;missing&#39;).head()</code></pre>
<pre><code>0         A+
1         B+
2         B+
3    missing
4         A-
Name: Physics, dtype: object</code></pre><pre><code class="python">df[&#39;Physics&#39;].fillna(method=&#39;ffill&#39;).head()</code></pre>
<pre><code>0    A+
1    B+
2    B+
3    B+
4    A-
Name: Physics, dtype: object</code></pre><pre><code class="python">df[&#39;Physics&#39;].fillna(method=&#39;backfill&#39;).head()</code></pre>
<pre><code>0    A+
1    B+
2    B+
3    A-
4    A-
Name: Physics, dtype: object</code></pre><h2 id="四、插值（interpolation）"><a href="#四、插值（interpolation）" class="headerlink" title="四、插值（interpolation）"></a>四、插值（interpolation）</h2><pre><code class="python">#1. 线性插值
#（a）索引无关的线性插值
#默认状态下，interpolate会对缺失的值进行线性插值¶</code></pre>
<pre><code>0     1.0
1    10.0
2    15.0
3    -5.0
4    -2.0
5     NaN
6     NaN
7    28.0
dtype: float64</code></pre><pre><code class="python">s.interpolate()</code></pre>
<pre><code>0     1.0
1    10.0
2    15.0
3    -5.0
4    -2.0
5     8.0
6    18.0
7    28.0
dtype: float64</code></pre><pre><code class="python">s.index = np.sort(np.random.randint(50,300,8))
s.interpolate()
#值不变</code></pre>
<pre><code>137     1.0
148    10.0
167    15.0
171    -5.0
171    -2.0
283     8.0
290    18.0
299    28.0
dtype: float64</code></pre><pre><code class="python"></code></pre>
]]></content>
      <categories>
        <category>Pandas教程</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas教程-Task5</title>
    <url>/2020/04/26/Pandas%E6%95%99%E7%A8%8B-Task5/</url>
    <content><![CDATA[<pre><code class="python">import numpy as np
import pandas as pd
df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.csv&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="一、append与assign"><a href="#一、append与assign" class="headerlink" title="一、append与assign"></a>一、append与assign</h2><pre><code class="python">#1. append方法
#（a）利用序列添加行（必须指定name）
df_append = df.loc[:3,[&#39;Gender&#39;,&#39;Height&#39;]].copy()
df_append</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>M</td>
      <td>173</td>
    </tr>
    <tr>
      <th>1</th>
      <td>F</td>
      <td>192</td>
    </tr>
    <tr>
      <th>2</th>
      <td>M</td>
      <td>186</td>
    </tr>
    <tr>
      <th>3</th>
      <td>F</td>
      <td>167</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">s = pd.Series({&#39;Gender&#39;:&#39;F&#39;,&#39;Height&#39;:188},name=&#39;new_row&#39;)
df_append.append(s)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>M</td>
      <td>173</td>
    </tr>
    <tr>
      <th>1</th>
      <td>F</td>
      <td>192</td>
    </tr>
    <tr>
      <th>2</th>
      <td>M</td>
      <td>186</td>
    </tr>
    <tr>
      <th>3</th>
      <td>F</td>
      <td>167</td>
    </tr>
    <tr>
      <th>new_row</th>
      <td>F</td>
      <td>188</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#（b）用DataFrame添加表
df_temp = pd.DataFrame({&#39;Gender&#39;:[&#39;F&#39;,&#39;M&#39;],&#39;Height&#39;:[188,176]},index=[&#39;new_1&#39;,&#39;new_2&#39;])
df_append.append(df_temp)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>M</td>
      <td>173</td>
    </tr>
    <tr>
      <th>1</th>
      <td>F</td>
      <td>192</td>
    </tr>
    <tr>
      <th>2</th>
      <td>M</td>
      <td>186</td>
    </tr>
    <tr>
      <th>3</th>
      <td>F</td>
      <td>167</td>
    </tr>
    <tr>
      <th>new_1</th>
      <td>F</td>
      <td>188</td>
    </tr>
    <tr>
      <th>new_2</th>
      <td>M</td>
      <td>176</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#2. assign方法
#该方法主要用于添加列，列名直接由参数指定
s = pd.Series(list(&#39;abcd&#39;),index=range(4))
df_append.assign(Letter=s)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Height</th>
      <th>Letter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>M</td>
      <td>173</td>
      <td>a</td>
    </tr>
    <tr>
      <th>1</th>
      <td>F</td>
      <td>192</td>
      <td>b</td>
    </tr>
    <tr>
      <th>2</th>
      <td>M</td>
      <td>186</td>
      <td>c</td>
    </tr>
    <tr>
      <th>3</th>
      <td>F</td>
      <td>167</td>
      <td>d</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="二、combine与update"><a href="#二、combine与update" class="headerlink" title="二、combine与update"></a>二、combine与update</h2><pre><code class="python">#1. comine方法
#comine和update都是用于表的填充函数，可以根据某种规则填充
df_combine_1 = df.loc[:1,[&#39;Gender&#39;,&#39;Height&#39;]].copy()
df_combine_2 = df.loc[10:11,[&#39;Gender&#39;,&#39;Height&#39;]].copy()
df_combine_1.combine(df_combine_2,lambda x,y:print(x,y))</code></pre>
<pre><code>0       M
1       F
10    NaN
11    NaN
Name: Gender, dtype: object 0     NaN
1     NaN
10      M
11      F
Name: Gender, dtype: object
0     173.0
1     192.0
10      NaN
11      NaN
Name: Height, dtype: float64 0       NaN
1       NaN
10    161.0
11    175.0
Name: Height, dtype: float64</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Gender</th>
      <th>Height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>10</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>11</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#2. update方法
#（a）三个特点
#①返回的框索引只会与被调用框的一致（默认使用左连接，下一节会介绍）
#②第二个框中的nan元素不会起作用
#③没有返回值，直接在df上操作
df1 = pd.DataFrame({&#39;A&#39;: [1, 2, 3],
                    &#39;B&#39;: [400, 500, 600]})
df2 = pd.DataFrame({&#39;B&#39;: [4, 5, 6],
                    &#39;C&#39;: [7, 8, 9]})
df1.update(df2)
df1</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="三、concat方法"><a href="#三、concat方法" class="headerlink" title="三、concat方法"></a>三、concat方法</h2><pre><code class="python">#concat方法可以在两个维度上拼接，默认纵向凭借（axis=0），拼接方式默认外连接
#所谓外连接，就是取拼接方向的并集，而&#39;inner&#39;时取拼接方向（若使用默认的纵向拼接，则为列的交集）的交集
#下面举一些例子说明其参数：
df1 = pd.DataFrame({&#39;A&#39;: [&#39;A0&#39;, &#39;A1&#39;],
                    &#39;B&#39;: [&#39;B0&#39;, &#39;B1&#39;]},
                    index = [0,1])
df2 = pd.DataFrame({&#39;A&#39;: [&#39;A2&#39;, &#39;A3&#39;],
                    &#39;B&#39;: [&#39;B2&#39;, &#39;B3&#39;]},
                    index = [2,3])
df3 = pd.DataFrame({&#39;A&#39;: [&#39;A1&#39;, &#39;A3&#39;],
                    &#39;D&#39;: [&#39;D1&#39;, &#39;D3&#39;],
                    &#39;E&#39;: [&#39;E1&#39;, &#39;E3&#39;]},
                    index = [1,3])</code></pre>
<pre><code class="python">pd.concat([df1,df2])</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A3</td>
      <td>B3</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">pd.concat([df1,df2],axis=1)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>A2</td>
      <td>B2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>A3</td>
      <td>B3</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">pd.concat([df3,df1],join=&#39;inner&#39;)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>A1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A3</td>
    </tr>
    <tr>
      <th>0</th>
      <td>A0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="四、merge与join"><a href="#四、merge与join" class="headerlink" title="四、merge与join"></a>四、merge与join</h2><pre><code class="python">#1. merge函数
#merge函数的作用是将两个pandas对象横向合并，遇到重复的索引项时会使用笛卡尔积，默认inner连接，可选left、outer、right连接
#所谓左连接，就是指以第一个表索引为基准，右边的表中如果不再左边的则不加入，如果在左边的就以笛卡尔积的方式加入
#merge/join与concat的不同之处在于on参数，可以指定某一个对象为key来进行连接
left = pd.DataFrame({&#39;key1&#39;: [&#39;K0&#39;, &#39;K0&#39;, &#39;K1&#39;, &#39;K2&#39;],
                     &#39;key2&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K0&#39;, &#39;K1&#39;],
                      &#39;A&#39;: [&#39;A0&#39;, &#39;A1&#39;, &#39;A2&#39;, &#39;A3&#39;],
                      &#39;B&#39;: [&#39;B0&#39;, &#39;B1&#39;, &#39;B2&#39;, &#39;B3&#39;]}) 
right = pd.DataFrame({&#39;key1&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K1&#39;, &#39;K2&#39;],
                      &#39;key2&#39;: [&#39;K0&#39;, &#39;K0&#39;, &#39;K0&#39;, &#39;K0&#39;],
                      &#39;C&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;],
                      &#39;D&#39;: [&#39;D0&#39;, &#39;D1&#39;, &#39;D2&#39;, &#39;D3&#39;]})
right2 = pd.DataFrame({&#39;key1&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K1&#39;, &#39;K2&#39;],
                      &#39;key2&#39;: [&#39;K0&#39;, &#39;K0&#39;, &#39;K0&#39;, &#39;K0&#39;],
                      &#39;C&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;]})</code></pre>
<pre><code class="python">pd.merge(left, right, on=&#39;key1&#39;)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>key1</th>
      <th>key2_x</th>
      <th>A</th>
      <th>B</th>
      <th>key2_y</th>
      <th>C</th>
      <th>D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>K0</td>
      <td>K0</td>
      <td>A0</td>
      <td>B0</td>
      <td>K0</td>
      <td>C0</td>
      <td>D0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>K0</td>
      <td>K1</td>
      <td>A1</td>
      <td>B1</td>
      <td>K0</td>
      <td>C0</td>
      <td>D0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>K1</td>
      <td>K0</td>
      <td>A2</td>
      <td>B2</td>
      <td>K0</td>
      <td>C1</td>
      <td>D1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>K1</td>
      <td>K0</td>
      <td>A2</td>
      <td>B2</td>
      <td>K0</td>
      <td>C2</td>
      <td>D2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>K2</td>
      <td>K1</td>
      <td>A3</td>
      <td>B3</td>
      <td>K0</td>
      <td>C3</td>
      <td>D3</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#2. join函数
#join函数作用是将多个pandas对象横向拼接，
#遇到重复的索引项时会使用笛卡尔积，默认左连接，可选inner、outer、right连接
left = pd.DataFrame({&#39;A&#39;: [&#39;A0&#39;, &#39;A1&#39;, &#39;A2&#39;],
                     &#39;B&#39;: [&#39;B0&#39;, &#39;B1&#39;, &#39;B2&#39;]},
                    index=[&#39;K0&#39;, &#39;K1&#39;, &#39;K2&#39;])
right = pd.DataFrame({&#39;C&#39;: [&#39;C0&#39;, &#39;C2&#39;, &#39;C3&#39;],
                      &#39;D&#39;: [&#39;D0&#39;, &#39;D2&#39;, &#39;D3&#39;]},
                    index=[&#39;K0&#39;, &#39;K2&#39;, &#39;K3&#39;])
left.join(right)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>K0</th>
      <td>A0</td>
      <td>B0</td>
      <td>C0</td>
      <td>D0</td>
    </tr>
    <tr>
      <th>K1</th>
      <td>A1</td>
      <td>B1</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>K2</th>
      <td>A2</td>
      <td>B2</td>
      <td>C2</td>
      <td>D2</td>
    </tr>
  </tbody>
</table>
</div>


]]></content>
      <categories>
        <category>Pandas教程</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas教程-Task4</title>
    <url>/2020/04/26/Pandas%E6%95%99%E7%A8%8B-Task4/</url>
    <content><![CDATA[<p>第4章 变形</p>
<pre><code class="python">import numpy as np
import pandas as pd
df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.csv&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#1. pivot¶
#一般状态下，数据在DataFrame会以压缩（stacked）状态存放，例如上面的Gender，
#两个类别被叠在一列中，pivot函数可将某一列作为新的cols
df.pivot(index=&#39;ID&#39;,columns=&#39;Gender&#39;,values=&#39;Height&#39;).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>F</th>
      <th>M</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1101</th>
      <td>NaN</td>
      <td>173.0</td>
    </tr>
    <tr>
      <th>1102</th>
      <td>192.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>NaN</td>
      <td>186.0</td>
    </tr>
    <tr>
      <th>1104</th>
      <td>167.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1105</th>
      <td>159.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#2. pivot_table
#由于功能更多，速度上自然是比不上原来的pivot函数
%timeit df.pivot(index=&#39;ID&#39;,columns=&#39;Gender&#39;,values=&#39;Height&#39;)
%timeit pd.pivot_table(df,index=&#39;ID&#39;,columns=&#39;Gender&#39;,values=&#39;Height&#39;)</code></pre>
<pre><code>3.15 ms ± 336 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
14 ms ± 663 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</code></pre><pre><code class="python">#3. crosstab（交叉表）
#交叉表是一种特殊的透视表，典型的用途如分组统计，如现在想要统计关于街道和性别分组的频数：¶
pd.crosstab(index=df[&#39;Address&#39;],columns=df[&#39;Gender&#39;])</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>F</th>
      <th>M</th>
    </tr>
    <tr>
      <th>Address</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>street_1</th>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>street_2</th>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <th>street_4</th>
      <td>3</td>
      <td>5</td>
    </tr>
    <tr>
      <th>street_5</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>street_6</th>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>street_7</th>
      <td>3</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#其他变形方法
#1. melt
#melt函数可以认为是pivot函数的逆操作，将unstacked状态的数据，压缩成stacked，使“宽”的DataFrame变“窄”
df_m = df[[&#39;ID&#39;,&#39;Gender&#39;,&#39;Math&#39;]]
df_m.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Gender</th>
      <th>Math</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1101</td>
      <td>M</td>
      <td>34.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1102</td>
      <td>F</td>
      <td>32.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1103</td>
      <td>M</td>
      <td>87.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1104</td>
      <td>F</td>
      <td>80.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1105</td>
      <td>F</td>
      <td>84.8</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.pivot(index=&#39;ID&#39;,columns=&#39;Gender&#39;,values=&#39;Math&#39;).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Gender</th>
      <th>F</th>
      <th>M</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1101</th>
      <td>NaN</td>
      <td>34.0</td>
    </tr>
    <tr>
      <th>1102</th>
      <td>32.5</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>NaN</td>
      <td>87.2</td>
    </tr>
    <tr>
      <th>1104</th>
      <td>80.4</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1105</th>
      <td>84.8</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">pivoted = df.pivot(index=&#39;ID&#39;,columns=&#39;Gender&#39;,values=&#39;Math&#39;)
result = pivoted.reset_index().melt(id_vars=[&#39;ID&#39;],value_vars=[&#39;F&#39;,&#39;M&#39;],value_name=&#39;Math&#39;)\
                     .dropna().set_index(&#39;ID&#39;).sort_index()
#检验是否与展开前的df相同，可以分别将这些链式方法的中间步骤展开，看看是什么结果
result.equals(df_m.set_index(&#39;ID&#39;))</code></pre>
<pre><code>True</code></pre><pre><code class="python">#哑变量与因子化
#1. Dummy Variable（哑变量）
#这里主要介绍get_dummies函数，其功能主要是进行one-hot编码
df_d = df[[&#39;Class&#39;,&#39;Gender&#39;,&#39;Weight&#39;]]
df_d.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Class</th>
      <th>Gender</th>
      <th>Weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>C_1</td>
      <td>M</td>
      <td>63</td>
    </tr>
    <tr>
      <th>1</th>
      <td>C_1</td>
      <td>F</td>
      <td>73</td>
    </tr>
    <tr>
      <th>2</th>
      <td>C_1</td>
      <td>M</td>
      <td>82</td>
    </tr>
    <tr>
      <th>3</th>
      <td>C_1</td>
      <td>F</td>
      <td>81</td>
    </tr>
    <tr>
      <th>4</th>
      <td>C_1</td>
      <td>F</td>
      <td>64</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">pd.get_dummies(df_d[[&#39;Class&#39;,&#39;Gender&#39;]]).join(df_d[&#39;Weight&#39;]).head()
#可选prefix参数添加前缀，prefix_sep添加分隔符</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Class_C_1</th>
      <th>Class_C_2</th>
      <th>Class_C_3</th>
      <th>Class_C_4</th>
      <th>Gender_F</th>
      <th>Gender_M</th>
      <th>Weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>63</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>73</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>82</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>81</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>64</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">#2. factorize方法
#该方法主要用于自然数编码，并且缺失值会被记做-1，其中sort参数表示是否排序后赋值
codes, uniques = pd.factorize([&#39;b&#39;, None, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;], sort=True)
display(codes)
display(uniques)</code></pre>
<pre><code>array([ 1, -1,  0,  2,  1])



array([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], dtype=object)</code></pre>]]></content>
      <categories>
        <category>Pandas教程</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫编程实践-Task4</title>
    <url>/2020/04/26/Python%E7%88%AC%E8%99%AB%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5-Task4/</url>
    <content><![CDATA[<ol>
<li>了解ajax加载</li>
<li>通过chrome的开发者工具，监控网络请求，并分析</li>
<li>用selenium完成爬虫</li>
</ol>
<pre><code class="python">import time
from  selenium import webdriver
driver=webdriver.Chrome(executable_path=&quot;D:\chromedriver\chromedriver.exe&quot;)
driver.get(&quot;https://news.qq.com&quot;)
#了解ajax加载
for i in range(1,100):
    time.sleep(2)
    driver.execute_script(&quot;window.scrollTo(window.scrollX, %d);&quot;%(i*200))</code></pre>
<pre><code class="python">from bs4 import BeautifulSoup
html=driver.page_source
bsObj=BeautifulSoup(html,&quot;lxml&quot;)</code></pre>
<pre><code class="python">jxtits=bsObj.find_all(&quot;div&quot;,{&quot;class&quot;:&quot;jx-tit&quot;})[0].find_next_sibling().find_all(&quot;li&quot;)</code></pre>
<pre><code class="python">print(&quot;index&quot;,&quot;,&quot;,&quot;title&quot;,&quot;,&quot;,&quot;url&quot;)
for i,jxtit in enumerate(jxtits):
#     print(jxtit)

    try:
        text=jxtit.find_all(&quot;img&quot;)[0][&quot;alt&quot;]
    except:
        text=jxtit.find_all(&quot;div&quot;,{&quot;class&quot;:&quot;lazyload-placeholder&quot;})[0].text
    try:
        url=jxtit.find_all(&quot;a&quot;)[0][&quot;href&quot;]
    except:
        print(jxtit)
    print(i+1,&quot;,&quot;,text,&quot;,&quot;,url) </code></pre>
<p>进阶加餐-知乎爬虫</p>
<p>链接如下<br><a href="https://www.zhihu.com/search?q=Datawhale&amp;utm_content=search_history&amp;type=content" target="_blank" rel="noopener">https://www.zhihu.com/search?q=Datawhale&amp;utm_content=search_history&amp;type=content</a><br>用requests库实现，不能用selenium网页自动化</p>
<p>提示：<br>该链接需要登录，可通过github等，搜索知乎登录的代码实现，并理解其中的逻辑，此任务允许复制粘贴代码<br>与上面ajax加载类似，这次的ajax加载需要用requests完成爬取，最终存储样式随意，但是通过Chrome的开发者工具，分析出ajax的流程需要写出来</p>
<pre><code class="python">import requests
from http import cookiejar
Session=requests.session()
Session.cookies = cookiejar.LWPCookieJar(filename=&#39;./cookies.txt&#39;)
Session.cookies.load(ignore_discard=True)
Session.headers={
            &#39;Host&#39;: &#39;www.zhihu.com&#39;,
            &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 &#39;
                          &#39;(KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36&#39;
        }
r=Session.get(&quot;https://www.zhihu.com/search?q=Datawhale&amp;utm_content=search_history&amp;type=content&quot;)
r.encoding=&quot;utf-8&quot;</code></pre>
<pre><code class="python">from bs4 import BeautifulSoup
import re
compiler=re.compile(&#39;&quot;next&quot;:&quot;(https:\\\\u002F\\\\u002Fapi.zhihu.com\\\\u002Fsearch_v3.*?)&quot;&#39;)
r.text</code></pre>
<pre><code class="python">bsObj=BeautifulSoup(r.text,&quot;lxml&quot;)
url=compiler.findall(r.text)[0]</code></pre>
<pre><code class="python">from urllib.parse import unquote
url=unquote(url,encoding=&quot;utf-8&quot;, errors=&#39;replace&#39;)
url=url.replace(&quot;\\u002F&quot;,&quot;/&quot;)
search_hash_id=re.search(&quot;search_hash_id=(.*?)&amp;show_all_topics&quot;,url).group(1)
search_hash_id</code></pre>
<pre><code class="python">offset=20
lc_idx=21
for i in range(5):
    r=Session.get(&quot;https://www.zhihu.com/api/v4/search_v3?t=general&amp;q=Datawhale&amp;correction=1&amp;offset={offset}&amp;limit=20&amp;lc_idx={lc_idx}&amp;show_all_topics=0&amp;search_hash_id={search_hash_id}&amp;vertical_info=0%2C0%2C1%2C0%2C0%2C0%2C0%2C0%2C0%2C0&quot;.format(**{&quot;offset&quot;:offset+i*20,&quot;lc_idx&quot;:lc_idx+i*20,&quot;search_hash_id&quot;:search_hash_id}))
    r.encoding=&quot;utf-8&quot;
    print(r.json())
    print(&quot;\n&quot;*20)</code></pre>
]]></content>
      <categories>
        <category>Python爬虫编程实践</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫编程实践-Task3</title>
    <url>/2020/04/25/Python%E7%88%AC%E8%99%AB%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5-Task3/</url>
    <content><![CDATA[<h2 id="session和cookie"><a href="#session和cookie" class="headerlink" title="session和cookie"></a>session和cookie</h2><p>Session 是会话的意思，会话是产生在服务端的，用来保存当前用户的会话信息，而 Cookies 是保存在客户端（浏览器），有了 Cookie 以后，客户端（浏览器）再次访问服务端的时候，会将这个 Cookie 带上，这时，服务端可以通过 Cookie 来识别本次请求到底是谁在访问。</p>
<a id="more"></a>
<p>可以简单理解为 Cookies 中保存了登录凭证，我们只要持有这个凭证，就可以在服务端保持一个登录状态。</p>
<p>在爬虫中，有时候遇到需要登录才能访问的网页，只需要在登录后获取了 Cookies ，在下次访问的时候将登录后获取到的 Cookies 放在请求头中，这时，服务端就会认为我们的爬虫是一个正常登录用户。</p>
<p>一个重要概念：</p>
<p>当我们关闭浏览器的时候会自动销毁服务端的会话，这个是错误的，因为在关闭浏览器的时候，浏览器并不会额外的通知服务端说，我要关闭了，你把和我的会话销毁掉吧。</p>
<p>因为服务端的会话是保存在内存中的，虽然一个会话不会很大，但是架不住会话多啊，硬件毕竟是会有限制的，不能无限扩充下去的，所以在服务端设置会话的过期时间就非常有必要。</p>
<p>当然，有没有方式能让浏览器在关闭的时候同步的关闭服务端的会话，当然是可以的，我们可以通过脚本语言 JS 来监听浏览器关闭的动作，当浏览器触发关闭动作的时候，由 JS 像服务端发起一个请求来通知服务端销毁会话。</p>
<p>由于不同的浏览器对 JS 事件的实现机制不一致，不一定保证 JS 能监听到浏览器关闭的动作，所以现在常用的方式还是在服务端自己设置会话的过期时间</p>
<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>如何应对IP被封的问题</p>
<p>有几种套路：</p>
<ol>
<li>修改请求头，模拟浏览器（而不是代码去直接访问）去访问</li>
<li>采用代理IP并轮换</li>
<li>设置访问时间间隔</li>
</ol>
<pre><code class="python">import requests
import re
import json


def open_proxy_url(url):
    user_agent = &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36&#39;
    headers = {&#39;User-Agent&#39;: user_agent}
    try:
        r = requests.get(url, headers = headers, timeout = 10)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        print(&#39;无法访问网页&#39; + url)


def get_proxy_ip(response):
    proxy_ip_list = []
    soup = BeautifulSoup(response, &#39;html.parser&#39;)
    proxy_ips = soup.find(id = &#39;ip_list&#39;).find_all(&#39;tr&#39;)
    for proxy_ip in proxy_ips:
        if len(proxy_ip.select(&#39;td&#39;)) &gt;=8:
            ip = proxy_ip.select(&#39;td&#39;)[1].text
            port = proxy_ip.select(&#39;td&#39;)[2].text
            protocol = proxy_ip.select(&#39;td&#39;)[5].text
            if protocol in (&#39;HTTP&#39;,&#39;HTTPS&#39;,&#39;http&#39;,&#39;https&#39;):
                proxy_ip_list.append(f&#39;{protocol}://{ip}:{port}&#39;)
    return proxy_ip_list


def open_url_using_proxy(url, proxy):
    user_agent = &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36&#39;
    headers = {&#39;User-Agent&#39;: user_agent}
    proxies = {}
    if proxy.startswith((&#39;HTTPS&#39;,&#39;https&#39;)):
        proxies[&#39;https&#39;] = proxy
    else:
        proxies[&#39;http&#39;] = proxy

    try:
        r = requests.get(url, headers = headers, proxies = proxies, timeout = 10)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return (r.text, r.status_code)
    except:
        print(&#39;无法访问网页&#39; + url)
        print(&#39;无效代理IP: &#39; + proxy)
        return False


def check_proxy_avaliability(proxy):
    url = &#39;http://www.baidu.com&#39;
    result = open_url_using_proxy(url, proxy)
    VALID_PROXY = False
    if result:
        text, status_code = result
        if status_code == 200:
            r_title = re.findall(&#39;&lt;title&gt;.*&lt;/title&gt;&#39;, text)
            if r_title:
                if r_title[0] == &#39;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&#39;:
                    VALID_PROXY = True
        if VALID_PROXY:
            check_ip_url = &#39;https://jsonip.com/&#39;
            try:
                text, status_code = open_url_using_proxy(check_ip_url, proxy)
            except:
                return

            print(&#39;有效代理IP: &#39; + proxy)
            with open(&#39;valid_proxy_ip.txt&#39;,&#39;a&#39;) as f:
                f.writelines(proxy)
            try:
                source_ip = json.loads(text).get(&#39;ip&#39;)
                print(f&#39;源IP地址为：{source_ip}&#39;)
                print(&#39;=&#39;*40)
            except:
                print(&#39;返回的非json,无法解析&#39;)
                print(text)
    else:
        print(&#39;无效代理IP: &#39; + proxy)


if __name__ == &#39;__main__&#39;:
    proxy_url = &#39;https://www.xicidaili.com/&#39;
    proxy_ip_filename = &#39;proxy_ip.txt&#39;
    text = open(proxy_ip_filename, &#39;r&#39;).read()
    proxy_ip_list = get_proxy_ip(text)
    for proxy in proxy_ip_list:
        check_proxy_avaliability(proxy)</code></pre>
<h2 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h2><p>selenium是什么：一个自动化测试工具（大家都是这么说的）</p>
<p>selenium应用场景：用代码的方式去模拟浏览器操作过程（如：打开浏览器、在输入框里输入文字、回车等），在爬虫方面很有必要</p>
<p>准备工作：</p>
<ol>
<li>安装selenium（pip install selenium）</li>
<li>安装chromedriver（一个驱动程序，用以启动chrome浏览器，具体的驱动程序需要对应的驱动，在官网上可以找到下载地址） 基本步骤：</li>
</ol>
<pre><code class="python">from selenium import webdriver  # 启动浏览器需要用到
from selenium.webdriver.common.keys import Keys</code></pre>
<pre><code class="python">driver = webdriver.Chrome(&quot;chromedriver驱动程序路径&quot;)</code></pre>
<pre><code class="python">driver.get(&quot;http://www.python.org&quot;)</code></pre>
<pre><code class="python">driver.close()  # 关闭浏览器一个Tab
# or
driver.quit()  # 关闭浏览器窗口</code></pre>
]]></content>
      <categories>
        <category>Python爬虫编程实践</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas教程-Task3</title>
    <url>/2020/04/25/Pandas%E6%95%99%E7%A8%8B-Task3/</url>
    <content><![CDATA[<pre><code class="python">import numpy as np
import pandas as pd
df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.csv&#39;,index_col=&#39;ID&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1101</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1102</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1104</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>1105</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="一、SAC过程"><a href="#一、SAC过程" class="headerlink" title="一、SAC过程"></a>一、SAC过程</h2><h3 id="1-内涵"><a href="#1-内涵" class="headerlink" title="1. 内涵"></a>1. 内涵</h3><p>SAC指的是分组操作中的split-apply-combine过程<br>其中split指基于某一些规则，将数据拆成若干组，apply是指对每一组独立地使用函数，combine指将每一组的结果组合成某一类数据结构</p>
<h3 id="2-apply过程"><a href="#2-apply过程" class="headerlink" title="2. apply过程"></a>2. apply过程</h3><p>在该过程中，我们实际往往会遇到四类问题：<br>整合（Aggregation）——即分组计算统计量（如求均值、求每组元素个数）<br>变换（Transformation）——即分组对每个单元的数据进行操作（如元素标准化）<br>过滤（Filtration）——即按照某些规则筛选出一些组（如选出组内某一指标小于50的组）<br>综合问题——即前面提及的三种问题的混合</p>
<h2 id="二、groupby函数"><a href="#二、groupby函数" class="headerlink" title="二、groupby函数"></a>二、groupby函数</h2><pre><code class="python">grouped_single = df.groupby(&#39;School&#39;)</code></pre>
<pre><code class="python">grouped_single.get_group(&#39;S_1&#39;).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1101</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1102</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1104</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>1105</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">grouped_mul = df.groupby([&#39;School&#39;,&#39;Class&#39;])
grouped_mul.get_group((&#39;S_2&#39;,&#39;C_4&#39;))</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2401</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>62</td>
      <td>45.3</td>
      <td>A</td>
    </tr>
    <tr>
      <th>2402</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>M</td>
      <td>street_7</td>
      <td>166</td>
      <td>82</td>
      <td>48.7</td>
      <td>B</td>
    </tr>
    <tr>
      <th>2403</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>F</td>
      <td>street_6</td>
      <td>158</td>
      <td>60</td>
      <td>59.7</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2404</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>F</td>
      <td>street_2</td>
      <td>160</td>
      <td>84</td>
      <td>67.7</td>
      <td>B</td>
    </tr>
    <tr>
      <th>2405</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>F</td>
      <td>street_6</td>
      <td>193</td>
      <td>54</td>
      <td>47.6</td>
      <td>B</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">grouped_single.size()</code></pre>
<pre><code>School
S_1    15
S_2    20
dtype: int64</code></pre><pre><code class="python">grouped_mul.size()</code></pre>
<pre><code>School  Class
S_1     C_1      5
        C_2      5
        C_3      5
S_2     C_1      5
        C_2      5
        C_3      5
        C_4      5
dtype: int64</code></pre><pre><code class="python">grouped_single.ngroups</code></pre>
<pre><code>2</code></pre><pre><code class="python">grouped_mul.ngroups
</code></pre>
<pre><code>7</code></pre><pre><code class="python">for name,group in grouped_single:
    print(name)
    display(group.head())</code></pre>
<pre><code>S_1</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1101</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1102</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1104</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>1105</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>


<pre><code>S_2</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2101</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_7</td>
      <td>174</td>
      <td>84</td>
      <td>83.3</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2102</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_6</td>
      <td>161</td>
      <td>61</td>
      <td>50.6</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2103</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_4</td>
      <td>157</td>
      <td>61</td>
      <td>52.5</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>2104</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_5</td>
      <td>159</td>
      <td>97</td>
      <td>72.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2105</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_4</td>
      <td>170</td>
      <td>81</td>
      <td>34.2</td>
      <td>A</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code class="python">df.set_index([&#39;Gender&#39;,&#39;School&#39;]).groupby(level=1,axis=0).get_group(&#39;S_1&#39;).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Class</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>Gender</th>
      <th>School</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>M</th>
      <th>S_1</th>
      <td>C_1</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>F</th>
      <th>S_1</th>
      <td>C_1</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>M</th>
      <th>S_1</th>
      <td>C_1</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">F</th>
      <th>S_1</th>
      <td>C_1</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>S_1</th>
      <td>C_1</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">print([attr for attr in dir(grouped_single) if not attr.startswith(&#39;_&#39;)])</code></pre>
<pre><code>[&#39;Address&#39;, &#39;Class&#39;, &#39;Gender&#39;, &#39;Height&#39;, &#39;Math&#39;, &#39;Physics&#39;, &#39;School&#39;, &#39;Weight&#39;, &#39;agg&#39;, &#39;aggregate&#39;, &#39;all&#39;, &#39;any&#39;, &#39;apply&#39;, &#39;backfill&#39;, &#39;bfill&#39;, &#39;boxplot&#39;, &#39;corr&#39;, &#39;corrwith&#39;, &#39;count&#39;, &#39;cov&#39;, &#39;cumcount&#39;, &#39;cummax&#39;, &#39;cummin&#39;, &#39;cumprod&#39;, &#39;cumsum&#39;, &#39;describe&#39;, &#39;diff&#39;, &#39;dtypes&#39;, &#39;expanding&#39;, &#39;ffill&#39;, &#39;fillna&#39;, &#39;filter&#39;, &#39;first&#39;, &#39;get_group&#39;, &#39;groups&#39;, &#39;head&#39;, &#39;hist&#39;, &#39;idxmax&#39;, &#39;idxmin&#39;, &#39;indices&#39;, &#39;last&#39;, &#39;mad&#39;, &#39;max&#39;, &#39;mean&#39;, &#39;median&#39;, &#39;min&#39;, &#39;ndim&#39;, &#39;ngroup&#39;, &#39;ngroups&#39;, &#39;nth&#39;, &#39;nunique&#39;, &#39;ohlc&#39;, &#39;pad&#39;, &#39;pct_change&#39;, &#39;pipe&#39;, &#39;plot&#39;, &#39;prod&#39;, &#39;quantile&#39;, &#39;rank&#39;, &#39;resample&#39;, &#39;rolling&#39;, &#39;sem&#39;, &#39;shift&#39;, &#39;size&#39;, &#39;skew&#39;, &#39;std&#39;, &#39;sum&#39;, &#39;tail&#39;, &#39;take&#39;, &#39;transform&#39;, &#39;tshift&#39;, &#39;var&#39;]</code></pre><pre><code class="python">grouped_single.head(2)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1101</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1102</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2101</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_7</td>
      <td>174</td>
      <td>84</td>
      <td>83.3</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2102</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_6</td>
      <td>161</td>
      <td>61</td>
      <td>50.6</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">grouped_single.first()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>School</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>S_1</th>
      <td>C_1</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>S_2</th>
      <td>C_1</td>
      <td>M</td>
      <td>street_7</td>
      <td>174</td>
      <td>84</td>
      <td>83.3</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.groupby(np.random.choice([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;],df.shape[0])).get_group(&#39;a&#39;).head()
#相当于将np.random.choice([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;],df.shape[0])当做新的一列进行分组</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1103</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1104</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>1202</th>
      <td>S_1</td>
      <td>C_2</td>
      <td>F</td>
      <td>street_4</td>
      <td>176</td>
      <td>94</td>
      <td>63.5</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>1301</th>
      <td>S_1</td>
      <td>C_3</td>
      <td>M</td>
      <td>street_4</td>
      <td>161</td>
      <td>68</td>
      <td>31.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2101</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_7</td>
      <td>174</td>
      <td>84</td>
      <td>83.3</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[:5].groupby(lambda x:print(x)).head(0)</code></pre>
<pre><code>1101
1102
1103
1104
1105</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




<pre><code class="python">df.groupby(lambda x:&#39;奇数行&#39; if not df.index.get_loc(x)%2==1 else &#39;偶数行&#39;).groups</code></pre>
<pre><code>{&#39;偶数行&#39;: Int64Index([1102, 1104, 1201, 1203, 1205, 1302, 1304, 2101, 2103, 2105, 2202,
             2204, 2301, 2303, 2305, 2402, 2404],
            dtype=&#39;int64&#39;, name=&#39;ID&#39;),
 &#39;奇数行&#39;: Int64Index([1101, 1103, 1105, 1202, 1204, 1301, 1303, 1305, 2102, 2104, 2201,
             2203, 2205, 2302, 2304, 2401, 2403, 2405],
            dtype=&#39;int64&#39;, name=&#39;ID&#39;)}</code></pre><pre><code class="python">math_score = df.set_index([&#39;Gender&#39;,&#39;School&#39;])[&#39;Math&#39;].sort_index()
grouped_score = df.set_index([&#39;Gender&#39;,&#39;School&#39;]).sort_index().\
            groupby(lambda x:(x,&#39;均分及格&#39; if math_score[x].mean()&gt;=60 else &#39;均分不及格&#39;))
for name,_ in grouped_score:print(name)</code></pre>
<pre><code>((&#39;F&#39;, &#39;S_1&#39;), &#39;均分及格&#39;)
((&#39;F&#39;, &#39;S_2&#39;), &#39;均分及格&#39;)
((&#39;M&#39;, &#39;S_1&#39;), &#39;均分及格&#39;)
((&#39;M&#39;, &#39;S_2&#39;), &#39;均分不及格&#39;)</code></pre><h2 id="三、聚合、过滤和变换"><a href="#三、聚合、过滤和变换" class="headerlink" title="三、聚合、过滤和变换"></a>三、聚合、过滤和变换</h2><h3 id="1-聚合（Aggregation）"><a href="#1-聚合（Aggregation）" class="headerlink" title="1. 聚合（Aggregation）"></a>1. 聚合（Aggregation）</h3><p>所谓聚合就是把一堆数，变成一个标量，因此mean/sum/size/count/std/var/sem/describe/first/last/nth/min/max都是聚合函数</p>
<h3 id="2-过滤（Filteration）"><a href="#2-过滤（Filteration）" class="headerlink" title="2. 过滤（Filteration）"></a>2. 过滤（Filteration）</h3><p>filter函数是用来筛选某些组的（务必记住结果是组的全体），因此传入的值应当是布尔标量</p>
<h3 id="3-变换（Transformation）"><a href="#3-变换（Transformation）" class="headerlink" title="3. 变换（Transformation）"></a>3. 变换（Transformation）</h3>]]></content>
      <categories>
        <category>Pandas教程</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫编程实践-Task2</title>
    <url>/2020/04/23/Python%E7%88%AC%E8%99%AB%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5-Task2/</url>
    <content><![CDATA[<h2 id="Beautiful-Soup库入门"><a href="#Beautiful-Soup库入门" class="headerlink" title="Beautiful Soup库入门"></a>Beautiful Soup库入门</h2><ol>
<li><p>学习beautifulsoup基础知识。</p>
</li>
<li><p>使用beautifulsoup解析HTML页面。</p>
</li>
</ol>
<p>Beautiful Soup 是一个HTML/XML 的解析器，主要用于解析和提取 HTML/XML 数据。<br>它基于HTML DOM 的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多，所以性能要低于lxml。</p>
<p>BeautifulSoup 用来解析 HTML 比较简单，API非常人性化，支持CSS选择器、Python标准库中的HTML解析器，也支持 lxml 的 XML解析器。</p>
<p>虽然说BeautifulSoup4 简单容易比较上手，但是匹配效率还是远远不如正则以及xpath的，一般不推荐使用，推荐正则的使用。</p>
<p>第一步：pip install beautifulsoup4 ，万事开头难，先安装 beautifulsoup4，安装成功后就完成了第一步。</p>
<p>第二步：导入from bs4 import BeautifulSoup</p>
<p>第三步：创建 Beautiful Soup对象   soup = BeautifulSoup(html，’html.parser’) </p>
<h2 id="学习xpath"><a href="#学习xpath" class="headerlink" title="学习xpath"></a>学习xpath</h2><ol>
<li>学习目标：<br>学习xpath，使用lxml+xpath提取内容。</li>
</ol>
<p>使用xpath提取丁香园论坛的回复内容。</p>
<p>抓取丁香园网页：<a href="http://www.dxy.cn/bbs/thread/626626#626626" target="_blank" rel="noopener">http://www.dxy.cn/bbs/thread/626626#626626</a> 。<br>2. Xpath常用的路径表达式：<br>XPath即为XML路径语言（XML Path Language），它是一种用来确定XML文档中某部分位置的语言。<br>在XPath中，有七种类型的节点：元素、属性、文本、命名空间、处理指令、注释以及文档（根）节点。<br>XML文档是被作为节点树来对待的。<br>XPath使用路径表达式在XML文档中选取节点。节点是通过沿着路径选取的。</p>
<ol start="3">
<li>使用lxml解析</li>
<li>实战：爬取丁香园-用户名和回复内容</li>
</ol>
<pre><code class="python"># 导入库
from lxml import etree
import requests

url = &quot;http://www.dxy.cn/bbs/thread/626626#626626&quot;</code></pre>
<pre><code class="python">req = requests.get(url)
html = req.text
# html</code></pre>
<pre><code class="python">tree = etree.HTML(html) 
tree</code></pre>
<pre><code>&lt;Element html at 0x110f226e0&gt;</code></pre><pre><code class="python">user = tree.xpath(&#39;&#39;)
# print(user)
content = tree.xpath(&#39;&#39;)</code></pre>
<pre><code class="python">results = []
for i in range(0, len(user)):
    # print(user[i].strip()+&quot;:&quot;+content[i].xpath(&#39;string(.)&#39;).strip())
    # print(&quot;*&quot;*80)
    # 因为回复内容中有换行等标签，所以需要用string()来获取数据
    results.append(user[i].strip() + &quot;:  &quot; + content[i].xpath(&#39;string(.)&#39;).strip())</code></pre>
<pre><code class="python"># 打印爬取的结果
for i,result in zip(range(0, len(user)),results):
    print(&quot;user&quot;+ str(i+1) + &quot;-&quot; + result)
    print(&quot;*&quot;*100)</code></pre>
<h2 id="学习正则表达式-re"><a href="#学习正则表达式-re" class="headerlink" title="学习正则表达式 re"></a>学习正则表达式 re</h2><p>re库的主要功能函数：</p>
<p>re.search() 在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象<br>re.search(pattern, string, flags=0)</p>
<p>re.match() 从一个字符串的开始位置起匹配正则表达式，返回match对象<br>re.match(pattern, string, flags=0)</p>
<p>re.findall() 搜索字符串，以列表类型返回全部能匹配的子串<br>re.findall(pattern, string, flags=0)</p>
<p>re.split() 将一个字符串按照正则表达式匹配结果进行分割，返回列表类型<br>re.split(pattern, string, maxsplit=0, flags=0)</p>
<p>re.finditer() 搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象<br>re.finditer(pattern, string, flags=0)</p>
<p>re.sub() 在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</p>
]]></content>
      <categories>
        <category>Python爬虫编程实践</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas教程-Task2</title>
    <url>/2020/04/23/Pandas%E6%95%99%E7%A8%8B-Task2/</url>
    <content><![CDATA[<pre><code class="python">import numpy as np
import pandas as pd
df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.csv&#39;,index_col=&#39;ID&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1101</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1102</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>1104</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>1105</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="单级索引"><a href="#单级索引" class="headerlink" title="单级索引"></a>单级索引</h2><h3 id="loc方法、iloc方法、-操作符"><a href="#loc方法、iloc方法、-操作符" class="headerlink" title="loc方法、iloc方法、[]操作符"></a>loc方法、iloc方法、[]操作符</h3><p>最常用的索引方法可能就是这三类，其中iloc表示位置索引，loc表示标签索引，[]也具有很大的便利性，各有特点</p>
<h3 id="布尔索引"><a href="#布尔索引" class="headerlink" title="布尔索引"></a>布尔索引</h3><h3 id="快速标量索引"><a href="#快速标量索引" class="headerlink" title="快速标量索引"></a>快速标量索引</h3><h3 id="区间索引"><a href="#区间索引" class="headerlink" title="区间索引"></a>区间索引</h3><h2 id="多级索引"><a href="#多级索引" class="headerlink" title="多级索引"></a>多级索引</h2><p>1.创建多级索引<br>（a）通过from_tuple或from_arrays</p>
<pre><code class="python">tuples = [(&#39;A&#39;,&#39;a&#39;),(&#39;A&#39;,&#39;b&#39;),(&#39;B&#39;,&#39;a&#39;),(&#39;B&#39;,&#39;b&#39;)]
mul_index = pd.MultiIndex.from_tuples(tuples, names=(&#39;Upper&#39;, &#39;Lower&#39;))
mul_index</code></pre>
<pre><code>MultiIndex([(&#39;A&#39;, &#39;a&#39;),
            (&#39;A&#39;, &#39;b&#39;),
            (&#39;B&#39;, &#39;a&#39;),
            (&#39;B&#39;, &#39;b&#39;)],
           names=[&#39;Upper&#39;, &#39;Lower&#39;])</code></pre><pre><code class="python">pd.DataFrame({&#39;Score&#39;:[&#39;perfect&#39;,&#39;good&#39;,&#39;fair&#39;,&#39;bad&#39;]},index=mul_index)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Score</th>
    </tr>
    <tr>
      <th>Upper</th>
      <th>Lower</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">A</th>
      <th>a</th>
      <td>perfect</td>
    </tr>
    <tr>
      <th>b</th>
      <td>good</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">B</th>
      <th>a</th>
      <td>fair</td>
    </tr>
    <tr>
      <th>b</th>
      <td>bad</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">L1 = list(&#39;AABB&#39;)
L2 = list(&#39;abab&#39;)
tuples = list(zip(L1,L2))
mul_index = pd.MultiIndex.from_tuples(tuples, names=(&#39;Upper&#39;, &#39;Lower&#39;))
pd.DataFrame({&#39;Score&#39;:[&#39;perfect&#39;,&#39;good&#39;,&#39;fair&#39;,&#39;bad&#39;]},index=mul_index)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Score</th>
    </tr>
    <tr>
      <th>Upper</th>
      <th>Lower</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">A</th>
      <th>a</th>
      <td>perfect</td>
    </tr>
    <tr>
      <th>b</th>
      <td>good</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">B</th>
      <th>a</th>
      <td>fair</td>
    </tr>
    <tr>
      <th>b</th>
      <td>bad</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">arrays = [[&#39;A&#39;,&#39;a&#39;],[&#39;A&#39;,&#39;b&#39;],[&#39;B&#39;,&#39;a&#39;],[&#39;B&#39;,&#39;b&#39;]]
mul_index = pd.MultiIndex.from_tuples(arrays, names=(&#39;Upper&#39;, &#39;Lower&#39;))
pd.DataFrame({&#39;Score&#39;:[&#39;perfect&#39;,&#39;good&#39;,&#39;fair&#39;,&#39;bad&#39;]},index=mul_index)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Score</th>
    </tr>
    <tr>
      <th>Upper</th>
      <th>Lower</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">A</th>
      <th>a</th>
      <td>perfect</td>
    </tr>
    <tr>
      <th>b</th>
      <td>good</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">B</th>
      <th>a</th>
      <td>fair</td>
    </tr>
    <tr>
      <th>b</th>
      <td>bad</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">mul_index
#由此看出内部自动转成元组</code></pre>
<pre><code>MultiIndex([(&#39;A&#39;, &#39;a&#39;),
            (&#39;A&#39;, &#39;b&#39;),
            (&#39;B&#39;, &#39;a&#39;),
            (&#39;B&#39;, &#39;b&#39;)],
           names=[&#39;Upper&#39;, &#39;Lower&#39;])</code></pre><p>（b）通过from_product</p>
<pre><code class="python">L1 = [&#39;A&#39;,&#39;B&#39;]
L2 = [&#39;a&#39;,&#39;b&#39;]
pd.MultiIndex.from_product([L1,L2],names=(&#39;Upper&#39;, &#39;Lower&#39;))
#两两相乘</code></pre>
<p>（c）指定df中的列创建（set_index方法）</p>
<pre><code class="python">df_using_mul = df.set_index([&#39;Class&#39;,&#39;Address&#39;])
df_using_mul.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>School</th>
      <th>Gender</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>Class</th>
      <th>Address</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">C_1</th>
      <th>street_1</th>
      <td>S_1</td>
      <td>M</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>street_2</th>
      <td>S_1</td>
      <td>F</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>street_2</th>
      <td>S_1</td>
      <td>M</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>street_2</th>
      <td>S_1</td>
      <td>F</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>street_4</th>
      <td>S_1</td>
      <td>F</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>



<p>2.多层索引切片</p>
<pre><code class="python">df_using_mul.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>School</th>
      <th>Gender</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>Class</th>
      <th>Address</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">C_1</th>
      <th>street_1</th>
      <td>S_1</td>
      <td>M</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>street_2</th>
      <td>S_1</td>
      <td>F</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>street_2</th>
      <td>S_1</td>
      <td>M</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>street_2</th>
      <td>S_1</td>
      <td>F</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>street_4</th>
      <td>S_1</td>
      <td>F</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>



<p>3.多层索引中的slice对象</p>
<pre><code class="python">L1,L2 = [&#39;A&#39;,&#39;B&#39;],[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]
mul_index1 = pd.MultiIndex.from_product([L1,L2],names=(&#39;Upper&#39;, &#39;Lower&#39;))
L3,L4 = [&#39;D&#39;,&#39;E&#39;,&#39;F&#39;],[&#39;d&#39;,&#39;e&#39;,&#39;f&#39;]
mul_index2 = pd.MultiIndex.from_product([L3,L4],names=(&#39;Big&#39;, &#39;Small&#39;))
df_s = pd.DataFrame(np.random.rand(6,9),index=mul_index1,columns=mul_index2)
df_s</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead tr th {
    text-align: left;
}

.dataframe thead tr:last-of-type th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>Big</th>
      <th colspan="3" halign="left">D</th>
      <th colspan="3" halign="left">E</th>
      <th colspan="3" halign="left">F</th>
    </tr>
    <tr>
      <th></th>
      <th>Small</th>
      <th>d</th>
      <th>e</th>
      <th>f</th>
      <th>d</th>
      <th>e</th>
      <th>f</th>
      <th>d</th>
      <th>e</th>
      <th>f</th>
    </tr>
    <tr>
      <th>Upper</th>
      <th>Lower</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">A</th>
      <th>a</th>
      <td>0.693152</td>
      <td>0.672084</td>
      <td>0.929580</td>
      <td>0.348846</td>
      <td>0.998656</td>
      <td>0.618890</td>
      <td>0.134470</td>
      <td>0.629302</td>
      <td>0.755844</td>
    </tr>
    <tr>
      <th>b</th>
      <td>0.793648</td>
      <td>0.663314</td>
      <td>0.793556</td>
      <td>0.632018</td>
      <td>0.837149</td>
      <td>0.573710</td>
      <td>0.083993</td>
      <td>0.774272</td>
      <td>0.634520</td>
    </tr>
    <tr>
      <th>c</th>
      <td>0.485607</td>
      <td>0.429198</td>
      <td>0.971712</td>
      <td>0.471989</td>
      <td>0.250029</td>
      <td>0.027371</td>
      <td>0.377319</td>
      <td>0.721766</td>
      <td>0.911952</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">B</th>
      <th>a</th>
      <td>0.434036</td>
      <td>0.430081</td>
      <td>0.590865</td>
      <td>0.106680</td>
      <td>0.678473</td>
      <td>0.946369</td>
      <td>0.681991</td>
      <td>0.788171</td>
      <td>0.272536</td>
    </tr>
    <tr>
      <th>b</th>
      <td>0.116107</td>
      <td>0.186889</td>
      <td>0.252728</td>
      <td>0.137849</td>
      <td>0.078398</td>
      <td>0.986727</td>
      <td>0.533018</td>
      <td>0.049788</td>
      <td>0.078079</td>
    </tr>
    <tr>
      <th>c</th>
      <td>0.577150</td>
      <td>0.858875</td>
      <td>0.468748</td>
      <td>0.016894</td>
      <td>0.717600</td>
      <td>0.283764</td>
      <td>0.595257</td>
      <td>0.037818</td>
      <td>0.839023</td>
    </tr>
  </tbody>
</table>
</div>


]]></content>
      <categories>
        <category>Pandas教程</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫编程实践-Task1</title>
    <url>/2020/04/21/Python%E7%88%AC%E8%99%AB%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5-Task1/</url>
    <content><![CDATA[<p>HTTP是一个客户端（用户）和服务器端（网站）之间进行请求和应答的标准。通过使用网页浏览器、网络爬虫或者其他工具，客户端可以向服务器上的指定端口（默认端口为80）发起一个HTTP请求。这个客户端成为客户代理（user agent）。应答服务器上存储着一些资源码，比如HTML文件和图像。这个应答服务器成为源服务器（origin server）。在用户代理和源服务器中间可能存在多个“中间层”，比如代理服务器、网关或者隧道（tunnel）。尽管TCP/IP是互联网最流行的协议，但HTTP中并没有规定必须使用它或它支持的层。</p>
<a id="more"></a>

<p>事实上。HTTP可以在互联网协议或其他网络上实现。HTTP假定其下层协议能够提供可靠的传输，因此，任何能够提供这种保证的协议都可以使用。使用TCP/IP协议族时RCP作为传输层。通常由HTTP客户端发起一个请求，创建一个到服务器指定端口（默认是80端口）的TCP链接。HTTP服务器则在该端口监听客户端的请求。一旦收到请求，服务器会向客户端返回一个状态（比如“THTTP/1.1 200 OK”），以及请求的文件、错误信息等响应内容。</p>
<p>HTTP的请求方法有很多种，主要包括以下几个：</p>
<ol>
<li><p>GET：向指定的资源发出“显示”请求。GET方法应该只用于读取数据，而不应当被用于“副作用”的操作中（例如在Web Application中）。其中一个原因是GET可能会被网络蜘蛛等随意访问。</p>
</li>
<li><p>HEAD：与GET方法一样，都是向服务器发出直顶资源的请求，只不过服务器将不会出传回资源的内容部分。它的好处在于，使用这个方法可以在不必传输内容的情况下，将获取到其中“关于该资源的信息”（元信息或元数据）。</p>
</li>
<li><p>POST：向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求文本中。这个请求可能会创建新的资源或修改现有资源，或二者皆有。</p>
</li>
<li><p>PUT：向指定资源位置上传输最新内容。</p>
</li>
<li><p>DELETE：请求服务器删除Request-URL所标识的资源，或二者皆有。</p>
</li>
<li><p>TRACE：回显服务器收到的请求，主要用于测试或诊断。</p>
</li>
<li><p>OPTIONS：这个方法可使服务器传回该资源所支持的所有HTTP请求方法。用“*”来代表资源名称向Web服务器发送OPTIONS请求，可以测试服务器共能是否正常。</p>
</li>
<li><p>CONNECT：HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的连接（经由非加密的HTTP代理服务器）。方法名称是区分大小写的。当某个请求所针对的资源不支持对应的请求方法的时候，服务器应当返回状态码405（Method Not Allowed），当服务器不认识或者不支持对应的请求方法的时候，应当返回状态码501（Not Implemented）。</p>
</li>
</ol>
<p>html和css都会跳过。</p>
<p>Chrome的开发者模式为用户提供了下面几组工具。</p>
<ol>
<li><p>Elements：允许用户从浏览器的角度来观察网页，用户可以借此看到Chrome渲染页面所需要的HTML、CSS和DOM（Document Object Model）对象。</p>
</li>
<li><p>Network：可以看到网页向服务气请求了哪些资源、资源的大小以及加载资源的相关信息。此外，还可以查看HTTP的请求头、返回内容等。</p>
</li>
<li><p>Source：即源代码面板，主要用来调试JavaScript。</p>
</li>
<li><p>Console：即控制台面板，可以显示各种警告与错误信息。在开发期间，可以使用控制台面板记录诊断信息，或者使用它作为shell在页面上与JavaScript交互。</p>
</li>
<li><p>Performance：使用这个模块可以记录和查看网站生命周期内发生的各种事情来提高页面运行时的性能。</p>
</li>
<li><p>Memory：这个面板可以提供比Performance更多的信息，比如跟踪内存泄漏。</p>
</li>
<li><p>Application：检查加载的所有资源。</p>
</li>
<li><p>Security：即安全面板，可以用来处理证书问题等。</p>
</li>
</ol>
<p>一个网络爬虫程序最普遍的过程：</p>
<ol>
<li>访问站点；</li>
<li>定位所需的信息；</li>
<li>得到并处理信息。</li>
</ol>
<pre><code class="python">import requests
url = &#39;https://www.python.org/dev/peps/pep-0020/&#39;
res = requests.get(url)
text = res.text</code></pre>
<pre><code class="python">## 爬取python之禅并存入txt文件

with open(&#39;zon_of_python.txt&#39;, &#39;w&#39;) as f:
    f.write(text[text.find(&#39;&lt;pre&#39;)+28:text.find(&#39;&lt;/pre&gt;&#39;)-1])
print(text[text.find(&#39;&lt;pre&#39;)+28:text.find(&#39;&lt;/pre&gt;&#39;)-1])</code></pre>
<pre><code class="python">import urllib
url = &#39;https://www.python.org/dev/peps/pep-0020/&#39;
res = urllib.request.urlopen(url).read().decode(&#39;utf-8&#39;)
print(res[res.find(&#39;&lt;pre&#39;)+28:res.find(&#39;&lt;/pre&gt;&#39;)-1])</code></pre>
<pre><code>Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren&#39;t special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you&#39;re Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it&#39;s a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let&#39;s do more of those!</code></pre><p>使用API：</p>
<p>所谓的采集网络数据，并不一定必须从网页中抓取数据，而api（Application Programming Iterface）的用处就在这里：API为开发者提供了方便友好的接口，不同的开发者用不同的语言都能获取相同的数据。目前API一般会以XML（Extensible Markup Language，可拓展标记语言）或者JSON（JavaScript Object Notation）格式来返回服务器响应，其中JSON数据格式越来越受到人们的欢迎，我们后面的课程也会详细介绍JSON格式。</p>
]]></content>
      <categories>
        <category>Python爬虫编程实践</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas教程-Task1</title>
    <url>/2020/04/20/Pandas%E6%95%99%E7%A8%8B-Task1/</url>
    <content><![CDATA[<pre><code class="python">import pandas as pd
import numpy as np</code></pre>
<pre><code class="python">pd.__version__</code></pre>
<pre><code>&#39;0.25.3&#39;</code></pre><pre><code class="python">df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.csv&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df_txt = pd.read_table(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.txt&#39;)
df_txt</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
      <th>col4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>a</td>
      <td>1.4</td>
      <td>apple</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>b</td>
      <td>3.4</td>
      <td>banana</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6</td>
      <td>c</td>
      <td>2.5</td>
      <td>orange</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>d</td>
      <td>3.2</td>
      <td>lemon</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df_excel = pd.read_excel(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.xlsx&#39;)
df_excel.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.to_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/new_table.csv&#39;)</code></pre>
<pre><code class="python">df.to_excel(&#39;Documents/Pandas教程/joyful-pandas-master/data/new_table2.xlsx&#39;, sheet_name=&#39;Sheet1&#39;)</code></pre>
<pre><code class="python">s = pd.Series(np.random.randn(5),index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;],name=&#39;这是一个Series&#39;,dtype=&#39;float64&#39;)
s</code></pre>
<pre><code>a   -0.699435
b   -0.583320
c   -0.526598
d   -1.110295
e   -0.006360
Name: 这是一个Series, dtype: float64</code></pre><pre><code class="python">s.values</code></pre>
<pre><code>array([-0.6994351 , -0.5833203 , -0.52659774, -1.11029458, -0.00635964])</code></pre><pre><code class="python">s.name</code></pre>
<pre><code>&#39;这是一个Series&#39;</code></pre><pre><code class="python">s.index</code></pre>
<pre><code>Index([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;], dtype=&#39;object&#39;)</code></pre><pre><code class="python">s.dtype</code></pre>
<pre><code>dtype(&#39;float64&#39;)</code></pre><pre><code class="python">s[&#39;a&#39;]</code></pre>
<pre><code>-0.6994350999787233</code></pre><pre><code class="python">s.mean()</code></pre>
<pre><code>-0.585201471154681</code></pre><pre><code class="python">print([attr for attr in dir(s) if not attr.startswith(&#39;_&#39;)])</code></pre>
<pre><code>[&#39;T&#39;, &#39;a&#39;, &#39;abs&#39;, &#39;add&#39;, &#39;add_prefix&#39;, &#39;add_suffix&#39;, &#39;agg&#39;, &#39;aggregate&#39;, &#39;align&#39;, &#39;all&#39;, &#39;any&#39;, &#39;append&#39;, &#39;apply&#39;, &#39;argmax&#39;, &#39;argmin&#39;, &#39;argsort&#39;, &#39;array&#39;, &#39;as_matrix&#39;, &#39;asfreq&#39;, &#39;asof&#39;, &#39;astype&#39;, &#39;at&#39;, &#39;at_time&#39;, &#39;autocorr&#39;, &#39;axes&#39;, &#39;b&#39;, &#39;between&#39;, &#39;between_time&#39;, &#39;bfill&#39;, &#39;bool&#39;, &#39;c&#39;, &#39;clip&#39;, &#39;clip_lower&#39;, &#39;clip_upper&#39;, &#39;combine&#39;, &#39;combine_first&#39;, &#39;compound&#39;, &#39;compress&#39;, &#39;copy&#39;, &#39;corr&#39;, &#39;count&#39;, &#39;cov&#39;, &#39;cummax&#39;, &#39;cummin&#39;, &#39;cumprod&#39;, &#39;cumsum&#39;, &#39;d&#39;, &#39;describe&#39;, &#39;diff&#39;, &#39;div&#39;, &#39;divide&#39;, &#39;divmod&#39;, &#39;dot&#39;, &#39;drop&#39;, &#39;drop_duplicates&#39;, &#39;droplevel&#39;, &#39;dropna&#39;, &#39;dtype&#39;, &#39;dtypes&#39;, &#39;duplicated&#39;, &#39;e&#39;, &#39;empty&#39;, &#39;eq&#39;, &#39;equals&#39;, &#39;ewm&#39;, &#39;expanding&#39;, &#39;explode&#39;, &#39;factorize&#39;, &#39;ffill&#39;, &#39;fillna&#39;, &#39;filter&#39;, &#39;first&#39;, &#39;first_valid_index&#39;, &#39;floordiv&#39;, &#39;from_array&#39;, &#39;ge&#39;, &#39;get&#39;, &#39;get_dtype_counts&#39;, &#39;get_ftype_counts&#39;, &#39;get_values&#39;, &#39;groupby&#39;, &#39;gt&#39;, &#39;hasnans&#39;, &#39;head&#39;, &#39;hist&#39;, &#39;iat&#39;, &#39;idxmax&#39;, &#39;idxmin&#39;, &#39;iloc&#39;, &#39;index&#39;, &#39;infer_objects&#39;, &#39;interpolate&#39;, &#39;is_monotonic&#39;, &#39;is_monotonic_decreasing&#39;, &#39;is_monotonic_increasing&#39;, &#39;is_unique&#39;, &#39;isin&#39;, &#39;isna&#39;, &#39;isnull&#39;, &#39;item&#39;, &#39;items&#39;, &#39;iteritems&#39;, &#39;keys&#39;, &#39;kurt&#39;, &#39;kurtosis&#39;, &#39;last&#39;, &#39;last_valid_index&#39;, &#39;le&#39;, &#39;loc&#39;, &#39;lt&#39;, &#39;mad&#39;, &#39;map&#39;, &#39;mask&#39;, &#39;max&#39;, &#39;mean&#39;, &#39;median&#39;, &#39;memory_usage&#39;, &#39;min&#39;, &#39;mod&#39;, &#39;mode&#39;, &#39;mul&#39;, &#39;multiply&#39;, &#39;name&#39;, &#39;nbytes&#39;, &#39;ndim&#39;, &#39;ne&#39;, &#39;nlargest&#39;, &#39;nonzero&#39;, &#39;notna&#39;, &#39;notnull&#39;, &#39;nsmallest&#39;, &#39;nunique&#39;, &#39;pct_change&#39;, &#39;pipe&#39;, &#39;plot&#39;, &#39;pop&#39;, &#39;pow&#39;, &#39;prod&#39;, &#39;product&#39;, &#39;ptp&#39;, &#39;put&#39;, &#39;quantile&#39;, &#39;radd&#39;, &#39;rank&#39;, &#39;ravel&#39;, &#39;rdiv&#39;, &#39;rdivmod&#39;, &#39;reindex&#39;, &#39;reindex_like&#39;, &#39;rename&#39;, &#39;rename_axis&#39;, &#39;reorder_levels&#39;, &#39;repeat&#39;, &#39;replace&#39;, &#39;resample&#39;, &#39;reset_index&#39;, &#39;rfloordiv&#39;, &#39;rmod&#39;, &#39;rmul&#39;, &#39;rolling&#39;, &#39;round&#39;, &#39;rpow&#39;, &#39;rsub&#39;, &#39;rtruediv&#39;, &#39;sample&#39;, &#39;searchsorted&#39;, &#39;sem&#39;, &#39;set_axis&#39;, &#39;shape&#39;, &#39;shift&#39;, &#39;size&#39;, &#39;skew&#39;, &#39;slice_shift&#39;, &#39;sort_index&#39;, &#39;sort_values&#39;, &#39;squeeze&#39;, &#39;std&#39;, &#39;sub&#39;, &#39;subtract&#39;, &#39;sum&#39;, &#39;swapaxes&#39;, &#39;swaplevel&#39;, &#39;tail&#39;, &#39;take&#39;, &#39;to_clipboard&#39;, &#39;to_csv&#39;, &#39;to_dense&#39;, &#39;to_dict&#39;, &#39;to_excel&#39;, &#39;to_frame&#39;, &#39;to_hdf&#39;, &#39;to_json&#39;, &#39;to_latex&#39;, &#39;to_list&#39;, &#39;to_msgpack&#39;, &#39;to_numpy&#39;, &#39;to_period&#39;, &#39;to_pickle&#39;, &#39;to_sparse&#39;, &#39;to_sql&#39;, &#39;to_string&#39;, &#39;to_timestamp&#39;, &#39;to_xarray&#39;, &#39;transform&#39;, &#39;transpose&#39;, &#39;truediv&#39;, &#39;truncate&#39;, &#39;tshift&#39;, &#39;tz_convert&#39;, &#39;tz_localize&#39;, &#39;unique&#39;, &#39;unstack&#39;, &#39;update&#39;, &#39;value_counts&#39;, &#39;values&#39;, &#39;var&#39;, &#39;view&#39;, &#39;where&#39;, &#39;xs&#39;]</code></pre><pre><code class="python">df = pd.DataFrame({&#39;col1&#39;:list(&#39;abcde&#39;),&#39;col2&#39;:range(5,10),&#39;col3&#39;:[1.3,2.5,3.6,4.6,5.8]},
                 index=list(&#39;一二三四五&#39;))
df</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col1</th>
      <th>col2</th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>一</th>
      <td>a</td>
      <td>5</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>二</th>
      <td>b</td>
      <td>6</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>三</th>
      <td>c</td>
      <td>7</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>四</th>
      <td>d</td>
      <td>8</td>
      <td>4.6</td>
    </tr>
    <tr>
      <th>五</th>
      <td>e</td>
      <td>9</td>
      <td>5.8</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[&#39;col1&#39;]</code></pre>
<pre><code>一    a
二    b
三    c
四    d
五    e
Name: col1, dtype: object</code></pre><pre><code class="python">type(df)</code></pre>
<pre><code>pandas.core.frame.DataFrame</code></pre><pre><code class="python">type(df[&#39;col1&#39;])</code></pre>
<pre><code>pandas.core.series.Series</code></pre><pre><code class="python">df.rename(index={&#39;一&#39;:&#39;one&#39;},columns={&#39;col1&#39;:&#39;new_col1&#39;})</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>new_col1</th>
      <th>col2</th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>one</th>
      <td>a</td>
      <td>5</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>二</th>
      <td>b</td>
      <td>6</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>三</th>
      <td>c</td>
      <td>7</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>四</th>
      <td>d</td>
      <td>8</td>
      <td>4.6</td>
    </tr>
    <tr>
      <th>五</th>
      <td>e</td>
      <td>9</td>
      <td>5.8</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.index</code></pre>
<pre><code>Index([&#39;一&#39;, &#39;二&#39;, &#39;三&#39;, &#39;四&#39;, &#39;五&#39;], dtype=&#39;object&#39;)</code></pre><pre><code class="python">df.columns</code></pre>
<pre><code>Index([&#39;col1&#39;, &#39;col2&#39;, &#39;col3&#39;], dtype=&#39;object&#39;)</code></pre><pre><code class="python">df.values</code></pre>
<pre><code>array([[&#39;a&#39;, 5, 1.3],
       [&#39;b&#39;, 6, 2.5],
       [&#39;c&#39;, 7, 3.6],
       [&#39;d&#39;, 8, 4.6],
       [&#39;e&#39;, 9, 5.8]], dtype=object)</code></pre><pre><code class="python">df.shape</code></pre>
<pre><code>(5, 3)</code></pre><pre><code class="python">df.mean() </code></pre>
<pre><code>col2    7.00
col3    3.56
dtype: float64</code></pre><pre><code class="python">df1 = pd.DataFrame({&#39;A&#39;:[1,2,3]},index=[1,2,3])
df2 = pd.DataFrame({&#39;A&#39;:[1,2,3]},index=[3,1,2])
df1-df2</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>-1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.drop(index=&#39;五&#39;,columns=&#39;col1&#39;)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col2</th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>一</th>
      <td>5</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>二</th>
      <td>6</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>三</th>
      <td>7</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>四</th>
      <td>8</td>
      <td>4.6</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[&#39;col1&#39;]=[1,2,3,4,5]
del df[&#39;col1&#39;]
df</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col2</th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>一</th>
      <td>5</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>二</th>
      <td>6</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>三</th>
      <td>7</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>四</th>
      <td>8</td>
      <td>4.6</td>
    </tr>
    <tr>
      <th>五</th>
      <td>9</td>
      <td>5.8</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[&#39;col1&#39;]=[1,2,3,4,5]
df.pop(&#39;col1&#39;)</code></pre>
<pre><code>一    1
二    2
三    3
四    4
五    5
Name: col1, dtype: int64</code></pre><pre><code class="python">df</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col2</th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>一</th>
      <td>5</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>二</th>
      <td>6</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>三</th>
      <td>7</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>四</th>
      <td>8</td>
      <td>4.6</td>
    </tr>
    <tr>
      <th>五</th>
      <td>9</td>
      <td>5.8</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df1[&#39;B&#39;]=list(&#39;abc&#39;)
df1</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>a</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>b</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>c</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df1.assign(C=pd.Series(list(&#39;def&#39;)))</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>a</td>
      <td>e</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>b</td>
      <td>f</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>c</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df1</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>a</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>b</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>c</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.select_dtypes(include=[&#39;number&#39;]).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col2</th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>一</th>
      <td>5</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>二</th>
      <td>6</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>三</th>
      <td>7</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>四</th>
      <td>8</td>
      <td>4.6</td>
    </tr>
    <tr>
      <th>五</th>
      <td>9</td>
      <td>5.8</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.select_dtypes(include=[&#39;float&#39;]).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>一</th>
      <td>1.3</td>
    </tr>
    <tr>
      <th>二</th>
      <td>2.5</td>
    </tr>
    <tr>
      <th>三</th>
      <td>3.6</td>
    </tr>
    <tr>
      <th>四</th>
      <td>4.6</td>
    </tr>
    <tr>
      <th>五</th>
      <td>5.8</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">s = df.mean()
s.name=&#39;to_DataFrame&#39;
s</code></pre>
<pre><code>col2    7.00
col3    3.56
Name: to_DataFrame, dtype: float64</code></pre><pre><code class="python">s.to_frame()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>to_DataFrame</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>col2</th>
      <td>7.00</td>
    </tr>
    <tr>
      <th>col3</th>
      <td>3.56</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">s.to_frame().T</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col2</th>
      <th>col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>to_DataFrame</th>
      <td>7.0</td>
      <td>3.56</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/table.csv&#39;)</code></pre>
<pre><code class="python">df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.tail()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>30</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>2401</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>62</td>
      <td>45.3</td>
      <td>A</td>
    </tr>
    <tr>
      <th>31</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>2402</td>
      <td>M</td>
      <td>street_7</td>
      <td>166</td>
      <td>82</td>
      <td>48.7</td>
      <td>B</td>
    </tr>
    <tr>
      <th>32</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>2403</td>
      <td>F</td>
      <td>street_6</td>
      <td>158</td>
      <td>60</td>
      <td>59.7</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>33</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>2404</td>
      <td>F</td>
      <td>street_2</td>
      <td>160</td>
      <td>84</td>
      <td>67.7</td>
      <td>B</td>
    </tr>
    <tr>
      <th>34</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>2405</td>
      <td>F</td>
      <td>street_6</td>
      <td>193</td>
      <td>54</td>
      <td>47.6</td>
      <td>B</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.head(3)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[&#39;Physics&#39;].nunique()</code></pre>
<pre><code>7</code></pre><pre><code class="python">df[&#39;Physics&#39;].unique()</code></pre>
<pre><code>array([&#39;A+&#39;, &#39;B+&#39;, &#39;B-&#39;, &#39;A-&#39;, &#39;B&#39;, &#39;A&#39;, &#39;C&#39;], dtype=object)</code></pre><pre><code class="python">df[&#39;Physics&#39;].count()</code></pre>
<pre><code>35</code></pre><pre><code class="python">
df[&#39;Physics&#39;].value_counts()</code></pre>
<pre><code>B+    9
B     8
B-    6
A     4
A-    3
A+    3
C     2
Name: Physics, dtype: int64</code></pre><pre><code class="python">df.info()</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 35 entries, 0 to 34
Data columns (total 9 columns):
School     35 non-null object
Class      35 non-null object
ID         35 non-null int64
Gender     35 non-null object
Address    35 non-null object
Height     35 non-null int64
Weight     35 non-null int64
Math       35 non-null float64
Physics    35 non-null object
dtypes: float64(1), int64(3), object(5)
memory usage: 2.6+ KB</code></pre><pre><code class="python">df.describe()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>35.00000</td>
      <td>35.000000</td>
      <td>35.000000</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1803.00000</td>
      <td>174.142857</td>
      <td>74.657143</td>
      <td>61.351429</td>
    </tr>
    <tr>
      <th>std</th>
      <td>536.87741</td>
      <td>13.541098</td>
      <td>12.895377</td>
      <td>19.915164</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1101.00000</td>
      <td>155.000000</td>
      <td>53.000000</td>
      <td>31.500000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1204.50000</td>
      <td>161.000000</td>
      <td>63.000000</td>
      <td>47.400000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2103.00000</td>
      <td>173.000000</td>
      <td>74.000000</td>
      <td>61.700000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2301.50000</td>
      <td>187.500000</td>
      <td>82.000000</td>
      <td>77.100000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2405.00000</td>
      <td>195.000000</td>
      <td>100.000000</td>
      <td>97.000000</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.describe(percentiles=[.05, .25, .75, .95])</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>35.00000</td>
      <td>35.000000</td>
      <td>35.000000</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1803.00000</td>
      <td>174.142857</td>
      <td>74.657143</td>
      <td>61.351429</td>
    </tr>
    <tr>
      <th>std</th>
      <td>536.87741</td>
      <td>13.541098</td>
      <td>12.895377</td>
      <td>19.915164</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1101.00000</td>
      <td>155.000000</td>
      <td>53.000000</td>
      <td>31.500000</td>
    </tr>
    <tr>
      <th>5%</th>
      <td>1102.70000</td>
      <td>157.000000</td>
      <td>56.100000</td>
      <td>32.640000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1204.50000</td>
      <td>161.000000</td>
      <td>63.000000</td>
      <td>47.400000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2103.00000</td>
      <td>173.000000</td>
      <td>74.000000</td>
      <td>61.700000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2301.50000</td>
      <td>187.500000</td>
      <td>82.000000</td>
      <td>77.100000</td>
    </tr>
    <tr>
      <th>95%</th>
      <td>2403.30000</td>
      <td>193.300000</td>
      <td>97.600000</td>
      <td>90.040000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2405.00000</td>
      <td>195.000000</td>
      <td>100.000000</td>
      <td>97.000000</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[&#39;Physics&#39;].describe()</code></pre>
<pre><code>count     35
unique     7
top       B+
freq       9
Name: Physics, dtype: object</code></pre><pre><code class="python">df[&#39;Math&#39;].idxmax()</code></pre>
<pre><code>5</code></pre><pre><code class="python">df[&#39;Math&#39;].nlargest(3)</code></pre>
<pre><code>5     97.0
28    95.5
11    87.7
Name: Math, dtype: float64</code></pre><pre><code class="python">df[&#39;Math&#39;].head()</code></pre>
<pre><code>0    34.0
1    32.5
2    87.2
3    80.4
4    84.8
Name: Math, dtype: float64</code></pre><pre><code class="python">df[&#39;Math&#39;].clip(33,80).head()</code></pre>
<pre><code>0    34.0
1    33.0
2    80.0
3    80.0
4    80.0
Name: Math, dtype: float64</code></pre><pre><code class="python">df[&#39;Math&#39;].mad()</code></pre>
<pre><code>16.924244897959188</code></pre><pre><code class="python">df[&#39;Address&#39;].head()</code></pre>
<pre><code>0    street_1
1    street_2
2    street_2
3    street_2
4    street_4
Name: Address, dtype: object</code></pre><pre><code class="python">df[&#39;Address&#39;].replace([&#39;street_1&#39;,&#39;street_2&#39;],[&#39;one&#39;,&#39;two&#39;]).head()</code></pre>
<pre><code>0         one
1         two
2         two
3         two
4    street_4
Name: Address, dtype: object</code></pre><pre><code class="python">df.replace({&#39;Address&#39;:{&#39;street_1&#39;:&#39;one&#39;,&#39;street_2&#39;:&#39;two&#39;}}).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>one</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>two</td>
      <td>192</td>
      <td>73</td>
      <td>32.5</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>two</td>
      <td>186</td>
      <td>82</td>
      <td>87.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>two</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>84.8</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[&#39;Math&#39;].apply(lambda x:str(x)+&#39;!&#39;).head() </code></pre>
<pre><code>0    34.0!
1    32.5!
2    87.2!
3    80.4!
4    84.8!
Name: Math, dtype: object</code></pre><pre><code class="python">df.apply(lambda x:x.apply(lambda x:str(x)+&#39;!&#39;)).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1!</td>
      <td>C_1!</td>
      <td>1101!</td>
      <td>M!</td>
      <td>street_1!</td>
      <td>173!</td>
      <td>63!</td>
      <td>34.0!</td>
      <td>A+!</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S_1!</td>
      <td>C_1!</td>
      <td>1102!</td>
      <td>F!</td>
      <td>street_2!</td>
      <td>192!</td>
      <td>73!</td>
      <td>32.5!</td>
      <td>B+!</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S_1!</td>
      <td>C_1!</td>
      <td>1103!</td>
      <td>M!</td>
      <td>street_2!</td>
      <td>186!</td>
      <td>82!</td>
      <td>87.2!</td>
      <td>B+!</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1!</td>
      <td>C_1!</td>
      <td>1104!</td>
      <td>F!</td>
      <td>street_2!</td>
      <td>167!</td>
      <td>81!</td>
      <td>80.4!</td>
      <td>B-!</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S_1!</td>
      <td>C_1!</td>
      <td>1105!</td>
      <td>F!</td>
      <td>street_4!</td>
      <td>159!</td>
      <td>64!</td>
      <td>84.8!</td>
      <td>B+!</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.set_index(&#39;Math&#39;).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>Math</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>34.0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>32.5</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>87.2</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1103</td>
      <td>M</td>
      <td>street_2</td>
      <td>186</td>
      <td>82</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>80.4</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>84.8</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1105</td>
      <td>F</td>
      <td>street_4</td>
      <td>159</td>
      <td>64</td>
      <td>B+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.set_index(&#39;Math&#39;).sort_index().head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Physics</th>
    </tr>
    <tr>
      <th>Math</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>31.5</th>
      <td>S_1</td>
      <td>C_3</td>
      <td>1301</td>
      <td>M</td>
      <td>street_4</td>
      <td>161</td>
      <td>68</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>32.5</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1102</td>
      <td>F</td>
      <td>street_2</td>
      <td>192</td>
      <td>73</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>32.7</th>
      <td>S_2</td>
      <td>C_3</td>
      <td>2302</td>
      <td>M</td>
      <td>street_5</td>
      <td>171</td>
      <td>88</td>
      <td>A</td>
    </tr>
    <tr>
      <th>33.8</th>
      <td>S_1</td>
      <td>C_2</td>
      <td>1204</td>
      <td>F</td>
      <td>street_5</td>
      <td>162</td>
      <td>63</td>
      <td>B</td>
    </tr>
    <tr>
      <th>34.0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>A+</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.sort_values(by=&#39;Class&#39;).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>19</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>2105</td>
      <td>M</td>
      <td>street_4</td>
      <td>170</td>
      <td>81</td>
      <td>34.2</td>
      <td>A</td>
    </tr>
    <tr>
      <th>18</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>2104</td>
      <td>F</td>
      <td>street_5</td>
      <td>159</td>
      <td>97</td>
      <td>72.2</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>16</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>2102</td>
      <td>F</td>
      <td>street_6</td>
      <td>161</td>
      <td>61</td>
      <td>50.6</td>
      <td>B+</td>
    </tr>
    <tr>
      <th>15</th>
      <td>S_2</td>
      <td>C_1</td>
      <td>2101</td>
      <td>M</td>
      <td>street_7</td>
      <td>174</td>
      <td>84</td>
      <td>83.3</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df.sort_values(by=[&#39;Address&#39;,&#39;Height&#39;]).head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>School</th>
      <th>Class</th>
      <th>ID</th>
      <th>Gender</th>
      <th>Address</th>
      <th>Height</th>
      <th>Weight</th>
      <th>Math</th>
      <th>Physics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1101</td>
      <td>M</td>
      <td>street_1</td>
      <td>173</td>
      <td>63</td>
      <td>34.0</td>
      <td>A+</td>
    </tr>
    <tr>
      <th>11</th>
      <td>S_1</td>
      <td>C_3</td>
      <td>1302</td>
      <td>F</td>
      <td>street_1</td>
      <td>175</td>
      <td>57</td>
      <td>87.7</td>
      <td>A-</td>
    </tr>
    <tr>
      <th>23</th>
      <td>S_2</td>
      <td>C_2</td>
      <td>2204</td>
      <td>M</td>
      <td>street_1</td>
      <td>175</td>
      <td>74</td>
      <td>47.2</td>
      <td>B-</td>
    </tr>
    <tr>
      <th>33</th>
      <td>S_2</td>
      <td>C_4</td>
      <td>2404</td>
      <td>F</td>
      <td>street_2</td>
      <td>160</td>
      <td>84</td>
      <td>67.7</td>
      <td>B</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S_1</td>
      <td>C_1</td>
      <td>1104</td>
      <td>F</td>
      <td>street_2</td>
      <td>167</td>
      <td>81</td>
      <td>80.4</td>
      <td>B-</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="【问题一】-Series和DataFrame有哪些常见属性和方法？"><a href="#【问题一】-Series和DataFrame有哪些常见属性和方法？" class="headerlink" title="【问题一】 Series和DataFrame有哪些常见属性和方法？"></a>【问题一】 Series和DataFrame有哪些常见属性和方法？</h3><p>对于一个Series，其中最常用的属性为值（values），索引（index），名字（name），类型（dtype）。<br>对于DataFrame，属性有index、columns、values、shape。<br>方法是mean（）。</p>
<h3 id="【问题二】-value-counts会统计缺失值吗？"><a href="#【问题二】-value-counts会统计缺失值吗？" class="headerlink" title="【问题二】 value_counts会统计缺失值吗？"></a>【问题二】 value_counts会统计缺失值吗？</h3><p>不会</p>
<h3 id="【问题三】-与idxmax和nlargest功能相反的是哪两组函数？"><a href="#【问题三】-与idxmax和nlargest功能相反的是哪两组函数？" class="headerlink" title="【问题三】 与idxmax和nlargest功能相反的是哪两组函数？"></a>【问题三】 与idxmax和nlargest功能相反的是哪两组函数？</h3><p>idxmin、nsmallest</p>
<h3 id="【问题四】-在常用函数一节中，由于一些函数的功能比较简单，因此没有列入，现在将它们列在下面，请分别说明它们的用途并尝试使用。"><a href="#【问题四】-在常用函数一节中，由于一些函数的功能比较简单，因此没有列入，现在将它们列在下面，请分别说明它们的用途并尝试使用。" class="headerlink" title="【问题四】 在常用函数一节中，由于一些函数的功能比较简单，因此没有列入，现在将它们列在下面，请分别说明它们的用途并尝试使用。"></a>【问题四】 在常用函数一节中，由于一些函数的功能比较简单，因此没有列入，现在将它们列在下面，请分别说明它们的用途并尝试使用。</h3><p>sum/mean/median/mad/min/max/abs/std/var/quantile/cummax/cumsum/cumprod</p>
<h3 id="【问题五】-df-mean-axis-1-是什么意思？它与df-mean-的结果一样吗？第一问提到的函数也有axis参数吗？怎么使用？"><a href="#【问题五】-df-mean-axis-1-是什么意思？它与df-mean-的结果一样吗？第一问提到的函数也有axis参数吗？怎么使用？" class="headerlink" title="【问题五】 df.mean(axis=1)是什么意思？它与df.mean()的结果一样吗？第一问提到的函数也有axis参数吗？怎么使用？"></a>【问题五】 df.mean(axis=1)是什么意思？它与df.mean()的结果一样吗？第一问提到的函数也有axis参数吗？怎么使用？</h3><h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>1.【练习一】 现有一份关于美剧《权力的游戏》剧本的数据集，请解决以下问题：¶</p>
<p>（a）在所有的数据中，一共出现了多少人物？</p>
<p>（b）以单元格计数（即简单把一个单元格视作一句），谁说了最多的话？</p>
<p>（c）以单词计数，谁说了最多的单词</p>
<p>2.【练习二】现有一份关于科比的投篮数据集，请解决如下问题：</p>
<p>（a）哪种action_type和combined_shot_type的组合是最多的？</p>
<p>（b）在所有被记录的game_id中，遭遇到最多的opponent是一个支？</p>
<pre><code class="python">#练习1-a
df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/Game_of_Thrones_Script.csv&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Release Date</th>
      <th>Season</th>
      <th>Episode</th>
      <th>Episode Title</th>
      <th>Name</th>
      <th>Sentence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011/4/17</td>
      <td>Season 1</td>
      <td>Episode 1</td>
      <td>Winter is Coming</td>
      <td>waymar royce</td>
      <td>What do you expect? They're savages. One lot s...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011/4/17</td>
      <td>Season 1</td>
      <td>Episode 1</td>
      <td>Winter is Coming</td>
      <td>will</td>
      <td>I've never seen wildlings do a thing like this...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011/4/17</td>
      <td>Season 1</td>
      <td>Episode 1</td>
      <td>Winter is Coming</td>
      <td>waymar royce</td>
      <td>How close did you get?</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011/4/17</td>
      <td>Season 1</td>
      <td>Episode 1</td>
      <td>Winter is Coming</td>
      <td>will</td>
      <td>Close as any man would.</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011/4/17</td>
      <td>Season 1</td>
      <td>Episode 1</td>
      <td>Winter is Coming</td>
      <td>gared</td>
      <td>We should head back to the wall.</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">df[&#39;Name&#39;].nunique()</code></pre>
<pre><code>564</code></pre><pre><code class="python">#练习1-b
df[&#39;Name&#39;].value_counts().index[0]</code></pre>
<pre><code>&#39;tyrion lannister&#39;</code></pre><pre><code class="python">#练习1-c
df_words = df.assign(Words=df[&#39;Sentence&#39;].apply(lambda x:len(x.split()))).sort_values(by=&#39;Name&#39;)
df_words.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Release Date</th>
      <th>Season</th>
      <th>Episode</th>
      <th>Episode Title</th>
      <th>Name</th>
      <th>Sentence</th>
      <th>Words</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>276</th>
      <td>2011/4/17</td>
      <td>Season 1</td>
      <td>Episode 1</td>
      <td>Winter is Coming</td>
      <td>a voice</td>
      <td>It's Maester Luwin, my lord.</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3012</th>
      <td>2011/6/19</td>
      <td>Season 1</td>
      <td>Episode 10</td>
      <td>Fire and Blood</td>
      <td>addam marbrand</td>
      <td>ls it true about Stannis and Renly?</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3017</th>
      <td>2011/6/19</td>
      <td>Season 1</td>
      <td>Episode 10</td>
      <td>Fire and Blood</td>
      <td>addam marbrand</td>
      <td>Kevan Lannister</td>
      <td>2</td>
    </tr>
    <tr>
      <th>13610</th>
      <td>2014/6/8</td>
      <td>Season 4</td>
      <td>Episode 9</td>
      <td>The Watchers on the Wall</td>
      <td>aemon</td>
      <td>And what is it that couldn't wait until mornin...</td>
      <td>10</td>
    </tr>
    <tr>
      <th>13614</th>
      <td>2014/6/8</td>
      <td>Season 4</td>
      <td>Episode 9</td>
      <td>The Watchers on the Wall</td>
      <td>aemon</td>
      <td>Oh, no need. I know my way around this library...</td>
      <td>48</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">L_count = []
N_words = list(zip(df_words[&#39;Name&#39;],df_words[&#39;Words&#39;]))
for i in N_words:
    if i == N_words[0]:
        L_count.append(i[1])
        last = i[0]
    else:
        L_count.append(L_count[-1]+i[1] if i[0]==last else i[1])
        last = i[0]
df_words[&#39;Count&#39;]=L_count
df_words[&#39;Name&#39;][df_words[&#39;Count&#39;].idxmax()]</code></pre>
<pre><code>&#39;tyrion lannister&#39;</code></pre><pre><code class="python">#练习2-a
df = pd.read_csv(&#39;Documents/Pandas教程/joyful-pandas-master/data/Kobe_data.csv&#39;,index_col=&#39;shot_id&#39;)
df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>action_type</th>
      <th>combined_shot_type</th>
      <th>game_event_id</th>
      <th>game_id</th>
      <th>lat</th>
      <th>loc_x</th>
      <th>loc_y</th>
      <th>lon</th>
      <th>minutes_remaining</th>
      <th>period</th>
      <th>...</th>
      <th>shot_made_flag</th>
      <th>shot_type</th>
      <th>shot_zone_area</th>
      <th>shot_zone_basic</th>
      <th>shot_zone_range</th>
      <th>team_id</th>
      <th>team_name</th>
      <th>game_date</th>
      <th>matchup</th>
      <th>opponent</th>
    </tr>
    <tr>
      <th>shot_id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Jump Shot</td>
      <td>Jump Shot</td>
      <td>10</td>
      <td>20000012</td>
      <td>33.9723</td>
      <td>167</td>
      <td>72</td>
      <td>-118.1028</td>
      <td>10</td>
      <td>1</td>
      <td>...</td>
      <td>NaN</td>
      <td>2PT Field Goal</td>
      <td>Right Side(R)</td>
      <td>Mid-Range</td>
      <td>16-24 ft.</td>
      <td>1610612747</td>
      <td>Los Angeles Lakers</td>
      <td>2000/10/31</td>
      <td>LAL @ POR</td>
      <td>POR</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jump Shot</td>
      <td>Jump Shot</td>
      <td>12</td>
      <td>20000012</td>
      <td>34.0443</td>
      <td>-157</td>
      <td>0</td>
      <td>-118.4268</td>
      <td>10</td>
      <td>1</td>
      <td>...</td>
      <td>0.0</td>
      <td>2PT Field Goal</td>
      <td>Left Side(L)</td>
      <td>Mid-Range</td>
      <td>8-16 ft.</td>
      <td>1610612747</td>
      <td>Los Angeles Lakers</td>
      <td>2000/10/31</td>
      <td>LAL @ POR</td>
      <td>POR</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jump Shot</td>
      <td>Jump Shot</td>
      <td>35</td>
      <td>20000012</td>
      <td>33.9093</td>
      <td>-101</td>
      <td>135</td>
      <td>-118.3708</td>
      <td>7</td>
      <td>1</td>
      <td>...</td>
      <td>1.0</td>
      <td>2PT Field Goal</td>
      <td>Left Side Center(LC)</td>
      <td>Mid-Range</td>
      <td>16-24 ft.</td>
      <td>1610612747</td>
      <td>Los Angeles Lakers</td>
      <td>2000/10/31</td>
      <td>LAL @ POR</td>
      <td>POR</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jump Shot</td>
      <td>Jump Shot</td>
      <td>43</td>
      <td>20000012</td>
      <td>33.8693</td>
      <td>138</td>
      <td>175</td>
      <td>-118.1318</td>
      <td>6</td>
      <td>1</td>
      <td>...</td>
      <td>0.0</td>
      <td>2PT Field Goal</td>
      <td>Right Side Center(RC)</td>
      <td>Mid-Range</td>
      <td>16-24 ft.</td>
      <td>1610612747</td>
      <td>Los Angeles Lakers</td>
      <td>2000/10/31</td>
      <td>LAL @ POR</td>
      <td>POR</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Driving Dunk Shot</td>
      <td>Dunk</td>
      <td>155</td>
      <td>20000012</td>
      <td>34.0443</td>
      <td>0</td>
      <td>0</td>
      <td>-118.2698</td>
      <td>6</td>
      <td>2</td>
      <td>...</td>
      <td>1.0</td>
      <td>2PT Field Goal</td>
      <td>Center(C)</td>
      <td>Restricted Area</td>
      <td>Less Than 8 ft.</td>
      <td>1610612747</td>
      <td>Los Angeles Lakers</td>
      <td>2000/10/31</td>
      <td>LAL @ POR</td>
      <td>POR</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>




<pre><code class="python">pd.Series(list(zip(df[&#39;action_type&#39;],df[&#39;combined_shot_type&#39;]))).value_counts().index[0]</code></pre>
<pre><code>(&#39;Jump Shot&#39;, &#39;Jump Shot&#39;)</code></pre><pre><code class="python">#练习2-b
pd.Series(list(list(zip(*(pd.Series(list(zip(df[&#39;game_id&#39;],df[&#39;opponent&#39;])))
                          .unique()).tolist()))[1])).value_counts().index[0]</code></pre>
<pre><code>&#39;SAS&#39;</code></pre>]]></content>
      <categories>
        <category>Pandas教程</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Datawhale 零基础入门数据挖掘-Task5 模型融合</title>
    <url>/2020/04/02/Datawhale-%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task5-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<h1 id="Task5-模型融合"><a href="#Task5-模型融合" class="headerlink" title="Task5 模型融合"></a>Task5 模型融合</h1><p>Tip:此部分为零基础入门数据挖掘的 Task5 模型融合 部分，带你来了解各种模型结果的融合方式，在比赛的攻坚时刻冲刺Top。</p>
<a id="more"></a>
<h2 id="1-模型融合目标"><a href="#1-模型融合目标" class="headerlink" title="1 模型融合目标"></a>1 模型融合目标</h2><ol>
<li><p>对于多种调参完成的模型进行模型融合。</p>
</li>
<li><p>完成对于多种模型的融合，提交融合结果并打卡。</p>
</li>
</ol>
<h2 id="2-内容介绍"><a href="#2-内容介绍" class="headerlink" title="2 内容介绍"></a>2 内容介绍</h2><p>模型融合是比赛后期一个重要的环节，大体来说有如下的类型方式。</p>
<ol>
<li>简单加权融合:<br>回归（分类概率）：算术平均融合（Arithmetic mean），几何平均融合（Geometric mean）；<br>分类：投票（Voting)<br>综合：排序融合(Rank averaging)，log融合</li>
<li>stacking/blending:<br>构建多层模型，并利用预测结果再拟合预测。</li>
<li>boosting/bagging（在xgboost，Adaboost,GBDT中已经用到）:<br>多树的提升方法<h2 id="Stacking相关理论介绍"><a href="#Stacking相关理论介绍" class="headerlink" title="Stacking相关理论介绍"></a>Stacking相关理论介绍</h2><h3 id="什么是-stacking"><a href="#什么是-stacking" class="headerlink" title="什么是 stacking"></a>什么是 stacking</h3>简单来说 stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。</li>
</ol>
<p>将个体学习器结合在一起的时候使用的方法叫做结合策略。对于分类问题，我们可以使用投票法来选择输出最多的类。对于回归问题，我们可以将分类器输出的结果求平均值。</p>
<p>上面说的投票法和平均法都是很有效的结合策略，还有一种结合策略是使用另外一个机器学习算法来将个体机器学习器的结果结合在一起，这个方法就是Stacking。</p>
<p>在stacking方法中，我们把个体学习器叫做初级学习器，用于结合的学习器叫做次级学习器或元学习器（meta-learner），次级学习器用于训练的数据叫做次级训练集。次级训练集是在训练集上用初级学习器得到的。</p>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>天池</tag>
      </tags>
  </entry>
  <entry>
    <title>Datawhale-二手车价格预测Task4</title>
    <url>/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/</url>
    <content><![CDATA[<h1 id="Task4-建模调参"><a href="#Task4-建模调参" class="headerlink" title="Task4-建模调参"></a>Task4-建模调参</h1><p>这部分的学习目标是：了解常用的机器学习模型，并掌握机器学习模型的建模与调参流程。</p>
<a id="more"></a>
<h2 id="1-内容介绍"><a href="#1-内容介绍" class="headerlink" title="1 内容介绍"></a>1 内容介绍</h2><ol>
<li><p>线性回归模型：<br>线性回归对于特征的要求；<br>处理长尾分布；<br>理解线性回归模型；</p>
</li>
<li><p>模型性能验证：<br>评价函数与目标函数；<br>交叉验证方法；<br>留一验证方法；<br>针对时间序列问题的验证；<br>绘制学习率曲线；<br>绘制验证曲线；</p>
</li>
<li><p>嵌入式特征选择：<br>Lasso回归；<br>Ridge回归；<br>决策树；</p>
</li>
<li><p>模型对比：<br>常用线性模型；<br>常用非线性模型；</p>
</li>
<li><p>模型调参：<br>贪心调参方法；<br>网格调参方法；<br>贝叶斯调参方法</p>
</li>
</ol>
<h2 id="2-代码示例"><a href="#2-代码示例" class="headerlink" title="2 代码示例"></a>2 代码示例</h2><h3 id="2-1读取数据"><a href="#2-1读取数据" class="headerlink" title="2.1读取数据"></a>2.1读取数据</h3><pre><code class="python">import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(&#39;ignore&#39;)</code></pre>
<pre><code class="python">def reduce_mem_usage(df):
    &quot;&quot;&quot; iterate through all the columns of a dataframe and modify the data type
        to reduce memory usage.        
    &quot;&quot;&quot;
    start_mem = df.memory_usage().sum() 
    print(&#39;Memory usage of dataframe is {:.2f} MB&#39;.format(start_mem))

    for col in df.columns:
        col_type = df[col].dtype

        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == &#39;int&#39;:
                if c_min &gt; np.iinfo(np.int8).min and c_max &lt; np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min &gt; np.iinfo(np.int16).min and c_max &lt; np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min &gt; np.iinfo(np.int32).min and c_max &lt; np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min &gt; np.iinfo(np.int64).min and c_max &lt; np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min &gt; np.finfo(np.float16).min and c_max &lt; np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min &gt; np.finfo(np.float32).min and c_max &lt; np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        else:
            df[col] = df[col].astype(&#39;category&#39;)

    end_mem = df.memory_usage().sum() 
    print(&#39;Memory usage after optimization is: {:.2f} MB&#39;.format(end_mem))
    print(&#39;Decreased by {:.1f}%&#39;.format(100 * (start_mem - end_mem) / start_mem))
    return df</code></pre>
<pre><code class="python">sample_feature = reduce_mem_usage(pd.read_csv(&#39;data_for_tree.csv&#39;))</code></pre>
<pre><code>Memory usage of dataframe is 62099672.00 MB
Memory usage after optimization is: 16520303.00 MB
Decreased by 73.4%</code></pre><pre><code class="python">continuous_feature_names = [x for x in sample_feature.columns if x not in [&#39;price&#39;,&#39;brand&#39;,&#39;model&#39;,&#39;brand&#39;]]</code></pre>
<h3 id="2-2线性回归-amp-五折交叉验证-amp-模拟真实业务情况"><a href="#2-2线性回归-amp-五折交叉验证-amp-模拟真实业务情况" class="headerlink" title="2.2线性回归 &amp; 五折交叉验证 &amp; 模拟真实业务情况"></a>2.2线性回归 &amp; 五折交叉验证 &amp; 模拟真实业务情况</h3><pre><code class="python">sample_feature = sample_feature.dropna().replace(&#39;-&#39;, 0).reset_index(drop=True)
sample_feature[&#39;notRepairedDamage&#39;] = sample_feature[&#39;notRepairedDamage&#39;].astype(np.float32)
train = sample_feature[continuous_feature_names + [&#39;price&#39;]]

train_X = train[continuous_feature_names]
train_y = train[&#39;price&#39;]</code></pre>
<h4 id="简单建模"><a href="#简单建模" class="headerlink" title="简单建模"></a>简单建模</h4><pre><code class="python">from sklearn.linear_model import LinearRegression</code></pre>
<pre><code class="python">model = LinearRegression(normalize=True)</code></pre>
<pre><code class="python">model = model.fit(train_X, train_y)</code></pre>
<p>查看训练的线性回归模型的截距（intercept）与权重(coef)：</p>
<pre><code class="python">&#39;intercept:&#39;+ str(model.intercept_)

sorted(dict(zip(continuous_feature_names, model.coef_)).items(), key=lambda x:x[1], reverse=True)</code></pre>
<pre><code>[(&#39;v_6&#39;, 3367064.3416419057),
 (&#39;v_8&#39;, 700675.560939892),
 (&#39;v_9&#39;, 170630.27723222843),
 (&#39;v_7&#39;, 32322.661932036997),
 (&#39;v_12&#39;, 20473.67079699449),
 (&#39;v_3&#39;, 17868.079541513765),
 (&#39;v_11&#39;, 11474.938996727224),
 (&#39;v_13&#39;, 11261.76456002154),
 (&#39;v_10&#39;, 2683.920090598985),
 (&#39;gearbox&#39;, 881.822503924978),
 (&#39;fuelType&#39;, 363.9042507217718),
 (&#39;bodyType&#39;, 189.6027101206811),
 (&#39;city&#39;, 44.94975120523234),
 (&#39;power&#39;, 28.55390161675385),
 (&#39;brand_price_median&#39;, 0.510372813407827),
 (&#39;brand_price_std&#39;, 0.4503634709262942),
 (&#39;brand_amount&#39;, 0.14881120395066458),
 (&#39;brand_price_max&#39;, 0.0031910186703154246),
 (&#39;SaleID&#39;, 5.355989919860341e-05),
 (&#39;offerType&#39;, 1.085083931684494e-05),
 (&#39;seller&#39;, -1.564621925354004e-07),
 (&#39;train&#39;, -9.801937267184258e-06),
 (&#39;brand_price_sum&#39;, -2.1750068681877473e-05),
 (&#39;name&#39;, -0.00029800127130055304),
 (&#39;used_time&#39;, -0.002515894332882901),
 (&#39;brand_price_average&#39;, -0.40490484510106556),
 (&#39;brand_price_min&#39;, -2.2467753486891016),
 (&#39;power_bin&#39;, -34.420644117280766),
 (&#39;v_14&#39;, -274.78411807803394),
 (&#39;kilometer&#39;, -372.8975266607397),
 (&#39;notRepairedDamage&#39;, -495.19038446291916),
 (&#39;v_0&#39;, -2045.0549573549322),
 (&#39;v_5&#39;, -11022.986240482482),
 (&#39;v_4&#39;, -15121.731109861388),
 (&#39;v_2&#39;, -26098.29992056384),
 (&#39;v_1&#39;, -45556.18929727631)]</code></pre><pre><code class="python">from matplotlib import pyplot as plt</code></pre>
<pre><code class="python">subsample_index = np.random.randint(low=0, high=len(train_y), size=50)</code></pre>
<pre><code class="python">plt.scatter(train_X[&#39;v_9&#39;][subsample_index], train_y[subsample_index], color=&#39;black&#39;)
plt.scatter(train_X[&#39;v_9&#39;][subsample_index], model.predict(train_X.loc[subsample_index]), color=&#39;blue&#39;)
plt.xlabel(&#39;v_9&#39;)
plt.ylabel(&#39;price&#39;)
plt.legend([&#39;True Price&#39;,&#39;Predicted Price&#39;],loc=&#39;upper right&#39;)
print(&#39;The predicted price is obvious different from true price&#39;)
plt.show()</code></pre>
<pre><code>The predicted price is obvious different from true price</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_15_1.png" alt="png"></p>
<pre><code class="python">import seaborn as sns
print(&#39;It is clear to see the price shows a typical exponential distribution&#39;)
plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
sns.distplot(train_y)
plt.subplot(1,2,2)
sns.distplot(train_y[train_y &lt; np.quantile(train_y, 0.9)])</code></pre>
<pre><code>It is clear to see the price shows a typical exponential distribution





&lt;matplotlib.axes._subplots.AxesSubplot at 0x1246a9f50&gt;</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_16_2.png" alt="png"></p>
<pre><code class="python">train_y_ln = np.log(train_y + 1)</code></pre>
<pre><code class="python">import seaborn as sns
print(&#39;The transformed price seems like normal distribution&#39;)
plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
sns.distplot(train_y_ln)
plt.subplot(1,2,2)
sns.distplot(train_y_ln[train_y_ln &lt; np.quantile(train_y_ln, 0.9)])</code></pre>
<pre><code>The transformed price seems like normal distribution





&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a2a8ca390&gt;</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_18_2.png" alt="png"></p>
<pre><code class="python">model = model.fit(train_X, train_y_ln)

print(&#39;intercept:&#39;+ str(model.intercept_))
sorted(dict(zip(continuous_feature_names, model.coef_)).items(), key=lambda x:x[1], reverse=True)</code></pre>
<pre><code>intercept:18.75074946555847





[(&#39;v_9&#39;, 8.052409900567731),
 (&#39;v_5&#39;, 5.764236596654289),
 (&#39;v_12&#39;, 1.6182081236824377),
 (&#39;v_1&#39;, 1.4798310582980099),
 (&#39;v_11&#39;, 1.166901656362573),
 (&#39;v_13&#39;, 0.9404711296038616),
 (&#39;v_7&#39;, 0.713727308356608),
 (&#39;v_3&#39;, 0.6837875771100316),
 (&#39;v_0&#39;, 0.008500518010162533),
 (&#39;power_bin&#39;, 0.008497969302895451),
 (&#39;gearbox&#39;, 0.007922377278326771),
 (&#39;fuelType&#39;, 0.006684769706822626),
 (&#39;bodyType&#39;, 0.00452352009270304),
 (&#39;power&#39;, 0.000716189420535552),
 (&#39;brand_price_min&#39;, 3.334351114749525e-05),
 (&#39;brand_amount&#39;, 2.897879704277287e-06),
 (&#39;brand_price_median&#39;, 1.2571172873067898e-06),
 (&#39;brand_price_std&#39;, 6.659176363472789e-07),
 (&#39;brand_price_max&#39;, 6.194956307515058e-07),
 (&#39;brand_price_average&#39;, 5.999345964992107e-07),
 (&#39;SaleID&#39;, 2.1194170039649608e-08),
 (&#39;offerType&#39;, 1.4733814168721437e-10),
 (&#39;train&#39;, 1.0828671292983927e-11),
 (&#39;seller&#39;, -6.533440455314121e-11),
 (&#39;brand_price_sum&#39;, -1.5126504215917122e-10),
 (&#39;name&#39;, -7.015512588913706e-08),
 (&#39;used_time&#39;, -4.122479372350841e-06),
 (&#39;city&#39;, -0.0022187824810423534),
 (&#39;v_14&#39;, -0.004234223418139086),
 (&#39;kilometer&#39;, -0.013835866226883525),
 (&#39;notRepairedDamage&#39;, -0.2702794234984643),
 (&#39;v_4&#39;, -0.8315701200997693),
 (&#39;v_2&#39;, -0.9470842241656942),
 (&#39;v_10&#39;, -1.626146668976213),
 (&#39;v_8&#39;, -40.34300748761572),
 (&#39;v_6&#39;, -238.79036385506865)]</code></pre><pre><code class="python">plt.scatter(train_X[&#39;v_9&#39;][subsample_index], train_y[subsample_index], color=&#39;black&#39;)
plt.scatter(train_X[&#39;v_9&#39;][subsample_index], np.exp(model.predict(train_X.loc[subsample_index])), color=&#39;blue&#39;)
plt.xlabel(&#39;v_9&#39;)
plt.ylabel(&#39;price&#39;)
plt.legend([&#39;True Price&#39;,&#39;Predicted Price&#39;],loc=&#39;upper right&#39;)
print(&#39;The predicted price seems normal after np.log transforming&#39;)
plt.show()</code></pre>
<pre><code>The predicted price seems normal after np.log transforming</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_20_1.png" alt="png"></p>
<h4 id="五折交叉验证"><a href="#五折交叉验证" class="headerlink" title="五折交叉验证"></a>五折交叉验证</h4><p>在使用训练集对参数进行训练的时候，经常会发现人们通常会将一整个训练集分为三个部分（比如mnist手写训练集）。一般分为：训练集（train_set），评估集（valid_set），测试集（test_set）这三个部分。这其实是为了保证训练效果而特意设置的。其中测试集很好理解，其实就是完全不参与训练的数据，仅仅用来观测测试效果的数据。而训练集和评估集则牵涉到下面的知识了。</p>
<p>因为在实际的训练中，训练的结果对于训练集的拟合程度通常还是挺好的（初始条件敏感），但是对于训练集之外的数据的拟合程度通常就不那么令人满意了。因此我们通常并不会把所有的数据集都拿来训练，而是分出一部分来（这一部分不参加训练）对训练集生成的参数进行测试，相对客观的判断这些参数对训练集之外的数据的符合程度。这种思想就称为交叉验证（Cross Validation）</p>
<pre><code class="python">from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_absolute_error,  make_scorer</code></pre>
<pre><code class="python">def log_transfer(func):
    def wrapper(y, yhat):
        result = func(np.log(y), np.nan_to_num(np.log(yhat)))
        return result
    return wrapper</code></pre>
<pre><code class="python">scores = cross_val_score(model, X=train_X, y=train_y, verbose=1, cv = 5, scoring=make_scorer(log_transfer(mean_absolute_error)))</code></pre>
<pre><code>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished</code></pre><pre><code class="python">print(&#39;AVG:&#39;, np.mean(scores))</code></pre>
<pre><code>AVG: 1.3658023920314182</code></pre><pre><code class="python">scores = cross_val_score(model, X=train_X, y=train_y_ln, verbose=1, cv = 5, scoring=make_scorer(mean_absolute_error))</code></pre>
<pre><code>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished</code></pre><pre><code class="python">print(&#39;AVG:&#39;, np.mean(scores))</code></pre>
<pre><code>AVG: 0.19325301837047415</code></pre><pre><code class="python">scores = pd.DataFrame(scores.reshape(1,-1))
scores.columns = [&#39;cv&#39; + str(x) for x in range(1, 6)]
scores.index = [&#39;MAE&#39;]
scores</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cv1</th>
      <th>cv2</th>
      <th>cv3</th>
      <th>cv4</th>
      <th>cv5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MAE</th>
      <td>0.190792</td>
      <td>0.193758</td>
      <td>0.194132</td>
      <td>0.191825</td>
      <td>0.195758</td>
    </tr>
  </tbody>
</table>
</div>



<h4 id="模拟真实业务情况"><a href="#模拟真实业务情况" class="headerlink" title="模拟真实业务情况"></a>模拟真实业务情况</h4><p>但在事实上，由于我们并不具有预知未来的能力，五折交叉验证在某些与时间相关的数据集上反而反映了不真实的情况。通过2018年的二手车价格预测2017年的二手车价格，这显然是不合理的，因此我们还可以采用时间顺序对数据集进行分隔。在本例中，我们选用靠前时间的4/5样本当作训练集，靠后时间的1/5当作验证集，最终结果与五折交叉验证差距不大。</p>
<pre><code class="python">import datetime</code></pre>
<pre><code class="python">sample_feature = sample_feature.reset_index(drop=True)</code></pre>
<pre><code class="python">split_point = len(sample_feature) // 5 * 4</code></pre>
<pre><code class="python">train = sample_feature.loc[:split_point].dropna()
val = sample_feature.loc[split_point:].dropna()

train_X = train[continuous_feature_names]
train_y_ln = np.log(train[&#39;price&#39;] + 1)
val_X = val[continuous_feature_names]
val_y_ln = np.log(val[&#39;price&#39;] + 1)</code></pre>
<pre><code class="python">model = model.fit(train_X, train_y_ln)</code></pre>
<pre><code class="python">mean_absolute_error(val_y_ln, model.predict(val_X))</code></pre>
<pre><code>0.19577667270300972</code></pre><h4 id="绘制学习率曲线与验证曲线"><a href="#绘制学习率曲线与验证曲线" class="headerlink" title="绘制学习率曲线与验证曲线"></a>绘制学习率曲线与验证曲线</h4><pre><code class="python">from sklearn.model_selection import learning_curve, validation_curve</code></pre>
<pre><code class="python">? learning_curve</code></pre>
<pre><code class="python">def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,n_jobs=1, train_size=np.linspace(.1, 1.0, 5 )):  
    plt.figure()  
    plt.title(title)  
    if ylim is not None:  
        plt.ylim(*ylim)  
    plt.xlabel(&#39;Training example&#39;)  
    plt.ylabel(&#39;score&#39;)  
    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_size, scoring = make_scorer(mean_absolute_error))  
    train_scores_mean = np.mean(train_scores, axis=1)  
    train_scores_std = np.std(train_scores, axis=1)  
    test_scores_mean = np.mean(test_scores, axis=1)  
    test_scores_std = np.std(test_scores, axis=1)  
    plt.grid()#区域  
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,  
                     train_scores_mean + train_scores_std, alpha=0.1,  
                     color=&quot;r&quot;)  
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,  
                     test_scores_mean + test_scores_std, alpha=0.1,  
                     color=&quot;g&quot;)  
    plt.plot(train_sizes, train_scores_mean, &#39;o-&#39;, color=&#39;r&#39;,  
             label=&quot;Training score&quot;)  
    plt.plot(train_sizes, test_scores_mean,&#39;o-&#39;,color=&quot;g&quot;,  
             label=&quot;Cross-validation score&quot;)  
    plt.legend(loc=&quot;best&quot;)  
    return plt  </code></pre>
<pre><code class="python">plot_learning_curve(LinearRegression(), &#39;Liner_model&#39;, train_X[:1000], train_y_ln[:1000], ylim=(0.0, 0.5), cv=5, n_jobs=1)  </code></pre>
<pre><code>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/opt/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py&#39;&gt;</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_40_1.png" alt="png"></p>
<h4 id="多种模型对比"><a href="#多种模型对比" class="headerlink" title="多种模型对比"></a>多种模型对比</h4><pre><code class="python">train = sample_feature[continuous_feature_names + [&#39;price&#39;]].dropna()

train_X = train[continuous_feature_names]
train_y = train[&#39;price&#39;]
train_y_ln = np.log(train_y + 1)</code></pre>
<h5 id="线性模型-amp-嵌入式特征选择"><a href="#线性模型-amp-嵌入式特征选择" class="headerlink" title="线性模型 &amp; 嵌入式特征选择"></a>线性模型 &amp; 嵌入式特征选择</h5><pre><code class="python">from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso</code></pre>
<pre><code class="python">models = [LinearRegression(),
          Ridge(),
          Lasso()]</code></pre>
<pre><code class="python">result = dict()
for model in models:
    model_name = str(model).split(&#39;(&#39;)[0]
    scores = cross_val_score(model, X=train_X, y=train_y_ln, verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error))
    result[model_name] = scores
    print(model_name + &#39; is finished&#39;)</code></pre>
<pre><code>LinearRegression is finished
Ridge is finished
Lasso is finished</code></pre><pre><code class="python">result = pd.DataFrame(result)
result.index = [&#39;cv&#39; + str(x) for x in range(1, 6)]
result</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LinearRegression</th>
      <th>Ridge</th>
      <th>Lasso</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cv1</th>
      <td>0.190792</td>
      <td>0.194832</td>
      <td>0.383899</td>
    </tr>
    <tr>
      <th>cv2</th>
      <td>0.193758</td>
      <td>0.197632</td>
      <td>0.381893</td>
    </tr>
    <tr>
      <th>cv3</th>
      <td>0.194132</td>
      <td>0.198123</td>
      <td>0.384090</td>
    </tr>
    <tr>
      <th>cv4</th>
      <td>0.191825</td>
      <td>0.195670</td>
      <td>0.380526</td>
    </tr>
    <tr>
      <th>cv5</th>
      <td>0.195758</td>
      <td>0.199676</td>
      <td>0.383611</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python">model = LinearRegression().fit(train_X, train_y_ln)
print(&#39;intercept:&#39;+ str(model.intercept_))
sns.barplot(abs(model.coef_), continuous_feature_names)</code></pre>
<pre><code>intercept:18.747877090866396





&lt;matplotlib.axes._subplots.AxesSubplot at 0x122af1510&gt;</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_48_2.png" alt="png"></p>
<p>L2正则化在拟合过程中通常都倾向于让权值尽可能小，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，专业一点的说法是『抗扰动能力强』</p>
<pre><code class="python">model = Ridge().fit(train_X, train_y_ln)
print(&#39;intercept:&#39;+ str(model.intercept_))
sns.barplot(abs(model.coef_), continuous_feature_names)</code></pre>
<pre><code>intercept:4.6717097880636445





&lt;matplotlib.axes._subplots.AxesSubplot at 0x122afafd0&gt;</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_50_2.png" alt="png"></p>
<p>L1正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择。如下图，我们发现power与userd_time特征非常重要。</p>
<pre><code class="python">model = Lasso().fit(train_X, train_y_ln)
print(&#39;intercept:&#39;+ str(model.intercept_))
sns.barplot(abs(model.coef_), continuous_feature_names)</code></pre>
<pre><code>intercept:8.672182402894254





&lt;matplotlib.axes._subplots.AxesSubplot at 0x12483b050&gt;</code></pre><p><img src="/2020/03/30/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask4/output_52_2.png" alt="png"></p>
<h5 id="非线性模型"><a href="#非线性模型" class="headerlink" title="非线性模型"></a>非线性模型</h5><h4 id="模型调参"><a href="#模型调参" class="headerlink" title="模型调参"></a>模型调参</h4><pre><code class="python">## LGB的参数集合：

objective = [&#39;regression&#39;, &#39;regression_l1&#39;, &#39;mape&#39;, &#39;huber&#39;, &#39;fair&#39;]

num_leaves = [3,5,10,15,20,40, 55]
max_depth = [3,5,10,15,20,40, 55]
bagging_fraction = []
feature_fraction = []
drop_rate = []</code></pre>
<h5 id="贪心调参"><a href="#贪心调参" class="headerlink" title="贪心调参"></a>贪心调参</h5><pre><code class="python">best_obj = dict()
for obj in objective:
    model = LGBMRegressor(objective=obj)
    score = np.mean(cross_val_score(model, X=train_X, y=train_y_ln, verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error)))
    best_obj[obj] = score

best_leaves = dict()
for leaves in num_leaves:
    model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0], num_leaves=leaves)
    score = np.mean(cross_val_score(model, X=train_X, y=train_y_ln, verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error)))
    best_leaves[leaves] = score

best_depth = dict()
for depth in max_depth:
    model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0],
                          num_leaves=min(best_leaves.items(), key=lambda x:x[1])[0],
                          max_depth=depth)
    score = np.mean(cross_val_score(model, X=train_X, y=train_y_ln, verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error)))
    best_depth[depth] = score</code></pre>
<pre><code class="python">sns.lineplot(x=[&#39;0_initial&#39;,&#39;1_turning_obj&#39;,&#39;2_turning_leaves&#39;,&#39;3_turning_depth&#39;], y=[0.143 ,min(best_obj.values()), min(best_leaves.values()), min(best_depth.values())])</code></pre>
<h5 id="Grid-Search-调参"><a href="#Grid-Search-调参" class="headerlink" title="Grid Search 调参"></a>Grid Search 调参</h5><pre><code class="python">from sklearn.model_selection import GridSearchCV</code></pre>
<pre><code class="python">parameters = {&#39;objective&#39;: objective , &#39;num_leaves&#39;: num_leaves, &#39;max_depth&#39;: max_depth}
model = LGBMRegressor()
clf = GridSearchCV(model, parameters, cv=5)
clf = clf.fit(train_X, train_y)
clf.best_params_
model = LGBMRegressor(objective=&#39;regression&#39;,
                          num_leaves=55,
                          max_depth=15)
np.mean(cross_val_score(model, X=train_X, y=train_y_ln, verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error)))</code></pre>
<h5 id="贝叶斯调参"><a href="#贝叶斯调参" class="headerlink" title="贝叶斯调参"></a>贝叶斯调参</h5><pre><code class="python">from bayes_opt import BayesianOptimization</code></pre>
<pre><code class="python">def rf_cv(num_leaves, max_depth, subsample, min_child_samples):
    val = cross_val_score(
        LGBMRegressor(objective = &#39;regression_l1&#39;,
            num_leaves=int(num_leaves),
            max_depth=int(max_depth),
            subsample = subsample,
            min_child_samples = int(min_child_samples)
        ),
        X=train_X, y=train_y_ln, verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error)
    ).mean()
    return 1 - val</code></pre>
<pre><code class="python">rf_bo = BayesianOptimization(
    rf_cv,
    {
    &#39;num_leaves&#39;: (2, 100),
    &#39;max_depth&#39;: (2, 100),
    &#39;subsample&#39;: (0.1, 1),
    &#39;min_child_samples&#39; : (2, 100)
    }
)
rf_bo.maximize()
1 - rf_bo.max[&#39;target&#39;]</code></pre>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>天池</tag>
      </tags>
  </entry>
  <entry>
    <title>FIT5216 Workshop-GraghLabel&amp;PowerGen</title>
    <url>/2020/03/28/FIT5216-Workshop-GraghLabel-PowerGen/</url>
    <content><![CDATA[<p>这两个题目是在第二周的workshop上讨论做的，第一道简单，第二道有点难，难在miniizinc的语法，最好记住。</p>
<a id="more"></a>

<h1 id="GraghLabel"><a href="#GraghLabel" class="headerlink" title="GraghLabel"></a>GraghLabel</h1><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p><img src="/2020/03/28/FIT5216-Workshop-GraghLabel-PowerGen/image-20200328111720203.png" alt="image-20200328111720203"></p>
<p><img src="/2020/03/28/FIT5216-Workshop-GraghLabel-PowerGen/image-20200328111736614.png" alt="image-20200328111736614"></p>
<h2 id="Answers"><a href="#Answers" class="headerlink" title="Answers"></a>Answers</h2><pre><code class="python">var 1..8:a;
var 1..8:b;
var 1..8:c;
var 1..8:d;
var 1..8:e;
var 1..8:f;
var 1..8:g;
var 1..8:h;

constraint abs(a-b)&gt;1;
constraint abs(a-c)&gt;1;
constraint abs(a-d)&gt;1;
constraint abs(b-e)&gt;1;
constraint abs(b-f)&gt;1;
constraint abs(b-c)&gt;1;
constraint abs(c-e)&gt;1;
constraint abs(c-f)&gt;1;
constraint abs(c-d)&gt;1;
constraint abs(c-g)&gt;1;
constraint abs(d-f)&gt;1;
constraint abs(d-g)&gt;1;
constraint abs(e-h)&gt;1;
constraint abs(e-f)&gt;1;
constraint abs(f-h)&gt;1;
constraint abs(f-g)&gt;1;
constraint abs(g-h)&gt;1;
include &quot;alldifferent.mzn&quot;;
constraint alldifferent([a,b,c,d,e,f,g,h]);</code></pre>
<h1 id="PowerGen"><a href="#PowerGen" class="headerlink" title="PowerGen"></a>PowerGen</h1><h2 id="Problem-Statement-1"><a href="#Problem-Statement-1" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p><img src="/2020/03/28/FIT5216-Workshop-GraghLabel-PowerGen/image-20200328111858984.png" alt="image-20200328111858984"></p>
<p><img src="/2020/03/28/FIT5216-Workshop-GraghLabel-PowerGen/image-20200328111916857.png" alt="image-20200328111916857"></p>
<h2 id="Answers-1"><a href="#Answers-1" class="headerlink" title="Answers"></a>Answers</h2><pre><code class="python">% power generation
int: T;                 % decades
array[1..T] of int: e;  % expected requirements
array[1..T] of int: a;  % current production

array[1..T] of var 0..infinity: N; % number of nuclear power plants built each decade
array[1..T] of var 0..infinity: C; % number of coal power plants built each decade
array[1..T] of var 0..infinity: S; % number of solar power plants built each decade

var 0..infinity: cost;  % costs of building all new power plants

constraint forall ( i in 1..T ) (
   sum ( j in max(1,i-5)..i ) ( N[j] * 4 ) + sum ( j in max(1,i-1)..i ) ( C[j] ) + sum ( j in max(1,i-2)..i ) ( S[j] ) &gt;= e[i] - a[i]
);

constraint forall ( i in 1..T ) (
   sum ( j in max(1,i-5)..i ) ( N[j] * 4 ) &lt;= 0.4 * ( a[i] + sum ( j in max(1,i-5)..i ) ( N[j] * 4 ) + sum ( j in max(1,i-1)..i ) ( C[j] ) + sum ( j in max(1,i-2)..i ) ( S[j] ) )
);

constraint forall ( i in 1..T ) (
   sum ( j in max(1,i-2)..i ) ( S[j] ) &gt;= 0.2 * ( a[i] + sum ( j in max(1,i-5)..i ) ( N[j] * 4 ) + sum ( j in max(1,i-1)..i ) ( C[j] ) + sum ( j in max(1,i-2)..i ) ( S[j] ) )
);

constraint C[1] + sum ( i in 2..T ) ( C[i] + C[i-1] ) &lt;= 10;

cost = sum ( i in 1..T ) ( N[i] * 10 + C[i] + S[i] * 2 );

solve minimize cost;

</code></pre>
]]></content>
      <categories>
        <category>FIT5216 Modelling Discrete Optimization Problems</category>
      </categories>
      <tags>
        <tag>-FIT5216 Week2</tag>
      </tags>
  </entry>
  <entry>
    <title>Datawhale 二手车价格预测Task3</title>
    <url>/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/</url>
    <content><![CDATA[<h2 id="Task3-特征工程"><a href="#Task3-特征工程" class="headerlink" title="Task3-特征工程"></a>Task3-特征工程</h2><p>特征工程的主要目的还是在于将数据转换为能更好地表示潜在问题的特征，从而提高机器学习的性能。比如，异常值处理是为了去除噪声，填补缺失值可以加入先验知识等。特征构造也属于特征工程的一部分，其目的是为了增强数据的表达。</p>
<a id="more"></a>

<h3 id="3-1-内容介绍"><a href="#3-1-内容介绍" class="headerlink" title="3.1 内容介绍"></a>3.1 内容介绍</h3><p>常见的特征工程包括：</p>
<ol>
<li><p>异常处理：<br>通过箱线图（或 3-Sigma）分析删除异常值；<br>BOX-COX 转换（处理有偏分布）；<br>长尾截断；</p>
</li>
<li><p>特征归一化/标准化：<br>标准化（转换为标准正态分布）；<br>归一化（抓换到 [0,1] 区间）；<br>针对幂律分布，可以采用公式<math xmlns="http://www.w3.org/1998/Math/MathML"><br><mi>l</mi><br><mi>o</mi><br><mi>g</mi><br><mo stretchy="false">(</mo></math></p>
<mfrac>
 <mrow>
   <mn>1</mn>
   <mo>+</mo>
   <mi>x</mi>
 </mrow>
 <mrow>
   <mn>1</mn>
   <mo>+</mo>
   <mi>m</mi>
   <mi>e</mi>
   <mi>d</mi>
   <mi>i</mi>
   <mi>a</mi>
   <mi>n</mi>
 </mrow>
</mfrac>
<mo stretchy="false">)</mo>

</li>
<li><p>数据分桶：<br>等频分桶；<br>等距分桶；<br>Best-KS 分桶（类似利用基尼指数进行二分类）；<br>卡方分桶；</p>
</li>
<li><p>缺失值处理：<br>不处理（针对类似 XGBoost 等树模型）；<br>删除（缺失数据太多）；<br>插值补全，包括均值/中位数/众数/建模预测/多重插补/压缩感知补全/矩阵补全等；<br>分箱，缺失值一个箱；</p>
</li>
<li><p>特征构造：<br>构造统计量特征，报告计数、求和、比例、标准差等；<br>时间特征，包括相对时间和绝对时间，节假日，双休日等；<br>地理信息，包括分箱，分布编码等方法；<br>非线性变换，包括 log/ 平方/ 根号等；<br>特征组合，特征交叉；<br>仁者见仁，智者见智。</p>
</li>
<li><p>特征筛选<br>过滤式（filter）：先对数据进行特征选择，然后在训练学习器，常见的方法有 Relief/方差选择发/相关系数法/卡方检验法/互信息法；<br>包裹式（wrapper）：直接把最终将要使用的学习器的性能作为特征子集的评价准则，常见方法有 LVM（Las Vegas Wrapper） ；<br>嵌入式（embedding）：结合过滤式和包裹式，学习器训练过程中自动进行了特征选择，常见的有 lasso 回归；</p>
</li>
<li><p>降维<br>PCA/ LDA/ ICA；<br>特征选择也是一种降维。</p>
</li>
</ol>
<h3 id="3-2-代码示例"><a href="#3-2-代码示例" class="headerlink" title="3.2 代码示例"></a>3.2 代码示例</h3><h4 id="3-2-0-导入数据"><a href="#3-2-0-导入数据" class="headerlink" title="3.2.0 导入数据"></a>3.2.0 导入数据</h4><pre><code class="python">import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from operator import itemgetter

%matplotlib inline</code></pre>
<pre><code class="python">path = &#39;./tianchi/&#39;
Train_data = pd.read_csv(path+&#39;used_car_train_20200313.csv&#39;, sep=&#39; &#39;)
Test_data = pd.read_csv(path+&#39;used_car_testA_20200313.csv&#39;, sep=&#39; &#39;)
print(Train_data.shape)
print(Test_data.shape)</code></pre>
<pre><code>(150000, 31)
(50000, 30)</code></pre><pre><code class="python">Train_data.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>736</td>
      <td>20040402</td>
      <td>30.0</td>
      <td>6</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.235676</td>
      <td>0.101988</td>
      <td>0.129549</td>
      <td>0.022816</td>
      <td>0.097462</td>
      <td>-2.881803</td>
      <td>2.804097</td>
      <td>-2.420821</td>
      <td>0.795292</td>
      <td>0.914762</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2262</td>
      <td>20030301</td>
      <td>40.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.264777</td>
      <td>0.121004</td>
      <td>0.135731</td>
      <td>0.026597</td>
      <td>0.020582</td>
      <td>-4.900482</td>
      <td>2.096338</td>
      <td>-1.030483</td>
      <td>-1.722674</td>
      <td>0.245522</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>14874</td>
      <td>20040403</td>
      <td>115.0</td>
      <td>15</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>163</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.251410</td>
      <td>0.114912</td>
      <td>0.165147</td>
      <td>0.062173</td>
      <td>0.027075</td>
      <td>-4.846749</td>
      <td>1.803559</td>
      <td>1.565330</td>
      <td>-0.832687</td>
      <td>-0.229963</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>71865</td>
      <td>19960908</td>
      <td>109.0</td>
      <td>10</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>193</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.274293</td>
      <td>0.110300</td>
      <td>0.121964</td>
      <td>0.033395</td>
      <td>0.000000</td>
      <td>-4.509599</td>
      <td>1.285940</td>
      <td>-0.501868</td>
      <td>-2.438353</td>
      <td>-0.478699</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>111080</td>
      <td>20120103</td>
      <td>110.0</td>
      <td>5</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>68</td>
      <td>5.0</td>
      <td>...</td>
      <td>0.228036</td>
      <td>0.073205</td>
      <td>0.091880</td>
      <td>0.078819</td>
      <td>0.121534</td>
      <td>-1.896240</td>
      <td>0.910783</td>
      <td>0.931110</td>
      <td>2.834518</td>
      <td>1.923482</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>




<pre><code class="python">Train_data.columns</code></pre>
<pre><code>Index([&#39;SaleID&#39;, &#39;name&#39;, &#39;regDate&#39;, &#39;model&#39;, &#39;brand&#39;, &#39;bodyType&#39;, &#39;fuelType&#39;,
       &#39;gearbox&#39;, &#39;power&#39;, &#39;kilometer&#39;, &#39;notRepairedDamage&#39;, &#39;regionCode&#39;,
       &#39;seller&#39;, &#39;offerType&#39;, &#39;creatDate&#39;, &#39;price&#39;, &#39;v_0&#39;, &#39;v_1&#39;, &#39;v_2&#39;, &#39;v_3&#39;,
       &#39;v_4&#39;, &#39;v_5&#39;, &#39;v_6&#39;, &#39;v_7&#39;, &#39;v_8&#39;, &#39;v_9&#39;, &#39;v_10&#39;, &#39;v_11&#39;, &#39;v_12&#39;,
       &#39;v_13&#39;, &#39;v_14&#39;],
      dtype=&#39;object&#39;)</code></pre><pre><code class="python">Test_data.columns</code></pre>
<pre><code>Index([&#39;SaleID&#39;, &#39;name&#39;, &#39;regDate&#39;, &#39;model&#39;, &#39;brand&#39;, &#39;bodyType&#39;, &#39;fuelType&#39;,
       &#39;gearbox&#39;, &#39;power&#39;, &#39;kilometer&#39;, &#39;notRepairedDamage&#39;, &#39;regionCode&#39;,
       &#39;seller&#39;, &#39;offerType&#39;, &#39;creatDate&#39;, &#39;v_0&#39;, &#39;v_1&#39;, &#39;v_2&#39;, &#39;v_3&#39;, &#39;v_4&#39;,
       &#39;v_5&#39;, &#39;v_6&#39;, &#39;v_7&#39;, &#39;v_8&#39;, &#39;v_9&#39;, &#39;v_10&#39;, &#39;v_11&#39;, &#39;v_12&#39;, &#39;v_13&#39;,
       &#39;v_14&#39;],
      dtype=&#39;object&#39;)</code></pre><h4 id="3-2-1-删除异常值"><a href="#3-2-1-删除异常值" class="headerlink" title="3.2.1 删除异常值"></a>3.2.1 删除异常值</h4><pre><code class="python"># 这里我包装了一个异常值处理的代码，可以随便调用。
def outliers_proc(data, col_name, scale=3):
    &quot;&quot;&quot;
    用于清洗异常值，默认用 box_plot（scale=3）进行清洗
    :param data: 接收 pandas 数据格式
    :param col_name: pandas 列名
    :param scale: 尺度
    :return:
    &quot;&quot;&quot;

    def box_plot_outliers(data_ser, box_scale):
        &quot;&quot;&quot;
        利用箱线图去除异常值
        :param data_ser: 接收 pandas.Series 数据格式
        :param box_scale: 箱线图尺度，
        :return:
        &quot;&quot;&quot;
        iqr = box_scale * (data_ser.quantile(0.75) - data_ser.quantile(0.25))
        val_low = data_ser.quantile(0.25) - iqr
        val_up = data_ser.quantile(0.75) + iqr
        rule_low = (data_ser &lt; val_low)
        rule_up = (data_ser &gt; val_up)
        return (rule_low, rule_up), (val_low, val_up)

    data_n = data.copy()
    data_series = data_n[col_name]
    rule, value = box_plot_outliers(data_series, box_scale=scale)
    index = np.arange(data_series.shape[0])[rule[0] | rule[1]]
    print(&quot;Delete number is: {}&quot;.format(len(index)))
    data_n = data_n.drop(index)
    data_n.reset_index(drop=True, inplace=True)
    print(&quot;Now column number is: {}&quot;.format(data_n.shape[0]))
    index_low = np.arange(data_series.shape[0])[rule[0]]
    outliers = data_series.iloc[index_low]
    print(&quot;Description of data less than the lower bound is:&quot;)
    print(pd.Series(outliers).describe())
    index_up = np.arange(data_series.shape[0])[rule[1]]
    outliers = data_series.iloc[index_up]
    print(&quot;Description of data larger than the upper bound is:&quot;)
    print(pd.Series(outliers).describe())

    fig, ax = plt.subplots(1, 2, figsize=(10, 7))
    sns.boxplot(y=data[col_name], data=data, palette=&quot;Set1&quot;, ax=ax[0])
    sns.boxplot(y=data_n[col_name], data=data_n, palette=&quot;Set1&quot;, ax=ax[1])
    return data_n</code></pre>
<pre><code class="python"># 我们可以删掉一些异常数据，以 power 为例。  
# 这里删不删同学可以自行判断
# 但是要注意 test 的数据不能删 = = 不能掩耳盗铃是不是

Train_data = outliers_proc(Train_data, &#39;power&#39;, scale=3)</code></pre>
<pre><code>Delete number is: 963
Now column number is: 149037
Description of data less than the lower bound is:
count    0.0
mean     NaN
std      NaN
min      NaN
25%      NaN
50%      NaN
75%      NaN
max      NaN
Name: power, dtype: float64
Description of data larger than the upper bound is:
count      963.000000
mean       846.836968
std       1929.418081
min        376.000000
25%        400.000000
50%        436.000000
75%        514.000000
max      19312.000000
Name: power, dtype: float64</code></pre><p><img src="/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/output_8_1.png" alt="png"></p>
<h4 id="3-2-2-特征构造"><a href="#3-2-2-特征构造" class="headerlink" title="3.2.2 特征构造"></a>3.2.2 特征构造</h4><pre><code class="python"># 训练集和测试集放在一起，方便构造特征
Train_data[&#39;train&#39;]=1
Test_data[&#39;train&#39;]=0
data = pd.concat([Train_data, Test_data], ignore_index=True)</code></pre>
<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass &#39;sort=False&#39;.

To retain the current behavior and silence the warning, pass &#39;sort=True&#39;.

  after removing the cwd from sys.path.</code></pre><pre><code class="python"># 使用时间：data[&#39;creatDate&#39;] - data[&#39;regDate&#39;]，反应汽车使用时间，一般来说价格与使用时间成反比
# 不过要注意，数据里有时间出错的格式，所以我们需要 errors=&#39;coerce&#39;
data[&#39;used_time&#39;] = (pd.to_datetime(data[&#39;creatDate&#39;], format=&#39;%Y%m%d&#39;, errors=&#39;coerce&#39;) - 
                            pd.to_datetime(data[&#39;regDate&#39;], format=&#39;%Y%m%d&#39;, errors=&#39;coerce&#39;)).dt.days</code></pre>
<pre><code class="python"># 看一下空数据，有 15k 个样本的时间是有问题的，我们可以选择删除，也可以选择放着。
# 但是这里不建议删除，因为删除缺失数据占总样本量过大，7.5%
# 我们可以先放着，因为如果我们 XGBoost 之类的决策树，其本身就能处理缺失值，所以可以不用管；
data[&#39;used_time&#39;].isnull().sum()</code></pre>
<pre><code>15072</code></pre><pre><code class="python"># 从邮编中提取城市信息，相当于加入了先验知识
data[&#39;city&#39;] = data[&#39;regionCode&#39;].apply(lambda x : str(x)[:-3])
data = data</code></pre>
<pre><code class="python"># 计算某品牌的销售统计量，同学们还可以计算其他特征的统计量
# 这里要以 train 的数据计算统计量
Train_gb = Train_data.groupby(&quot;brand&quot;)
all_info = {}
for kind, kind_data in Train_gb:
    info = {}
    kind_data = kind_data[kind_data[&#39;price&#39;] &gt; 0]
    info[&#39;brand_amount&#39;] = len(kind_data)
    info[&#39;brand_price_max&#39;] = kind_data.price.max()
    info[&#39;brand_price_median&#39;] = kind_data.price.median()
    info[&#39;brand_price_min&#39;] = kind_data.price.min()
    info[&#39;brand_price_sum&#39;] = kind_data.price.sum()
    info[&#39;brand_price_std&#39;] = kind_data.price.std()
    info[&#39;brand_price_average&#39;] = round(kind_data.price.sum() / (len(kind_data) + 1), 2)
    all_info[kind] = info
brand_fe = pd.DataFrame(all_info).T.reset_index().rename(columns={&quot;index&quot;: &quot;brand&quot;})
data = data.merge(brand_fe, how=&#39;left&#39;, on=&#39;brand&#39;)</code></pre>
<pre><code class="python"># 数据分桶 以 power 为例
# 这时候我们的缺失值也进桶了，
# 为什么要做数据分桶呢，原因有很多，= =
# 1. 离散后稀疏向量内积乘法运算速度更快，计算结果也方便存储，容易扩展；
# 2. 离散后的特征对异常值更具鲁棒性，如 age&gt;30 为 1 否则为 0，对于年龄为 200 的也不会对模型造成很大的干扰；
# 3. LR 属于广义线性模型，表达能力有限，经过离散化后，每个变量有单独的权重，这相当于引入了非线性，能够提升模型的表达能力，加大拟合；
# 4. 离散后特征可以进行特征交叉，提升表达能力，由 M+N 个变量编程 M*N 个变量，进一步引入非线形，提升了表达能力；
# 5. 特征离散后模型更稳定，如用户年龄区间，不会因为用户年龄长了一岁就变化

# 当然还有很多原因，LightGBM 在改进 XGBoost 时就增加了数据分桶，增强了模型的泛化性

bin = [i*10 for i in range(31)]
data[&#39;power_bin&#39;] = pd.cut(data[&#39;power&#39;], bin, labels=False)
data[[&#39;power_bin&#39;, &#39;power&#39;]].head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>power_bin</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>60</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16.0</td>
      <td>163</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19.0</td>
      <td>193</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.0</td>
      <td>68</td>
    </tr>
  </tbody>
</table>
</div>




<pre><code class="python"># 删除不需要的数据
data = data.drop([&#39;creatDate&#39;, &#39;regDate&#39;, &#39;regionCode&#39;], axis=1)</code></pre>
<pre><code class="python">print(data.shape)
data.columns</code></pre>
<pre><code>(199037, 39)





Index([&#39;SaleID&#39;, &#39;bodyType&#39;, &#39;brand&#39;, &#39;fuelType&#39;, &#39;gearbox&#39;, &#39;kilometer&#39;,
       &#39;model&#39;, &#39;name&#39;, &#39;notRepairedDamage&#39;, &#39;offerType&#39;, &#39;power&#39;, &#39;price&#39;,
       &#39;seller&#39;, &#39;train&#39;, &#39;v_0&#39;, &#39;v_1&#39;, &#39;v_10&#39;, &#39;v_11&#39;, &#39;v_12&#39;, &#39;v_13&#39;, &#39;v_14&#39;,
       &#39;v_2&#39;, &#39;v_3&#39;, &#39;v_4&#39;, &#39;v_5&#39;, &#39;v_6&#39;, &#39;v_7&#39;, &#39;v_8&#39;, &#39;v_9&#39;, &#39;used_time&#39;,
       &#39;city&#39;, &#39;brand_amount&#39;, &#39;brand_price_max&#39;, &#39;brand_price_median&#39;,
       &#39;brand_price_min&#39;, &#39;brand_price_sum&#39;, &#39;brand_price_std&#39;,
       &#39;brand_price_average&#39;, &#39;power_bin&#39;],
      dtype=&#39;object&#39;)</code></pre><pre><code class="python"># 目前的数据其实已经可以给树模型使用了，所以我们导出一下
data.to_csv(&#39;data_for_tree.csv&#39;, index=0)</code></pre>
<pre><code class="python"># 我们可以再构造一份特征给 LR NN 之类的模型用
# 之所以分开构造是因为，不同模型对数据集的要求不同
# 我们看下数据分布：
data[&#39;power&#39;].plot.hist()</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x104cfb890&gt;</code></pre><p><img src="/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/output_19_1.png" alt="png"></p>
<pre><code class="python"># 我们刚刚已经对 train 进行异常值处理了，但是现在还有这么奇怪的分布是因为 test 中的 power 异常值，
# 所以我们其实刚刚 train 中的 power 异常值不删为好，可以用长尾分布截断来代替
Train_data[&#39;power&#39;].plot.hist()</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1ac0e090&gt;</code></pre><p><img src="/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/output_20_1.png" alt="png"></p>
<pre><code class="python"># 我们对其取 log，在做归一化
from sklearn import preprocessing
min_max_scaler = preprocessing.MinMaxScaler()
data[&#39;power&#39;] = np.log(data[&#39;power&#39;] + 1) 
data[&#39;power&#39;] = ((data[&#39;power&#39;] - np.min(data[&#39;power&#39;])) / (np.max(data[&#39;power&#39;]) - np.min(data[&#39;power&#39;])))
data[&#39;power&#39;].plot.hist()</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11829b050&gt;</code></pre><p><img src="/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/output_21_1.png" alt="png"></p>
<pre><code class="python"># km 的比较正常，应该是已经做过分桶了
data[&#39;kilometer&#39;].plot.hist()</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1b54ced0&gt;</code></pre><p><img src="/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/output_22_1.png" alt="png"></p>
<pre><code class="python"># 所以我们可以直接做归一化
data[&#39;kilometer&#39;] = ((data[&#39;kilometer&#39;] - np.min(data[&#39;kilometer&#39;])) / 
                        (np.max(data[&#39;kilometer&#39;]) - np.min(data[&#39;kilometer&#39;])))
data[&#39;kilometer&#39;].plot.hist()</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1c187750&gt;</code></pre><p><img src="/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/output_23_1.png" alt="png"></p>
<pre><code class="python"># 除此之外 还有我们刚刚构造的统计量特征：
# &#39;brand_amount&#39;, &#39;brand_price_average&#39;, &#39;brand_price_max&#39;,
# &#39;brand_price_median&#39;, &#39;brand_price_min&#39;, &#39;brand_price_std&#39;,
# &#39;brand_price_sum&#39;
# 这里不再一一举例分析了，直接做变换，
def max_min(x):
    return (x - np.min(x)) / (np.max(x) - np.min(x))

data[&#39;brand_amount&#39;] = ((data[&#39;brand_amount&#39;] - np.min(data[&#39;brand_amount&#39;])) / 
                        (np.max(data[&#39;brand_amount&#39;]) - np.min(data[&#39;brand_amount&#39;])))
data[&#39;brand_price_average&#39;] = ((data[&#39;brand_price_average&#39;] - np.min(data[&#39;brand_price_average&#39;])) / 
                               (np.max(data[&#39;brand_price_average&#39;]) - np.min(data[&#39;brand_price_average&#39;])))
data[&#39;brand_price_max&#39;] = ((data[&#39;brand_price_max&#39;] - np.min(data[&#39;brand_price_max&#39;])) / 
                           (np.max(data[&#39;brand_price_max&#39;]) - np.min(data[&#39;brand_price_max&#39;])))
data[&#39;brand_price_median&#39;] = ((data[&#39;brand_price_median&#39;] - np.min(data[&#39;brand_price_median&#39;])) /
                              (np.max(data[&#39;brand_price_median&#39;]) - np.min(data[&#39;brand_price_median&#39;])))
data[&#39;brand_price_min&#39;] = ((data[&#39;brand_price_min&#39;] - np.min(data[&#39;brand_price_min&#39;])) / 
                           (np.max(data[&#39;brand_price_min&#39;]) - np.min(data[&#39;brand_price_min&#39;])))
data[&#39;brand_price_std&#39;] = ((data[&#39;brand_price_std&#39;] - np.min(data[&#39;brand_price_std&#39;])) / 
                           (np.max(data[&#39;brand_price_std&#39;]) - np.min(data[&#39;brand_price_std&#39;])))
data[&#39;brand_price_sum&#39;] = ((data[&#39;brand_price_sum&#39;] - np.min(data[&#39;brand_price_sum&#39;])) / 
                           (np.max(data[&#39;brand_price_sum&#39;]) - np.min(data[&#39;brand_price_sum&#39;])))</code></pre>
<pre><code class="python"># 对类别特征进行 OneEncoder
data = pd.get_dummies(data, columns=[&#39;model&#39;, &#39;brand&#39;, &#39;bodyType&#39;, &#39;fuelType&#39;,
                                     &#39;gearbox&#39;, &#39;notRepairedDamage&#39;, &#39;power_bin&#39;])</code></pre>
<pre><code class="python">print(data.shape)
data.columns</code></pre>
<pre><code>(199037, 370)





Index([&#39;SaleID&#39;, &#39;kilometer&#39;, &#39;name&#39;, &#39;offerType&#39;, &#39;power&#39;, &#39;price&#39;, &#39;seller&#39;,
       &#39;train&#39;, &#39;v_0&#39;, &#39;v_1&#39;,
       ...
       &#39;power_bin_20.0&#39;, &#39;power_bin_21.0&#39;, &#39;power_bin_22.0&#39;, &#39;power_bin_23.0&#39;,
       &#39;power_bin_24.0&#39;, &#39;power_bin_25.0&#39;, &#39;power_bin_26.0&#39;, &#39;power_bin_27.0&#39;,
       &#39;power_bin_28.0&#39;, &#39;power_bin_29.0&#39;],
      dtype=&#39;object&#39;, length=370)</code></pre><pre><code class="python"># 这份数据可以给 LR 用
data.to_csv(&#39;data_for_lr.csv&#39;, index=0)</code></pre>
<h4 id="3-2-3-特征筛选"><a href="#3-2-3-特征筛选" class="headerlink" title="3.2.3 特征筛选"></a>3.2.3 特征筛选</h4><h5 id="过滤式"><a href="#过滤式" class="headerlink" title="过滤式"></a>过滤式</h5><pre><code class="python"># 相关性分析
print(data[&#39;power&#39;].corr(data[&#39;price&#39;], method=&#39;spearman&#39;))
print(data[&#39;kilometer&#39;].corr(data[&#39;price&#39;], method=&#39;spearman&#39;))
print(data[&#39;brand_amount&#39;].corr(data[&#39;price&#39;], method=&#39;spearman&#39;))
print(data[&#39;brand_price_average&#39;].corr(data[&#39;price&#39;], method=&#39;spearman&#39;))
print(data[&#39;brand_price_max&#39;].corr(data[&#39;price&#39;], method=&#39;spearman&#39;))
print(data[&#39;brand_price_median&#39;].corr(data[&#39;price&#39;], method=&#39;spearman&#39;))</code></pre>
<pre><code>0.5728285196051496
-0.4082569701616764
0.058156610025581514
0.3834909576057687
0.259066833880992
0.38691042393409447</code></pre><pre><code class="python"># 当然也可以直接看图
data_numeric = data[[&#39;power&#39;, &#39;kilometer&#39;, &#39;brand_amount&#39;, &#39;brand_price_average&#39;, 
                     &#39;brand_price_max&#39;, &#39;brand_price_median&#39;]]
correlation = data_numeric.corr()

f , ax = plt.subplots(figsize = (7, 7))
plt.title(&#39;Correlation of Numeric Features with Price&#39;,y=1,size=16)
sns.heatmap(correlation,square = True,  vmax=0.8)</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1b4f4b90&gt;</code></pre><p><img src="/2020/03/27/Datawhale-%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask3/output_30_1.png" alt="png"></p>
<h5 id="包裹式"><a href="#包裹式" class="headerlink" title="包裹式"></a>包裹式</h5><pre><code class="python"># k_feature 太大会很难跑，没服务器，所以提前 interrupt 了
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from sklearn.linear_model import LinearRegression
sfs = SFS(LinearRegression(),
           k_features=10,
           forward=True,
           floating=False,
           scoring = &#39;r2&#39;,
           cv = 0)
x = data.drop([&#39;price&#39;], axis=1)
x = x.fillna(0)
y = data[&#39;price&#39;]
sfs.fit(x, y)
sfs.k_feature_names_ </code></pre>
<pre><code class="python"># 画出来，可以看到边际效益
from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs
import matplotlib.pyplot as plt
fig1 = plot_sfs(sfs.get_metric_dict(), kind=&#39;std_dev&#39;)
plt.grid()
plt.show()</code></pre>
<h5 id="嵌入式"><a href="#嵌入式" class="headerlink" title="嵌入式"></a>嵌入式</h5><p>下一章介绍。</p>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>天池</tag>
      </tags>
  </entry>
  <entry>
    <title>Datawhale 二手车价格预测Task1&amp;Task2</title>
    <url>/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&amp;Task2/</url>
    <content><![CDATA[<p>二手车交易价格预测</p>
<p>大家好，我是一个数据挖掘小白，通过看官方提供的内容我发现很多专业词汇我都没有接触过，我想通过这个平台来锻炼提高自己，感谢大家批评指正。</p>
<a id="more"></a>

<h2 id="Task1-赛题理解"><a href="#Task1-赛题理解" class="headerlink" title="Task1-赛题理解"></a>Task1-赛题理解</h2><h3 id="1-1-赛题概况"><a href="#1-1-赛题概况" class="headerlink" title="1.1 赛题概况"></a>1.1 赛题概况</h3><p>赛题以预测二手车的交易价格为任务，数据集来自某交易平台的二手车交易记录，总数据量超过40w，包含31列变量信息，其中15列为匿名变量。为了保证比赛的公平性，将会从中抽取15万条作为训练集，5万条作为测试集A，5万条作为测试集B，同时会对name、model、brand和regionCode等信息进行脱敏。</p>
<h3 id="1-2-数据概况"><a href="#1-2-数据概况" class="headerlink" title="1.2 数据概况"></a>1.2 数据概况</h3><p>train.csv</p>
<p>SaleID - 销售样本ID</p>
<p>name - 汽车编码</p>
<p>regDate - 汽车注册时间</p>
<p>model - 车型编码</p>
<p>brand - 品牌</p>
<p>bodyType - 车身类型</p>
<p>fuelType - 燃油类型</p>
<p>gearbox - 变速箱</p>
<p>power - 汽车功率</p>
<p>kilometer - 汽车行驶公里</p>
<p>notRepairedDamage - 汽车有尚未修复的损坏</p>
<p>regionCode - 看车地区编码</p>
<p>seller - 销售方</p>
<p>offerType - 报价类型</p>
<p>creatDate - 广告发布时间</p>
<p>price - 汽车价格<br>v_0’, ‘v_1’, ‘v_2’, ‘v_3’, ‘v_4’, ‘v_5’, ‘v_6’, ‘v_7’, ‘v_8’, ‘v_9’, ‘v_10’, ‘v_11’, ‘v_12’, ‘v_13’,’v_14’ 【匿名特征，包含v0-14在内15个匿名特征】</p>
<p>数字全都脱敏处理，都为label encoding形式，即数字形式</p>
<h3 id="1-3-预测指标"><a href="#1-3-预测指标" class="headerlink" title="1.3 预测指标"></a>1.3 预测指标</h3><p>本赛题的评价标准为MAE(Mean Absolute Error)。</p>
<h3 id="1-3-数据读取pandas"><a href="#1-3-数据读取pandas" class="headerlink" title="1.3 数据读取pandas"></a>1.3 数据读取pandas</h3><pre><code class="python">import pandas as pd
import numpy as np

## 1 载入训练集和测试集
path = &#39;./tianchi/&#39;
Train_data = pd.read_csv(path+&#39;used_car_train_20200313.csv&#39;, sep=&#39; &#39;)
Test_data = pd.read_csv(path+&#39;used_car_testA_20200313.csv&#39;, sep=&#39; &#39;)

print(&#39;Train data shape:&#39;,Train_data.shape)
print(&#39;TestA data shape:&#39;,Test_data.shape)</code></pre>
<pre><code>Train data shape: (150000, 31)
TestA data shape: (50000, 30)</code></pre><pre><code class="python">Train_data.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>736</td>
      <td>20040402</td>
      <td>30.0</td>
      <td>6</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.235676</td>
      <td>0.101988</td>
      <td>0.129549</td>
      <td>0.022816</td>
      <td>0.097462</td>
      <td>-2.881803</td>
      <td>2.804097</td>
      <td>-2.420821</td>
      <td>0.795292</td>
      <td>0.914762</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2262</td>
      <td>20030301</td>
      <td>40.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.264777</td>
      <td>0.121004</td>
      <td>0.135731</td>
      <td>0.026597</td>
      <td>0.020582</td>
      <td>-4.900482</td>
      <td>2.096338</td>
      <td>-1.030483</td>
      <td>-1.722674</td>
      <td>0.245522</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>14874</td>
      <td>20040403</td>
      <td>115.0</td>
      <td>15</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>163</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.251410</td>
      <td>0.114912</td>
      <td>0.165147</td>
      <td>0.062173</td>
      <td>0.027075</td>
      <td>-4.846749</td>
      <td>1.803559</td>
      <td>1.565330</td>
      <td>-0.832687</td>
      <td>-0.229963</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>71865</td>
      <td>19960908</td>
      <td>109.0</td>
      <td>10</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>193</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.274293</td>
      <td>0.110300</td>
      <td>0.121964</td>
      <td>0.033395</td>
      <td>0.000000</td>
      <td>-4.509599</td>
      <td>1.285940</td>
      <td>-0.501868</td>
      <td>-2.438353</td>
      <td>-0.478699</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>111080</td>
      <td>20120103</td>
      <td>110.0</td>
      <td>5</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>68</td>
      <td>5.0</td>
      <td>...</td>
      <td>0.228036</td>
      <td>0.073205</td>
      <td>0.091880</td>
      <td>0.078819</td>
      <td>0.121534</td>
      <td>-1.896240</td>
      <td>0.910783</td>
      <td>0.931110</td>
      <td>2.834518</td>
      <td>1.923482</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>



<h3 id="1-4-分类指标评价计算"><a href="#1-4-分类指标评价计算" class="headerlink" title="1.4 分类指标评价计算"></a>1.4 分类指标评价计算</h3><pre><code class="python">## accuracy
import numpy as np 
from sklearn.metrics import accuracy_score
y_pred = [0,1,0,1]
y_true = [0,1,1,1]
print(&#39;ACC:&#39;,accuracy_score(y_true,y_pred))</code></pre>
<pre><code>ACC: 0.75</code></pre><pre><code class="python">## Precision,Recall,F1-score
from sklearn import metrics
y_pred = [0,1,0,0]
y_true = [0,1,0,1]
print(&#39;Precision:&#39;,metrics.precision_score(y_true,y_pred))
print(&#39;Recall&#39;,metrics.recall_score(y_true,y_pred))
print(&#39;F1-score:&#39;,metrics.f1_score(y_true,y_pred))</code></pre>
<pre><code>Precision: 1.0
Recall 0.5
F1-score: 0.6666666666666666</code></pre><pre><code class="python"># AUC
import numpy as np
from sklearn.metrics import roc_auc_score
y_true = np.array([0,0,1,1])
y_scores=np.array([0.1,0.4,0.35,0.8])
print(&#39;AUC score:&#39;,roc_auc_score(y_true,y_scores))</code></pre>
<pre><code>AUC score: 0.75</code></pre><h3 id="1-5-回归指标评价计算"><a href="#1-5-回归指标评价计算" class="headerlink" title="1.5 回归指标评价计算"></a>1.5 回归指标评价计算</h3><pre><code class="python"># coding=utf-8
import numpy as np
from sklearn import metrics

def mape(y_true,y_pred):
    return np.mean(np.abs((y_pred - y_true)/y_true))
y_true = np.array([1.0,5.0,4.0,3.0,2.0,5.0,-3.0])
y_pred = np.array([1.0,4.5,3.8,3.2,3.0,4.8,-2.2])

#Mse
print(&#39;MSE:&#39;,metrics.mean_squared_error(y_true,y_pred))
print(&#39;RMSE:&#39;,np.sqrt(metrics.mean_squared_error(y_true,y_pred)))
print(&#39;MAE:&#39;,metrics.mean_absolute_error(y_true,y_pred))
print(&#39;MAPE:&#39;,mape(y_true,y_pred))</code></pre>
<pre><code>MSE: 0.2871428571428571
RMSE: 0.5358571238146014
MAE: 0.4142857142857143
MAPE: 0.1461904761904762</code></pre><pre><code class="python">## R2-score
from sklearn.metrics import r2_score
y_true =[3,-0.5,2,7]
y_pred =[2.5,0.0,2,8]
print(&#39;R2-score:&#39;,r2_score(y_true,y_pred))</code></pre>
<pre><code>R2-score: 0.9486081370449679</code></pre><h2 id="Task2-数据分析"><a href="#Task2-数据分析" class="headerlink" title="Task2-数据分析"></a>Task2-数据分析</h2><h2 id="2-1-目标"><a href="#2-1-目标" class="headerlink" title="2.1 目标"></a>2.1 目标</h2><p>1.熟悉数据集，了解数据集<br>2.了解变量间的互相关系以及变量与预测值之间的存在关系<br>3.引导我们进行数据吹以及特征工程的步骤<br>4.对数据进行一些图表或者文字总结。</p>
<h2 id="2-2-内容步骤"><a href="#2-2-内容步骤" class="headerlink" title="2.2 内容步骤"></a>2.2 内容步骤</h2><h3 id="2-2-1-载入各种数据科学以及可视化库"><a href="#2-2-1-载入各种数据科学以及可视化库" class="headerlink" title="2.2.1 载入各种数据科学以及可视化库"></a>2.2.1 载入各种数据科学以及可视化库</h3><pre><code class="python">#coding:utf-8
#导入warnings包，利用过滤器来实现忽略警告语句。
import warnings
warnings.filterwarnings(&#39;ignore&#39;)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno</code></pre>
<h3 id="2-2-2-载入数据"><a href="#2-2-2-载入数据" class="headerlink" title="2.2.2 载入数据"></a>2.2.2 载入数据</h3><pre><code class="python">## 1载入训练集和测试集
path = &#39;./tianchi/&#39;
Train_data = pd.read_csv(path+&#39;used_car_train_20200313.csv&#39;, sep=&#39; &#39;)
Test_data = pd.read_csv(path+&#39;used_car_testA_20200313.csv&#39;, sep=&#39; &#39;)</code></pre>
<pre><code class="python">## 2观察数据（head()+shape）
Train_data.head().append(Train_data.tail())</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>736</td>
      <td>20040402</td>
      <td>30.0</td>
      <td>6</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.235676</td>
      <td>0.101988</td>
      <td>0.129549</td>
      <td>0.022816</td>
      <td>0.097462</td>
      <td>-2.881803</td>
      <td>2.804097</td>
      <td>-2.420821</td>
      <td>0.795292</td>
      <td>0.914762</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2262</td>
      <td>20030301</td>
      <td>40.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.264777</td>
      <td>0.121004</td>
      <td>0.135731</td>
      <td>0.026597</td>
      <td>0.020582</td>
      <td>-4.900482</td>
      <td>2.096338</td>
      <td>-1.030483</td>
      <td>-1.722674</td>
      <td>0.245522</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>14874</td>
      <td>20040403</td>
      <td>115.0</td>
      <td>15</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>163</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.251410</td>
      <td>0.114912</td>
      <td>0.165147</td>
      <td>0.062173</td>
      <td>0.027075</td>
      <td>-4.846749</td>
      <td>1.803559</td>
      <td>1.565330</td>
      <td>-0.832687</td>
      <td>-0.229963</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>71865</td>
      <td>19960908</td>
      <td>109.0</td>
      <td>10</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>193</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.274293</td>
      <td>0.110300</td>
      <td>0.121964</td>
      <td>0.033395</td>
      <td>0.000000</td>
      <td>-4.509599</td>
      <td>1.285940</td>
      <td>-0.501868</td>
      <td>-2.438353</td>
      <td>-0.478699</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>111080</td>
      <td>20120103</td>
      <td>110.0</td>
      <td>5</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>68</td>
      <td>5.0</td>
      <td>...</td>
      <td>0.228036</td>
      <td>0.073205</td>
      <td>0.091880</td>
      <td>0.078819</td>
      <td>0.121534</td>
      <td>-1.896240</td>
      <td>0.910783</td>
      <td>0.931110</td>
      <td>2.834518</td>
      <td>1.923482</td>
    </tr>
    <tr>
      <th>149995</th>
      <td>149995</td>
      <td>163978</td>
      <td>20000607</td>
      <td>121.0</td>
      <td>10</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>163</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.280264</td>
      <td>0.000310</td>
      <td>0.048441</td>
      <td>0.071158</td>
      <td>0.019174</td>
      <td>1.988114</td>
      <td>-2.983973</td>
      <td>0.589167</td>
      <td>-1.304370</td>
      <td>-0.302592</td>
    </tr>
    <tr>
      <th>149996</th>
      <td>149996</td>
      <td>184535</td>
      <td>20091102</td>
      <td>116.0</td>
      <td>11</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>125</td>
      <td>10.0</td>
      <td>...</td>
      <td>0.253217</td>
      <td>0.000777</td>
      <td>0.084079</td>
      <td>0.099681</td>
      <td>0.079371</td>
      <td>1.839166</td>
      <td>-2.774615</td>
      <td>2.553994</td>
      <td>0.924196</td>
      <td>-0.272160</td>
    </tr>
    <tr>
      <th>149997</th>
      <td>149997</td>
      <td>147587</td>
      <td>20101003</td>
      <td>60.0</td>
      <td>11</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>90</td>
      <td>6.0</td>
      <td>...</td>
      <td>0.233353</td>
      <td>0.000705</td>
      <td>0.118872</td>
      <td>0.100118</td>
      <td>0.097914</td>
      <td>2.439812</td>
      <td>-1.630677</td>
      <td>2.290197</td>
      <td>1.891922</td>
      <td>0.414931</td>
    </tr>
    <tr>
      <th>149998</th>
      <td>149998</td>
      <td>45907</td>
      <td>20060312</td>
      <td>34.0</td>
      <td>10</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>156</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.256369</td>
      <td>0.000252</td>
      <td>0.081479</td>
      <td>0.083558</td>
      <td>0.081498</td>
      <td>2.075380</td>
      <td>-2.633719</td>
      <td>1.414937</td>
      <td>0.431981</td>
      <td>-1.659014</td>
    </tr>
    <tr>
      <th>149999</th>
      <td>149999</td>
      <td>177672</td>
      <td>19990204</td>
      <td>19.0</td>
      <td>28</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>193</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.284475</td>
      <td>0.000000</td>
      <td>0.040072</td>
      <td>0.062543</td>
      <td>0.025819</td>
      <td>1.978453</td>
      <td>-3.179913</td>
      <td>0.031724</td>
      <td>-1.483350</td>
      <td>-0.342674</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 31 columns</p>
</div>




<pre><code class="python">Train_data.shape</code></pre>
<pre><code>(150000, 31)</code></pre><pre><code class="python">Test_data.head().append(Test_data.tail())</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>150000</td>
      <td>66932</td>
      <td>20111212</td>
      <td>222.0</td>
      <td>4</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>313</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.264405</td>
      <td>0.121800</td>
      <td>0.070899</td>
      <td>0.106558</td>
      <td>0.078867</td>
      <td>-7.050969</td>
      <td>-0.854626</td>
      <td>4.800151</td>
      <td>0.620011</td>
      <td>-3.664654</td>
    </tr>
    <tr>
      <th>1</th>
      <td>150001</td>
      <td>174960</td>
      <td>19990211</td>
      <td>19.0</td>
      <td>21</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>75</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.261745</td>
      <td>0.000000</td>
      <td>0.096733</td>
      <td>0.013705</td>
      <td>0.052383</td>
      <td>3.679418</td>
      <td>-0.729039</td>
      <td>-3.796107</td>
      <td>-1.541230</td>
      <td>-0.757055</td>
    </tr>
    <tr>
      <th>2</th>
      <td>150002</td>
      <td>5356</td>
      <td>20090304</td>
      <td>82.0</td>
      <td>21</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>109</td>
      <td>7.0</td>
      <td>...</td>
      <td>0.260216</td>
      <td>0.112081</td>
      <td>0.078082</td>
      <td>0.062078</td>
      <td>0.050540</td>
      <td>-4.926690</td>
      <td>1.001106</td>
      <td>0.826562</td>
      <td>0.138226</td>
      <td>0.754033</td>
    </tr>
    <tr>
      <th>3</th>
      <td>150003</td>
      <td>50688</td>
      <td>20100405</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>160</td>
      <td>7.0</td>
      <td>...</td>
      <td>0.260466</td>
      <td>0.106727</td>
      <td>0.081146</td>
      <td>0.075971</td>
      <td>0.048268</td>
      <td>-4.864637</td>
      <td>0.505493</td>
      <td>1.870379</td>
      <td>0.366038</td>
      <td>1.312775</td>
    </tr>
    <tr>
      <th>4</th>
      <td>150004</td>
      <td>161428</td>
      <td>19970703</td>
      <td>26.0</td>
      <td>14</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>75</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.250999</td>
      <td>0.000000</td>
      <td>0.077806</td>
      <td>0.028600</td>
      <td>0.081709</td>
      <td>3.616475</td>
      <td>-0.673236</td>
      <td>-3.197685</td>
      <td>-0.025678</td>
      <td>-0.101290</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>199995</td>
      <td>20903</td>
      <td>19960503</td>
      <td>4.0</td>
      <td>4</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>116</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.284664</td>
      <td>0.130044</td>
      <td>0.049833</td>
      <td>0.028807</td>
      <td>0.004616</td>
      <td>-5.978511</td>
      <td>1.303174</td>
      <td>-1.207191</td>
      <td>-1.981240</td>
      <td>-0.357695</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>199996</td>
      <td>708</td>
      <td>19991011</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>75</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.268101</td>
      <td>0.108095</td>
      <td>0.066039</td>
      <td>0.025468</td>
      <td>0.025971</td>
      <td>-3.913825</td>
      <td>1.759524</td>
      <td>-2.075658</td>
      <td>-1.154847</td>
      <td>0.169073</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>199997</td>
      <td>6693</td>
      <td>20040412</td>
      <td>49.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>224</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.269432</td>
      <td>0.105724</td>
      <td>0.117652</td>
      <td>0.057479</td>
      <td>0.015669</td>
      <td>-4.639065</td>
      <td>0.654713</td>
      <td>1.137756</td>
      <td>-1.390531</td>
      <td>0.254420</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>199998</td>
      <td>96900</td>
      <td>20020008</td>
      <td>27.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>334</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.261152</td>
      <td>0.000490</td>
      <td>0.137366</td>
      <td>0.086216</td>
      <td>0.051383</td>
      <td>1.833504</td>
      <td>-2.828687</td>
      <td>2.465630</td>
      <td>-0.911682</td>
      <td>-2.057353</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>199999</td>
      <td>193384</td>
      <td>20041109</td>
      <td>166.0</td>
      <td>6</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>68</td>
      <td>9.0</td>
      <td>...</td>
      <td>0.228730</td>
      <td>0.000300</td>
      <td>0.103534</td>
      <td>0.080625</td>
      <td>0.124264</td>
      <td>2.914571</td>
      <td>-1.135270</td>
      <td>0.547628</td>
      <td>2.094057</td>
      <td>-1.552150</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 30 columns</p>
</div>




<pre><code class="python">Test_data.shape</code></pre>
<pre><code>(50000, 30)</code></pre><h3 id="2-2-3-总览数据概况"><a href="#2-2-3-总览数据概况" class="headerlink" title="2.2.3 总览数据概况"></a>2.2.3 总览数据概况</h3><pre><code class="python">##1通过describe（）来熟悉数据的相关统计量
Train_data.describe()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>1.500000e+05</td>
      <td>149999.000000</td>
      <td>150000.000000</td>
      <td>145494.000000</td>
      <td>141320.000000</td>
      <td>144019.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>...</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>74999.500000</td>
      <td>68349.172873</td>
      <td>2.003417e+07</td>
      <td>47.129021</td>
      <td>8.052733</td>
      <td>1.792369</td>
      <td>0.375842</td>
      <td>0.224943</td>
      <td>119.316547</td>
      <td>12.597160</td>
      <td>...</td>
      <td>0.248204</td>
      <td>0.044923</td>
      <td>0.124692</td>
      <td>0.058144</td>
      <td>0.061996</td>
      <td>-0.001000</td>
      <td>0.009035</td>
      <td>0.004813</td>
      <td>0.000313</td>
      <td>-0.000688</td>
    </tr>
    <tr>
      <th>std</th>
      <td>43301.414527</td>
      <td>61103.875095</td>
      <td>5.364988e+04</td>
      <td>49.536040</td>
      <td>7.864956</td>
      <td>1.760640</td>
      <td>0.548677</td>
      <td>0.417546</td>
      <td>177.168419</td>
      <td>3.919576</td>
      <td>...</td>
      <td>0.045804</td>
      <td>0.051743</td>
      <td>0.201410</td>
      <td>0.029186</td>
      <td>0.035692</td>
      <td>3.772386</td>
      <td>3.286071</td>
      <td>2.517478</td>
      <td>1.288988</td>
      <td>1.038685</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.991000e+07</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.500000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-9.168192</td>
      <td>-5.558207</td>
      <td>-9.639552</td>
      <td>-4.153899</td>
      <td>-6.546556</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>37499.750000</td>
      <td>11156.000000</td>
      <td>1.999091e+07</td>
      <td>10.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>75.000000</td>
      <td>12.500000</td>
      <td>...</td>
      <td>0.243615</td>
      <td>0.000038</td>
      <td>0.062474</td>
      <td>0.035334</td>
      <td>0.033930</td>
      <td>-3.722303</td>
      <td>-1.951543</td>
      <td>-1.871846</td>
      <td>-1.057789</td>
      <td>-0.437034</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>74999.500000</td>
      <td>51638.000000</td>
      <td>2.003091e+07</td>
      <td>30.000000</td>
      <td>6.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>110.000000</td>
      <td>15.000000</td>
      <td>...</td>
      <td>0.257798</td>
      <td>0.000812</td>
      <td>0.095866</td>
      <td>0.057014</td>
      <td>0.058484</td>
      <td>1.624076</td>
      <td>-0.358053</td>
      <td>-0.130753</td>
      <td>-0.036245</td>
      <td>0.141246</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>112499.250000</td>
      <td>118841.250000</td>
      <td>2.007111e+07</td>
      <td>66.000000</td>
      <td>13.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>150.000000</td>
      <td>15.000000</td>
      <td>...</td>
      <td>0.265297</td>
      <td>0.102009</td>
      <td>0.125243</td>
      <td>0.079382</td>
      <td>0.087491</td>
      <td>2.844357</td>
      <td>1.255022</td>
      <td>1.776933</td>
      <td>0.942813</td>
      <td>0.680378</td>
    </tr>
    <tr>
      <th>max</th>
      <td>149999.000000</td>
      <td>196812.000000</td>
      <td>2.015121e+07</td>
      <td>247.000000</td>
      <td>39.000000</td>
      <td>7.000000</td>
      <td>6.000000</td>
      <td>1.000000</td>
      <td>19312.000000</td>
      <td>15.000000</td>
      <td>...</td>
      <td>0.291838</td>
      <td>0.151420</td>
      <td>1.404936</td>
      <td>0.160791</td>
      <td>0.222787</td>
      <td>12.357011</td>
      <td>18.819042</td>
      <td>13.847792</td>
      <td>11.147669</td>
      <td>8.658418</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 30 columns</p>
</div>




<pre><code class="python">Test_data.describe()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>5.000000e+04</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>48587.000000</td>
      <td>47107.000000</td>
      <td>48090.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>...</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
      <td>50000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>174999.500000</td>
      <td>68542.223280</td>
      <td>2.003393e+07</td>
      <td>46.844520</td>
      <td>8.056240</td>
      <td>1.782185</td>
      <td>0.373405</td>
      <td>0.224350</td>
      <td>119.883620</td>
      <td>12.595580</td>
      <td>...</td>
      <td>0.248669</td>
      <td>0.045021</td>
      <td>0.122744</td>
      <td>0.057997</td>
      <td>0.062000</td>
      <td>-0.017855</td>
      <td>-0.013742</td>
      <td>-0.013554</td>
      <td>-0.003147</td>
      <td>0.001516</td>
    </tr>
    <tr>
      <th>std</th>
      <td>14433.901067</td>
      <td>61052.808133</td>
      <td>5.368870e+04</td>
      <td>49.469548</td>
      <td>7.819477</td>
      <td>1.760736</td>
      <td>0.546442</td>
      <td>0.417158</td>
      <td>185.097387</td>
      <td>3.908979</td>
      <td>...</td>
      <td>0.044601</td>
      <td>0.051766</td>
      <td>0.195972</td>
      <td>0.029211</td>
      <td>0.035653</td>
      <td>3.747985</td>
      <td>3.231258</td>
      <td>2.515962</td>
      <td>1.286597</td>
      <td>1.027360</td>
    </tr>
    <tr>
      <th>min</th>
      <td>150000.000000</td>
      <td>0.000000</td>
      <td>1.991000e+07</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.500000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-9.160049</td>
      <td>-5.411964</td>
      <td>-8.916949</td>
      <td>-4.123333</td>
      <td>-6.112667</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>162499.750000</td>
      <td>11203.500000</td>
      <td>1.999091e+07</td>
      <td>10.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>75.000000</td>
      <td>12.500000</td>
      <td>...</td>
      <td>0.243762</td>
      <td>0.000044</td>
      <td>0.062644</td>
      <td>0.035084</td>
      <td>0.033714</td>
      <td>-3.700121</td>
      <td>-1.971325</td>
      <td>-1.876703</td>
      <td>-1.060428</td>
      <td>-0.437920</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>174999.500000</td>
      <td>52248.500000</td>
      <td>2.003091e+07</td>
      <td>29.000000</td>
      <td>6.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>109.000000</td>
      <td>15.000000</td>
      <td>...</td>
      <td>0.257877</td>
      <td>0.000815</td>
      <td>0.095828</td>
      <td>0.057084</td>
      <td>0.058764</td>
      <td>1.613212</td>
      <td>-0.355843</td>
      <td>-0.142779</td>
      <td>-0.035956</td>
      <td>0.138799</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>187499.250000</td>
      <td>118856.500000</td>
      <td>2.007110e+07</td>
      <td>65.000000</td>
      <td>13.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>150.000000</td>
      <td>15.000000</td>
      <td>...</td>
      <td>0.265328</td>
      <td>0.102025</td>
      <td>0.125438</td>
      <td>0.079077</td>
      <td>0.087489</td>
      <td>2.832708</td>
      <td>1.262914</td>
      <td>1.764335</td>
      <td>0.941469</td>
      <td>0.681163</td>
    </tr>
    <tr>
      <th>max</th>
      <td>199999.000000</td>
      <td>196805.000000</td>
      <td>2.015121e+07</td>
      <td>246.000000</td>
      <td>39.000000</td>
      <td>7.000000</td>
      <td>6.000000</td>
      <td>1.000000</td>
      <td>20000.000000</td>
      <td>15.000000</td>
      <td>...</td>
      <td>0.291618</td>
      <td>0.153265</td>
      <td>1.358813</td>
      <td>0.156355</td>
      <td>0.214775</td>
      <td>12.338872</td>
      <td>18.856218</td>
      <td>12.950498</td>
      <td>5.913273</td>
      <td>2.624622</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 29 columns</p>
</div>




<pre><code class="python">##2通过info（）来熟悉数据类型
Train_data.info()</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 150000 entries, 0 to 149999
Data columns (total 31 columns):
 #   Column             Non-Null Count   Dtype  
---  ------             --------------   -----  
 0   SaleID             150000 non-null  int64  
 1   name               150000 non-null  int64  
 2   regDate            150000 non-null  int64  
 3   model              149999 non-null  float64
 4   brand              150000 non-null  int64  
 5   bodyType           145494 non-null  float64
 6   fuelType           141320 non-null  float64
 7   gearbox            144019 non-null  float64
 8   power              150000 non-null  int64  
 9   kilometer          150000 non-null  float64
 10  notRepairedDamage  150000 non-null  object 
 11  regionCode         150000 non-null  int64  
 12  seller             150000 non-null  int64  
 13  offerType          150000 non-null  int64  
 14  creatDate          150000 non-null  int64  
 15  price              150000 non-null  int64  
 16  v_0                150000 non-null  float64
 17  v_1                150000 non-null  float64
 18  v_2                150000 non-null  float64
 19  v_3                150000 non-null  float64
 20  v_4                150000 non-null  float64
 21  v_5                150000 non-null  float64
 22  v_6                150000 non-null  float64
 23  v_7                150000 non-null  float64
 24  v_8                150000 non-null  float64
 25  v_9                150000 non-null  float64
 26  v_10               150000 non-null  float64
 27  v_11               150000 non-null  float64
 28  v_12               150000 non-null  float64
 29  v_13               150000 non-null  float64
 30  v_14               150000 non-null  float64
dtypes: float64(20), int64(10), object(1)
memory usage: 35.5+ MB</code></pre><pre><code class="python">Test_data.info()</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 50000 entries, 0 to 49999
Data columns (total 30 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   SaleID             50000 non-null  int64  
 1   name               50000 non-null  int64  
 2   regDate            50000 non-null  int64  
 3   model              50000 non-null  float64
 4   brand              50000 non-null  int64  
 5   bodyType           48587 non-null  float64
 6   fuelType           47107 non-null  float64
 7   gearbox            48090 non-null  float64
 8   power              50000 non-null  int64  
 9   kilometer          50000 non-null  float64
 10  notRepairedDamage  50000 non-null  object 
 11  regionCode         50000 non-null  int64  
 12  seller             50000 non-null  int64  
 13  offerType          50000 non-null  int64  
 14  creatDate          50000 non-null  int64  
 15  v_0                50000 non-null  float64
 16  v_1                50000 non-null  float64
 17  v_2                50000 non-null  float64
 18  v_3                50000 non-null  float64
 19  v_4                50000 non-null  float64
 20  v_5                50000 non-null  float64
 21  v_6                50000 non-null  float64
 22  v_7                50000 non-null  float64
 23  v_8                50000 non-null  float64
 24  v_9                50000 non-null  float64
 25  v_10               50000 non-null  float64
 26  v_11               50000 non-null  float64
 27  v_12               50000 non-null  float64
 28  v_13               50000 non-null  float64
 29  v_14               50000 non-null  float64
dtypes: float64(20), int64(9), object(1)
memory usage: 11.4+ MB</code></pre><h3 id="2-2-4-判断数据缺失和异常"><a href="#2-2-4-判断数据缺失和异常" class="headerlink" title="2.2.4 判断数据缺失和异常"></a>2.2.4 判断数据缺失和异常</h3><pre><code class="python">##1查看每列的存在nan情况
Train_data.isnull().sum()</code></pre>
<pre><code>SaleID                  0
name                    0
regDate                 0
model                   1
brand                   0
bodyType             4506
fuelType             8680
gearbox              5981
power                   0
kilometer               0
notRepairedDamage       0
regionCode              0
seller                  0
offerType               0
creatDate               0
price                   0
v_0                     0
v_1                     0
v_2                     0
v_3                     0
v_4                     0
v_5                     0
v_6                     0
v_7                     0
v_8                     0
v_9                     0
v_10                    0
v_11                    0
v_12                    0
v_13                    0
v_14                    0
dtype: int64</code></pre><pre><code class="python">Test_data.isnull().sum()</code></pre>
<pre><code>SaleID                  0
name                    0
regDate                 0
model                   0
brand                   0
bodyType             1413
fuelType             2893
gearbox              1910
power                   0
kilometer               0
notRepairedDamage       0
regionCode              0
seller                  0
offerType               0
creatDate               0
v_0                     0
v_1                     0
v_2                     0
v_3                     0
v_4                     0
v_5                     0
v_6                     0
v_7                     0
v_8                     0
v_9                     0
v_10                    0
v_11                    0
v_12                    0
v_13                    0
v_14                    0
dtype: int64</code></pre><pre><code class="python">#nan可视化
missing = Train_data.isnull().sum()
missing = missing[missing &gt; 0]
missing.sort_values(inplace = True)
missing.plot.bar()</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x118cbff10&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_27_1.png" alt="png"></p>
<pre><code class="python">#可视化看下缺省值
msno.matrix(Train_data.sample(250))</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x118b63910&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_28_1.png" alt="png"></p>
<pre><code class="python">msno.bar(Train_data.sample(1000))</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x106d80290&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_29_1.png" alt="png"></p>
<pre><code class="python">msno.matrix(Test_data.sample(250))</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11f6e36d0&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_30_1.png" alt="png"></p>
<pre><code class="python">msno.bar(Test_data.sample(1000))</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11880d6d0&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_31_1.png" alt="png"></p>
<pre><code class="python">##2查看异常值检测
Train_data.info()</code></pre>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 150000 entries, 0 to 149999
Data columns (total 31 columns):
 #   Column             Non-Null Count   Dtype  
---  ------             --------------   -----  
 0   SaleID             150000 non-null  int64  
 1   name               150000 non-null  int64  
 2   regDate            150000 non-null  int64  
 3   model              149999 non-null  float64
 4   brand              150000 non-null  int64  
 5   bodyType           145494 non-null  float64
 6   fuelType           141320 non-null  float64
 7   gearbox            144019 non-null  float64
 8   power              150000 non-null  int64  
 9   kilometer          150000 non-null  float64
 10  notRepairedDamage  150000 non-null  object 
 11  regionCode         150000 non-null  int64  
 12  seller             150000 non-null  int64  
 13  offerType          150000 non-null  int64  
 14  creatDate          150000 non-null  int64  
 15  price              150000 non-null  int64  
 16  v_0                150000 non-null  float64
 17  v_1                150000 non-null  float64
 18  v_2                150000 non-null  float64
 19  v_3                150000 non-null  float64
 20  v_4                150000 non-null  float64
 21  v_5                150000 non-null  float64
 22  v_6                150000 non-null  float64
 23  v_7                150000 non-null  float64
 24  v_8                150000 non-null  float64
 25  v_9                150000 non-null  float64
 26  v_10               150000 non-null  float64
 27  v_11               150000 non-null  float64
 28  v_12               150000 non-null  float64
 29  v_13               150000 non-null  float64
 30  v_14               150000 non-null  float64
dtypes: float64(20), int64(10), object(1)
memory usage: 35.5+ MB</code></pre><pre><code class="python">Train_data[&#39;notRepairedDamage&#39;].value_counts()</code></pre>
<pre><code>0.0    111361
-       24324
1.0     14315
Name: notRepairedDamage, dtype: int64</code></pre><pre><code class="python">Train_data[&#39;notRepairedDamage&#39;].replace(&#39;-&#39;,np.nan,inplace=True)</code></pre>
<pre><code class="python">Train_data[&#39;notRepairedDamage&#39;].value_counts()</code></pre>
<pre><code>0.0    111361
1.0     14315
Name: notRepairedDamage, dtype: int64</code></pre><pre><code class="python">Train_data.isnull().sum()</code></pre>
<pre><code>SaleID                   0
name                     0
regDate                  0
model                    1
brand                    0
bodyType              4506
fuelType              8680
gearbox               5981
power                    0
kilometer                0
notRepairedDamage    24324
regionCode               0
seller                   0
offerType                0
creatDate                0
price                    0
v_0                      0
v_1                      0
v_2                      0
v_3                      0
v_4                      0
v_5                      0
v_6                      0
v_7                      0
v_8                      0
v_9                      0
v_10                     0
v_11                     0
v_12                     0
v_13                     0
v_14                     0
dtype: int64</code></pre><pre><code class="python">Test_data[&#39;notRepairedDamage&#39;].value_counts()</code></pre>
<pre><code>0.0    37249
-       8031
1.0     4720
Name: notRepairedDamage, dtype: int64</code></pre><pre><code class="python">Test_data[&#39;notRepairedDamage&#39;].replace(&#39;-&#39;,np.nan,inplace=True)</code></pre>
<pre><code class="python">Test_data.isnull().sum()</code></pre>
<pre><code>SaleID                  0
name                    0
regDate                 0
model                   0
brand                   0
bodyType             1413
fuelType             2893
gearbox              1910
power                   0
kilometer               0
notRepairedDamage    8031
regionCode              0
seller                  0
offerType               0
creatDate               0
v_0                     0
v_1                     0
v_2                     0
v_3                     0
v_4                     0
v_5                     0
v_6                     0
v_7                     0
v_8                     0
v_9                     0
v_10                    0
v_11                    0
v_12                    0
v_13                    0
v_14                    0
dtype: int64</code></pre><pre><code class="python">Train_data[&quot;seller&quot;].value_counts()</code></pre>
<pre><code>0    149999
1         1
Name: seller, dtype: int64</code></pre><pre><code class="python">Train_data[&quot;offerType&quot;].value_counts()</code></pre>
<pre><code>0    150000
Name: offerType, dtype: int64</code></pre><pre><code class="python">del Train_data[&quot;seller&quot;]
del Train_data[&quot;offerType&quot;]
del Test_data[&quot;seller&quot;]
del Test_data[&quot;offerType&quot;]
##删除完毕
Train_data.isnull().sum()</code></pre>
<pre><code>SaleID                   0
name                     0
regDate                  0
model                    1
brand                    0
bodyType              4506
fuelType              8680
gearbox               5981
power                    0
kilometer                0
notRepairedDamage    24324
regionCode               0
creatDate                0
price                    0
v_0                      0
v_1                      0
v_2                      0
v_3                      0
v_4                      0
v_5                      0
v_6                      0
v_7                      0
v_8                      0
v_9                      0
v_10                     0
v_11                     0
v_12                     0
v_13                     0
v_14                     0
dtype: int64</code></pre><h3 id="2-2-5-了解预测值的分布"><a href="#2-2-5-了解预测值的分布" class="headerlink" title="2.2.5 了解预测值的分布"></a>2.2.5 了解预测值的分布</h3><pre><code class="python">Train_data[&#39;price&#39;]</code></pre>
<pre><code>0         1850
1         3600
2         6222
3         2400
4         5200
          ... 
149995    5900
149996    9500
149997    7500
149998    4999
149999    4700
Name: price, Length: 150000, dtype: int64</code></pre><pre><code class="python">Train_data[&#39;price&#39;].value_counts()</code></pre>
<pre><code>500      2337
1500     2158
1200     1922
1000     1850
2500     1821
         ... 
25321       1
8886        1
8801        1
37920       1
8188        1
Name: price, Length: 3763, dtype: int64</code></pre><pre><code class="python">##1总体分布概况
import scipy.stats as st
y = Train_data[&#39;price&#39;]
plt.figure(1);plt.title(&#39;Johnson SU&#39;)
sns.distplot(y,kde=False,fit=st.johnsonsu)
plt.figure(2);plt.title(&#39;Normal&#39;)
sns.distplot(y,kde=False,fit=st.norm)
plt.figure(3);plt.title(&#39;Log Normal&#39;)
sns.distplot(y,kde=False,fit=st.lognorm)</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x119904b50&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_46_1.png" alt="png"></p>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_46_2.png" alt="png"></p>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_46_3.png" alt="png"></p>
<pre><code class="python">##2查看skewness 和 kurtosis
sns.distplot(Train_data[&#39;price&#39;]);
print(&quot;Skewness: %f&quot; % Train_data[&#39;price&#39;].skew())
print(&quot;Kurtosis: %f&quot; % Train_data[&#39;price&#39;].kurt())</code></pre>
<pre><code>Skewness: 3.346487
Kurtosis: 18.995183</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_47_1.png" alt="png"></p>
<pre><code class="python">Train_data.skew(),Train_data.kurt()</code></pre>
<pre><code>(SaleID               6.017846e-17
 name                 5.576058e-01
 regDate              2.849508e-02
 model                1.484388e+00
 brand                1.150760e+00
 bodyType             9.915299e-01
 fuelType             1.595486e+00
 gearbox              1.317514e+00
 power                6.586318e+01
 kilometer           -1.525921e+00
 notRepairedDamage    2.430640e+00
 regionCode           6.888812e-01
 creatDate           -7.901331e+01
 price                3.346487e+00
 v_0                 -1.316712e+00
 v_1                  3.594543e-01
 v_2                  4.842556e+00
 v_3                  1.062920e-01
 v_4                  3.679890e-01
 v_5                 -4.737094e+00
 v_6                  3.680730e-01
 v_7                  5.130233e+00
 v_8                  2.046133e-01
 v_9                  4.195007e-01
 v_10                 2.522046e-02
 v_11                 3.029146e+00
 v_12                 3.653576e-01
 v_13                 2.679152e-01
 v_14                -1.186355e+00
 dtype: float64,
 SaleID                 -1.200000
 name                   -1.039945
 regDate                -0.697308
 model                   1.740483
 brand                   1.076201
 bodyType                0.206937
 fuelType                5.880049
 gearbox                -0.264161
 power                5733.451054
 kilometer               1.141934
 notRepairedDamage       3.908072
 regionCode             -0.340832
 creatDate            6881.080328
 price                  18.995183
 v_0                     3.993841
 v_1                    -1.753017
 v_2                    23.860591
 v_3                    -0.418006
 v_4                    -0.197295
 v_5                    22.934081
 v_6                    -1.742567
 v_7                    25.845489
 v_8                    -0.636225
 v_9                    -0.321491
 v_10                   -0.577935
 v_11                   12.568731
 v_12                    0.268937
 v_13                   -0.438274
 v_14                    2.393526
 dtype: float64)</code></pre><pre><code class="python">sns.distplot(Train_data.skew(),color=&#39;blue&#39;,axlabel=&#39;Skewness&#39;)</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1197c88d0&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_49_1.png" alt="png"></p>
<pre><code class="python">sns.distplot(Train_data.kurt(),color=&#39;orange&#39;,axlabel=&#39;Kurtness&#39;)</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a301f4c10&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_50_1.png" alt="png"></p>
<pre><code class="python">##3查看预测值的具体频数
plt.hist(Train_data[&#39;price&#39;],orientation = &#39;vertical&#39;,histtype=&#39;bar&#39;,color=&#39;red&#39;)
plt.show()</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_51_0.png" alt="png"></p>
<pre><code class="python">#log变换
plt.hist(np.log(Train_data[&#39;price&#39;]),orientation = &#39;vertical&#39;,histtype=&#39;bar&#39;,color=&#39;red&#39;)
plt.show()</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_52_0.png" alt="png"></p>
<h3 id="2-2-6-特征分为类别特征和数字特征，并对类别特征查看unique分布"><a href="#2-2-6-特征分为类别特征和数字特征，并对类别特征查看unique分布" class="headerlink" title="2.2.6 特征分为类别特征和数字特征，并对类别特征查看unique分布"></a>2.2.6 特征分为类别特征和数字特征，并对类别特征查看unique分布</h3><pre><code class="python">#分离预测值
Y_train = Train_data[&#39;price&#39;]</code></pre>
<pre><code class="python">number_features = [&#39;power&#39;,&#39;kilometer&#39;,&#39;v_0&#39;,&#39;v_1&#39;,&#39;v_2&#39;,&#39;v_3&#39;,&#39;v_4&#39;,&#39;v_5&#39;,&#39;v_6&#39;,&#39;v_7&#39;,&#39;v_8&#39;,&#39;v_9&#39;,&#39;v_10&#39;,&#39;v_11&#39;,&#39;v_12&#39;,&#39;v_13&#39;,&#39;v_14&#39;]

categorical_features = [&#39;name&#39;,&#39;model&#39;,&#39;brand&#39;,&#39;bodyType&#39;,&#39;fuelType&#39;,&#39;gearbox&#39;,&#39;notRepairedDamage&#39;,&#39;regionCode&#39;]</code></pre>
<pre><code class="python">#特征nunique分布
for cat_fea in categorical_features:
    print(cat_fea + &quot;的特征分布如下：&quot;)
    print(&quot;{}特征有个{}不同的值&quot;.format(cat_fea,Train_data[cat_fea].nunique()))
    print(Train_data[cat_fea].value_counts())</code></pre>
<pre><code>name的特征分布如下：
name特征有个99662不同的值
708       282
387       282
55        280
1541      263
203       233
         ... 
5074        1
7123        1
11221       1
13270       1
174485      1
Name: name, Length: 99662, dtype: int64
model的特征分布如下：
model特征有个248不同的值
0.0      11762
19.0      9573
4.0       8445
1.0       6038
29.0      5186
         ...  
245.0        2
209.0        2
240.0        2
242.0        2
247.0        1
Name: model, Length: 248, dtype: int64
brand的特征分布如下：
brand特征有个40不同的值
0     31480
4     16737
14    16089
10    14249
1     13794
6     10217
9      7306
5      4665
13     3817
11     2945
3      2461
7      2361
16     2223
8      2077
25     2064
27     2053
21     1547
15     1458
19     1388
20     1236
12     1109
22     1085
26      966
30      940
17      913
24      772
28      649
32      592
29      406
37      333
2       321
31      318
18      316
36      228
34      227
33      218
23      186
35      180
38       65
39        9
Name: brand, dtype: int64
bodyType的特征分布如下：
bodyType特征有个8不同的值
0.0    41420
1.0    35272
2.0    30324
3.0    13491
4.0     9609
5.0     7607
6.0     6482
7.0     1289
Name: bodyType, dtype: int64
fuelType的特征分布如下：
fuelType特征有个7不同的值
0.0    91656
1.0    46991
2.0     2212
3.0      262
4.0      118
5.0       45
6.0       36
Name: fuelType, dtype: int64
gearbox的特征分布如下：
gearbox特征有个2不同的值
0.0    111623
1.0     32396
Name: gearbox, dtype: int64
notRepairedDamage的特征分布如下：
notRepairedDamage特征有个2不同的值
0.0    111361
1.0     14315
Name: notRepairedDamage, dtype: int64
regionCode的特征分布如下：
regionCode特征有个7905不同的值
419     369
764     258
125     137
176     136
462     134
       ... 
6414      1
7063      1
4239      1
5931      1
7267      1
Name: regionCode, Length: 7905, dtype: int64</code></pre><pre><code class="python">#特征nunique分布
for cat_fea in categorical_features:
    print(cat_fea + &quot;的特征分布如下：&quot;)
    print(&quot;{}特征有个{}不同的值&quot;.format(cat_fea,Test_data[cat_fea].nunique()))
    print(Test_data[cat_fea].value_counts())</code></pre>
<pre><code>name的特征分布如下：
name特征有个37453不同的值
55       97
708      96
387      95
1541     88
713      74
         ..
22270     1
89855     1
42752     1
48899     1
11808     1
Name: name, Length: 37453, dtype: int64
model的特征分布如下：
model特征有个247不同的值
0.0      3896
19.0     3245
4.0      3007
1.0      1981
29.0     1742
         ... 
242.0       1
240.0       1
244.0       1
243.0       1
246.0       1
Name: model, Length: 247, dtype: int64
brand的特征分布如下：
brand特征有个40不同的值
0     10348
4      5763
14     5314
10     4766
1      4532
6      3502
9      2423
5      1569
13     1245
11      919
7       795
3       773
16      771
8       704
25      695
27      650
21      544
15      511
20      450
19      450
12      389
22      363
30      324
17      317
26      303
24      268
28      225
32      193
29      117
31      115
18      106
2       104
37       92
34       77
33       76
36       67
23       62
35       53
38       23
39        2
Name: brand, dtype: int64
bodyType的特征分布如下：
bodyType特征有个8不同的值
0.0    13985
1.0    11882
2.0     9900
3.0     4433
4.0     3303
5.0     2537
6.0     2116
7.0      431
Name: bodyType, dtype: int64
fuelType的特征分布如下：
fuelType特征有个7不同的值
0.0    30656
1.0    15544
2.0      774
3.0       72
4.0       37
6.0       14
5.0       10
Name: fuelType, dtype: int64
gearbox的特征分布如下：
gearbox特征有个2不同的值
0.0    37301
1.0    10789
Name: gearbox, dtype: int64
notRepairedDamage的特征分布如下：
notRepairedDamage特征有个2不同的值
0.0    37249
1.0     4720
Name: notRepairedDamage, dtype: int64
regionCode的特征分布如下：
regionCode特征有个6971不同的值
419     146
764      78
188      52
125      51
759      51
       ... 
7753      1
7463      1
7230      1
826       1
112       1
Name: regionCode, Length: 6971, dtype: int64</code></pre><h3 id="2-2-7-数字特征分析"><a href="#2-2-7-数字特征分析" class="headerlink" title="2.2.7 数字特征分析"></a>2.2.7 数字特征分析</h3><pre><code class="python">number_features = [&#39;power&#39;,&#39;kilometer&#39;,&#39;v_0&#39;,&#39;v_1&#39;,&#39;v_2&#39;,&#39;v_3&#39;,&#39;v_4&#39;,&#39;v_5&#39;,&#39;v_6&#39;,&#39;v_7&#39;,&#39;v_8&#39;,&#39;v_9&#39;,&#39;v_10&#39;,&#39;v_11&#39;,&#39;v_12&#39;,&#39;v_13&#39;,&#39;v_14&#39;]
number_features.append(&#39;price&#39;)</code></pre>
<pre><code class="python">number_features</code></pre>
<pre><code>[&#39;power&#39;,
 &#39;kilometer&#39;,
 &#39;v_0&#39;,
 &#39;v_1&#39;,
 &#39;v_2&#39;,
 &#39;v_3&#39;,
 &#39;v_4&#39;,
 &#39;v_5&#39;,
 &#39;v_6&#39;,
 &#39;v_7&#39;,
 &#39;v_8&#39;,
 &#39;v_9&#39;,
 &#39;v_10&#39;,
 &#39;v_11&#39;,
 &#39;v_12&#39;,
 &#39;v_13&#39;,
 &#39;v_14&#39;,
 &#39;price&#39;]</code></pre><pre><code class="python">Train_data.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SaleID</th>
      <th>name</th>
      <th>regDate</th>
      <th>model</th>
      <th>brand</th>
      <th>bodyType</th>
      <th>fuelType</th>
      <th>gearbox</th>
      <th>power</th>
      <th>kilometer</th>
      <th>...</th>
      <th>v_5</th>
      <th>v_6</th>
      <th>v_7</th>
      <th>v_8</th>
      <th>v_9</th>
      <th>v_10</th>
      <th>v_11</th>
      <th>v_12</th>
      <th>v_13</th>
      <th>v_14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>736</td>
      <td>20040402</td>
      <td>30.0</td>
      <td>6</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>60</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.235676</td>
      <td>0.101988</td>
      <td>0.129549</td>
      <td>0.022816</td>
      <td>0.097462</td>
      <td>-2.881803</td>
      <td>2.804097</td>
      <td>-2.420821</td>
      <td>0.795292</td>
      <td>0.914762</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2262</td>
      <td>20030301</td>
      <td>40.0</td>
      <td>1</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.264777</td>
      <td>0.121004</td>
      <td>0.135731</td>
      <td>0.026597</td>
      <td>0.020582</td>
      <td>-4.900482</td>
      <td>2.096338</td>
      <td>-1.030483</td>
      <td>-1.722674</td>
      <td>0.245522</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>14874</td>
      <td>20040403</td>
      <td>115.0</td>
      <td>15</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>163</td>
      <td>12.5</td>
      <td>...</td>
      <td>0.251410</td>
      <td>0.114912</td>
      <td>0.165147</td>
      <td>0.062173</td>
      <td>0.027075</td>
      <td>-4.846749</td>
      <td>1.803559</td>
      <td>1.565330</td>
      <td>-0.832687</td>
      <td>-0.229963</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>71865</td>
      <td>19960908</td>
      <td>109.0</td>
      <td>10</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>193</td>
      <td>15.0</td>
      <td>...</td>
      <td>0.274293</td>
      <td>0.110300</td>
      <td>0.121964</td>
      <td>0.033395</td>
      <td>0.000000</td>
      <td>-4.509599</td>
      <td>1.285940</td>
      <td>-0.501868</td>
      <td>-2.438353</td>
      <td>-0.478699</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>111080</td>
      <td>20120103</td>
      <td>110.0</td>
      <td>5</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>68</td>
      <td>5.0</td>
      <td>...</td>
      <td>0.228036</td>
      <td>0.073205</td>
      <td>0.091880</td>
      <td>0.078819</td>
      <td>0.121534</td>
      <td>-1.896240</td>
      <td>0.910783</td>
      <td>0.931110</td>
      <td>2.834518</td>
      <td>1.923482</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 29 columns</p>
</div>




<pre><code class="python">##1相关性分析
price_numeric= Train_data[number_features]
correlation= price_numeric.corr()
print(correlation[&#39;price&#39;].sort_values(ascending = False),&#39;\n&#39;)</code></pre>
<pre><code>price        1.000000
v_12         0.692823
v_8          0.685798
v_0          0.628397
power        0.219834
v_5          0.164317
v_2          0.085322
v_6          0.068970
v_1          0.060914
v_14         0.035911
v_13        -0.013993
v_7         -0.053024
v_4         -0.147085
v_9         -0.206205
v_10        -0.246175
v_11        -0.275320
kilometer   -0.440519
v_3         -0.730946
Name: price, dtype: float64 </code></pre><pre><code class="python">f , ax = plt.subplots(figsize=(7,7))
plt.title(&#39;Correlation of Numeric Features with Price&#39;,y=1,size=16)
sns.heatmap(correlation,square= True, vmax=0.8)</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11979ed50&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_63_1.png" alt="png"></p>
<pre><code class="python">
## 2查看几个特征的偏度和峰值
for col in number_features:
    print(&#39;{:15}&#39;.format(col),
          &#39;Skewness:{:05.2f}&#39;.format(Train_data[col].skew()),
          &#39;   &#39;,
          &#39;Kurtosis:{:06.2f}&#39;.format(Train_data[col].kurt()))</code></pre>
<pre><code>power           Skewness:65.86     Kurtosis:5733.45
kilometer       Skewness:-1.53     Kurtosis:001.14
v_0             Skewness:-1.32     Kurtosis:003.99
v_1             Skewness:00.36     Kurtosis:-01.75
v_2             Skewness:04.84     Kurtosis:023.86
v_3             Skewness:00.11     Kurtosis:-00.42
v_4             Skewness:00.37     Kurtosis:-00.20
v_5             Skewness:-4.74     Kurtosis:022.93
v_6             Skewness:00.37     Kurtosis:-01.74
v_7             Skewness:05.13     Kurtosis:025.85
v_8             Skewness:00.20     Kurtosis:-00.64
v_9             Skewness:00.42     Kurtosis:-00.32
v_10            Skewness:00.03     Kurtosis:-00.58
v_11            Skewness:03.03     Kurtosis:012.57
v_12            Skewness:00.37     Kurtosis:000.27
v_13            Skewness:00.27     Kurtosis:-00.44
v_14            Skewness:-1.19     Kurtosis:002.39
price           Skewness:03.35     Kurtosis:019.00</code></pre><pre><code class="python">##3每个数字特征的分布可视化
f = pd.melt(Train_data,value_vars=number_features)
g = sns.FacetGrid(f,col=&quot;variable&quot;,col_wrap=2,sharex=False,sharey= False)
g=g.map(sns.distplot,&quot;value&quot;)</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_65_0.png" alt="png"></p>
<pre><code class="python">##4数字特征相互之间的关系可视化
sns.set()
columns=[&#39;price&#39;,&#39;v_12&#39;,&#39;v_8&#39;,&#39;v_0&#39;,&#39;power&#39;,&#39;v_5&#39;,&#39;v_2&#39;,&#39;v_6&#39;,&#39;v_1&#39;,&#39;v_14&#39;]
sns.pairplot(Train_data[columns],size = 2,kind=&#39;scatter&#39;,diag_kind=&#39;kde&#39;)
plt.show()</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_66_0.png" alt="png"></p>
<pre><code class="python">Train_data.columns</code></pre>
<pre><code>Index([&#39;SaleID&#39;, &#39;name&#39;, &#39;regDate&#39;, &#39;model&#39;, &#39;brand&#39;, &#39;bodyType&#39;, &#39;fuelType&#39;,
       &#39;gearbox&#39;, &#39;power&#39;, &#39;kilometer&#39;, &#39;notRepairedDamage&#39;, &#39;regionCode&#39;,
       &#39;creatDate&#39;, &#39;price&#39;, &#39;v_0&#39;, &#39;v_1&#39;, &#39;v_2&#39;, &#39;v_3&#39;, &#39;v_4&#39;, &#39;v_5&#39;, &#39;v_6&#39;,
       &#39;v_7&#39;, &#39;v_8&#39;, &#39;v_9&#39;, &#39;v_10&#39;, &#39;v_11&#39;, &#39;v_12&#39;, &#39;v_13&#39;, &#39;v_14&#39;],
      dtype=&#39;object&#39;)</code></pre><pre><code class="python">Y_train</code></pre>
<pre><code>0         1850
1         3600
2         6222
3         2400
4         5200
          ... 
149995    5900
149996    9500
149997    7500
149998    4999
149999    4700
Name: price, Length: 150000, dtype: int64</code></pre><pre><code class="python">##5多变量互相回归关系可视化
fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(nrows=5, ncols=2, figsize=(24, 20))
# [&#39;v_12&#39;, &#39;v_8&#39; , &#39;v_0&#39;, &#39;power&#39;, &#39;v_5&#39;,  &#39;v_2&#39;, &#39;v_6&#39;, &#39;v_1&#39;, &#39;v_14&#39;]
v_12_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_12&#39;]],axis = 1)
sns.regplot(x=&#39;v_12&#39;,y = &#39;price&#39;, data = v_12_scatter_plot,scatter= True, fit_reg=True, ax=ax1)

v_8_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_8&#39;]],axis = 1)
sns.regplot(x=&#39;v_8&#39;,y = &#39;price&#39;,data = v_8_scatter_plot,scatter= True, fit_reg=True, ax=ax2)

v_0_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_0&#39;]],axis = 1)
sns.regplot(x=&#39;v_0&#39;,y = &#39;price&#39;,data = v_0_scatter_plot,scatter= True, fit_reg=True, ax=ax3)

power_scatter_plot = pd.concat([Y_train,Train_data[&#39;power&#39;]],axis = 1)
sns.regplot(x=&#39;power&#39;,y = &#39;price&#39;,data = power_scatter_plot,scatter= True, fit_reg=True, ax=ax4)

v_5_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_5&#39;]],axis = 1)
sns.regplot(x=&#39;v_5&#39;,y = &#39;price&#39;,data = v_5_scatter_plot,scatter= True, fit_reg=True, ax=ax5)

v_2_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_2&#39;]],axis = 1)
sns.regplot(x=&#39;v_2&#39;,y = &#39;price&#39;,data = v_2_scatter_plot,scatter= True, fit_reg=True, ax=ax6)

v_6_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_6&#39;]],axis = 1)
sns.regplot(x=&#39;v_6&#39;,y = &#39;price&#39;,data = v_6_scatter_plot,scatter= True, fit_reg=True, ax=ax7)

v_1_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_1&#39;]],axis = 1)
sns.regplot(x=&#39;v_1&#39;,y = &#39;price&#39;,data = v_1_scatter_plot,scatter= True, fit_reg=True, ax=ax8)

v_14_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_14&#39;]],axis = 1)
sns.regplot(x=&#39;v_14&#39;,y = &#39;price&#39;,data = v_14_scatter_plot,scatter= True, fit_reg=True, ax=ax9)

v_13_scatter_plot = pd.concat([Y_train,Train_data[&#39;v_13&#39;]],axis = 1)
sns.regplot(x=&#39;v_13&#39;,y = &#39;price&#39;,data = v_13_scatter_plot,scatter= True, fit_reg=True, ax=ax10)</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a35942d10&gt;</code></pre><p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_69_1.png" alt="png"></p>
<h3 id="2-2-8-类别特征分析"><a href="#2-2-8-类别特征分析" class="headerlink" title="2.2.8 类别特征分析"></a>2.2.8 类别特征分析</h3><pre><code class="python">##1unique分布
for fea in categorical_features:
    print(Train_data[fea].nunique())</code></pre>
<pre><code>99662
248
40
8
7
2
2
7905</code></pre><pre><code class="python">categorical_features</code></pre>
<pre><code>[&#39;name&#39;,
 &#39;model&#39;,
 &#39;brand&#39;,
 &#39;bodyType&#39;,
 &#39;fuelType&#39;,
 &#39;gearbox&#39;,
 &#39;notRepairedDamage&#39;,
 &#39;regionCode&#39;]</code></pre><pre><code class="python">##2类别特征箱形图可视化
categorical_features = [&#39;model&#39;,
 &#39;brand&#39;,
 &#39;bodyType&#39;,
 &#39;fuelType&#39;,
 &#39;gearbox&#39;,
 &#39;notRepairedDamage&#39;]
for c in categorical_features:
    Train_data[c]=Train_data[c].astype(&#39;category&#39;)
    if Train_data[c].isnull().any():
        Train_data[c] = Train_data[c].cat.add_categories([&#39;MISSING&#39;])
        Train_data[c]=Train_data[c].fillna(&#39;MISSING&#39;)
def boxplot(x,y,**kwargs):
    sns.boxplot(x=x,y=y)
    x=plt.xticks(rotation=90)
f = pd.melt(Train_data,id_vars=[&#39;price&#39;],value_vars=categorical_features)
g = sns.FacetGrid(f,col=&quot;variable&quot;,col_wrap=2,sharex=False,sharey= False,size=5)
g = g.map(boxplot,&quot;value&quot;,&quot;price&quot;)</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_73_0.png" alt="png"></p>
<pre><code class="python">Train_data.columns</code></pre>
<pre><code>Index([&#39;SaleID&#39;, &#39;name&#39;, &#39;regDate&#39;, &#39;model&#39;, &#39;brand&#39;, &#39;bodyType&#39;, &#39;fuelType&#39;,
       &#39;gearbox&#39;, &#39;power&#39;, &#39;kilometer&#39;, &#39;notRepairedDamage&#39;, &#39;regionCode&#39;,
       &#39;creatDate&#39;, &#39;price&#39;, &#39;v_0&#39;, &#39;v_1&#39;, &#39;v_2&#39;, &#39;v_3&#39;, &#39;v_4&#39;, &#39;v_5&#39;, &#39;v_6&#39;,
       &#39;v_7&#39;, &#39;v_8&#39;, &#39;v_9&#39;, &#39;v_10&#39;, &#39;v_11&#39;, &#39;v_12&#39;, &#39;v_13&#39;, &#39;v_14&#39;],
      dtype=&#39;object&#39;)</code></pre><pre><code class="python">###3类别特征的小提琴图可视化
catg_list = categorical_features
target= &#39;price&#39;
for catg in catg_list :
    sns.violinplot(x=catg,y=target,data=Train_data)
    plt.show()</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_75_0.png" alt="png"></p>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_75_1.png" alt="png"></p>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_75_2.png" alt="png"></p>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_75_3.png" alt="png"></p>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_75_4.png" alt="png"></p>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_75_5.png" alt="png"></p>
<pre><code class="python">categorical_features = [&#39;model&#39;,
 &#39;brand&#39;,
 &#39;bodyType&#39;,
 &#39;fuelType&#39;,
 &#39;gearbox&#39;,
 &#39;notRepairedDamage&#39;]</code></pre>
<pre><code class="python">##4类别特征的柱形图可视化
def bar_plot(x, y, **kwargs):
    sns.barplot(x=x, y=y)
    x=plt.xticks(rotation=90)

f = pd.melt(Train_data, id_vars=[&#39;price&#39;], value_vars=categorical_features)
g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False, size=5)
g = g.map(bar_plot, &quot;value&quot;, &quot;price&quot;)</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_77_0.png" alt="png"></p>
<pre><code class="python">##5类别特征的每个类别频数可视化(count_plot)
def count_plot(x,  **kwargs):
    sns.countplot(x=x)
    x=plt.xticks(rotation=90)

f = pd.melt(Train_data,  value_vars=categorical_features)
g = sns.FacetGrid(f, col=&quot;variable&quot;,  col_wrap=2, sharex=False, sharey=False, size=5)
g = g.map(count_plot, &quot;value&quot;)</code></pre>
<p><img src="/2020/03/24/Datawhale%20%E4%BA%8C%E6%89%8B%E8%BD%A6%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8BTask1&Task2/output_78_0.png" alt="png"></p>
<h3 id="2-2-9-用pandas-profiling生成数据报告"><a href="#2-2-9-用pandas-profiling生成数据报告" class="headerlink" title="2.2.9 用pandas_profiling生成数据报告"></a>2.2.9 用pandas_profiling生成数据报告</h3><pre><code class="python">import pandas_profiling
###刚开始这个地方一直报错，终于解决了！！！！原因是我安装命令写错了
##错误的写成了pip install pandas profilling 正确的应该是pip install pandas_profiling</code></pre>
<pre><code class="python">pfr = pandas_profiling.ProfileReport(Train_data)
pfr.to_file(&quot;./tianchi/example.html&quot;)</code></pre>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>DataWhale</tag>
        <tag>天池</tag>
      </tags>
  </entry>
</search>
